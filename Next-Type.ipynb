{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Next Type - A Mobile Typing Assistant\n",
    "[CS 505 - NLP] [Final Project]\n",
    "Completed by Muhammad Aseef Imran\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Problem Statement\n",
    "\n",
    "Compared to typing on a keyboard, typing on our phones considerably slower. Luckily most phones come built in with a feature to predict your next word to make up for this. However, after much experimentation, it seems most of these prediction algorithms seem to use simple N-grams with a window of around 3-4 words of left context. Many times, predicting the next word based on simple N-gram based probabilities work \"fine\" but often, this strategy produces poor results due to ignoring the context of the sentence. As NLP technology leaps forward exponentially we can do much better than simplistic N-grams. For this reason **Next Type** aims to bring the next generation of typing experiance to its users in order to raise productivity and typing speed for users leaving more time for the important things in life!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "    <img src=\"assets/bad-phone-example-1.jpg\" alt=\"N-gram example 1\" style=\"width: 33%; padding-right: 10px;\">\n",
    "    <img src=\"assets/bad-phone-example-2.jpg\" alt=\"N-gram example 2\" style=\"width: 33%; padding-right: 10px;\">\n",
    "    <img src=\"assets/bad-phone-example-3.jpg\" alt=\"N-gram example 3\" style=\"width: 33%;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Presented above are three examples where unfortunately, the standard N-gram model employed on \"modern\" devices fails miserably.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Project Goals\n",
    "\n",
    "N-gram models perform very poorly with shorter context window, and any large context windows require an immense amount of data to produce reasonable results. Moreover, at least in this case, our N-gram models do not consider the right context when suggesting words. However, despite having their weaknesses, the N-gram approach also has some nice benefits. Particularly, the nature of the N-gram model allows it to be easily updated with new data and adapt to the typing habits of its users with little processing power.\n",
    "\n",
    "Keeping these things in mind, we can summarize our goals for the model we have set out to develop as:\n",
    "1. The model should consider both the left and right context before suggesting a \"natural\" word that fits the context.\n",
    "2. The model should be able to adapt to or learn from the user's word choices in various contexts.\n",
    "3. The model should be able to learn the user's word choice as—outlined above—quick enough to be useful.\n",
    "4. The model should be reasonably sized allowing it to be run and be updated on most modern-phone hardware with in reasonable time.\n",
    "\n",
    "Additional things that may be considered (depending on time) in our model may be that:\n",
    "\n",
    "5. The model should validate the input data for grammatical correctness to avoid learning incorrect patterns.\n",
    "6. The model should (optionally) avoid suggesting profane language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Key Questions & Challenges\n",
    "\n",
    "Let us better define the problem and explain exactly what we are seeking to achieve and possible challanges.\n",
    "\n",
    "1. People evolve and change. So can I get a better accuracy by consider ALL known history? Or only \"recent\" history? Should the more recent history be weighted more\"? If so, should history be judged more by time or the volume typed? If I'm wrong about this, then more data = better. OR the time people change in is just longer.\n",
    "2. My problem is my data is ever evolving. So how do I prevent the model from overfitting? Overfitting will make newer data harder to generalize. (i.e. How do I prevent it from forgetting the stuff it knew in the base model?). Also suppose if I don't want my model to consider the \"old\" history, how can I make the model \"forgot\" the old stuff (some kind of vanishing gradient is my best choice)?\n",
    "\n",
    "Shortcomings of this research: data may be biased. Only considering reddit users. Particularly those who type somewhat frequently on reddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Obtaining the Fine-Tuning Data\n",
    "\n",
    "It is important for my task that the fine-tunning data only come from a single person since my goal is to train the model to adapt to the typing behavior of a specific user. In order to achieve this we can use scraped messages from reddit for specific users and examine how the model adapts to their specific word-choice and typing habits. Particularly, we will be using data from a pre-scrapped dataset [Reddit comments/submissions 2005-06](https://academictorrents.com/details/89d24ff9d5fbc1efcdaf9d7689d72b7548f699fc). Further, we also want to make sure that sample data from any user we use:\n",
    "* Provides a reasonably large enough dataset to train on\n",
    "* Posts regularly (as opposed to posting a lot occasionally)\n",
    "\n",
    "With that defined, our focus will be between and including messages posted between [1/2011 - 6/2012]. Why this particular time range? No particular reason besides that data with in this time range was reasonably enough sized to be processed quickly yet still leave us with enough data to work with.\n",
    "\n",
    "We can then process the reddit dump creating a dictionary consisting of reddit users and the messages they sent. We further filter this data as follows:\n",
    "* \"Deleted\" users aren't included\n",
    "* First, we remove all authors with less than 546 (i.e. they must average more than 1 post a day) - although future filteration steps would've already ensured this requirement, we start of with this since this is a quick and dirty elimination step allowing for quicker processing in the next steps (which are a bit more complicated implementation wise)\n",
    "* Second, we filter to only authors that made at least 18 post per month in the time range without missing any month.\n",
    "* Third, we filter to only authors that made at least 2 post every week without missing a week.\n",
    "* Fourth, we filter down the remaining users to those that posted on at least 80% of the days.\n",
    "* In our final step, we post process the post messages by running it through a sequence-to-sequence model already developed by someone correcting silly grammatical errors. Otherwise, we may end up having messages in our data set that contain non-existent vocab.\n",
    "\n",
    "\n",
    "TODO: grammer corrrection may be needed! https://huggingface.co/pszemraj/grammar-synthesis-small/tree/main also trained on t5\n",
    "or https://huggingface.co/flexudy/t5-small-wav2vec2-grammar-fixer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Establishing a Baseline\n",
    "\n",
    "As previously mentioned, we want to develop a model the beats the naive n-gram models (with a window of 3) used by most keyboard apps. Therefore, we will define our baseline as 3-gram model trained on the entire reddit corpus. A larger window size will not be feasible do to the massive amounts of memory required to hold such a model. This model uses simple probabilities based on the frequency of the n-gram in the corpus to make predictions.\n",
    "\n",
    "However, compared to n-gram models used by most keyboard apps, we will be making several simplification assumptions for our baseline:\n",
    "1. Our baseline model will not \"update\" n-gram model by using data from its user. On real keyboard apps, the model updates based on the users behavior (much like how we will update our models too later in this project). However, just for the purpose of having a working \"baseline\" and in the interest of time, this is a detail we neglect.\n",
    "2. Our model will also predict punctuations. Most keyboard apps only predict words however to get a fairer comparison to the models we will me employing (which do predict) punctuations, our version predicts punctuations (or tries to anyways).\n",
    "3. As previously implied, our n-gram model will be constructed solely of reddit. Specifically, the n-gram model is \"trained\" on all messages typed on reddit between [1/2011 - 6/2012].\n",
    "\n",
    "#### Baseline Training Details\n",
    "\n",
    "We will be training a 3-gram model and a 2-gram model. Our model will first attempt to use the 3-gram to make a prediction. If the 3-gram model does not have a machine n-gram, we will then fall back to 2-grams.\n",
    "\n",
    "The 3-gram model is trained as follows:\n",
    "1. For each month in the range [1/2011 - 6/2012], gather all posts and for each posts construct a 3-gram.\n",
    "    1. Add the 3-grams to a counter.\n",
    "    2. If by the time we finish processing the current month, if n-gram has not occurred at least 2 times delete it.\n",
    "2. Now for the entire n-gram dictionary, delete all n-gram that occurred less than 16 times in the entire corpus.\n",
    "\n",
    "Similarly, for the 2-gram model:\n",
    "1. For each month in the range [1/2011 - 6/2012], gather all posts and for each posts construct a 2-gram.\n",
    "    1. Add the 2-grams to a counter.\n",
    "    2. If by the time we finish processing the current month, if n-gram has not occurred at least 5 times delete it.\n",
    "2. Now for the entire n-gram dictionary, delete all n-gram that occurred less than 25 times in the entire corpus.\n",
    "\n",
    "Exact training script used can be found in the [create_raw_reddit_ngrams.py](./create_raw_reddit_ngrams.py) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Definition a \"Successful\" Prediction\n",
    "\n",
    "We define a successful prediction as a prediction that meets the following criteria:\n",
    "```The predicted next word is one of the top 3 predictions or a \"close enough\" synonym of one of the top 3 words.```\n",
    "\n",
    "#### Justification\n",
    "The goal of our \"predict the next word\" is to allow our users to type faster by suggesting their next word. Generally, most mobile devices have enough screen space to suggest at least 3 words for the \"next word\". Moreover, users may not care enough to type to exact word they were thinking of if the suggested word has a \"close enough\" meaning to the word they intended to write.\n",
    "\n",
    "#### Defining a \"close enough\" synonym\n",
    "We will base our definition of a \"close enough\" synonym on the assumption that \"most words have a synonym\". Then, we define a synonym to be close enough as follows:\n",
    "1. For each word in the word embedding space, find the word closest to that word using some distance metric.\n",
    "2. Calculate the mean and standard deviation of the distances between the closest words.\n",
    "3. Now we define a word to be \"close enough\" as being with in (the mean minus 1 standard deviation) unit distance from the predicted word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Evaluation Stategy\n",
    "\n",
    "In light of our above outlined goals, we have two major evaluation goals:\n",
    "\n",
    "\n",
    "1. How well does the model predict the user's next token after having seen x tokens of examples from the user. In other words, not only how well the model predicts the user's next token but also how fast the model improves its prediction as a function of the data it has already seen?\n",
    "\n",
    "> We can evaluate \"how well\" the model predicts the user's next token by measuring the loss between what the user actually types vs what the model suggests. Then, we can further measure this loss as function of the number of tokens of examples the model has seen during its Fine-Tuning. For example, how does the loss change after the model has seen 1000 tokens of examples from the user?\n",
    "\n",
    "2. How much computation is needed is to both run the model and update the model on new data?\n",
    "\n",
    "> Measuring how long various parts of the model such prediction and training takes is trivial. (We can simply calculate the time between the target area of code). We may then analyze the run-time in context of the hardware the code is run on and comparing this information with current state of computational power of modern mobile devices. This information can be used to make an informed decision on the sequence lengths to input to the model to ensure our model can suggest new words to users in real-time on standard mobile hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Project Plan and Exploring Potential Solutions\n",
    "\n",
    "Once again, our goal is to accuractely and effectively predict the user's next token in real-time while adapting to the user's behavior and writing style over time.\n",
    "\n",
    "In order to reasonably meet these goals, we will fine-tune one or more combination of existing models such as T5, Bert, and GPT2, and/or their \"Distilled\" counterparts. We will use the Hugging Face transformers library simply due to its vast popularity and easy of use. I intend to use the SCC for rapid prototyping and experimentation as I already have significant experiance using the SCC at this stage.\n",
    "\n",
    "Finally I should note that in my initial research, I have identified potential pitfalls with each of these models and their strengths and weaknesses for my task. However, further experimentation will be needed to make a final decision on which model (or model combinations) to use. Detailed experimentation with each model will be required to evaluate its pros/cons.\n",
    "\n",
    "#### Bert\n",
    "Having been trained on a mask-fill task, Bert naturally lends itself to the kind of project I am trying to do. Being a relatively small model, and still quite versatile for the task, Bert may be a great choice. However, one downside to Bert is that Bert seems to perform poorly when attempting to Mask-Fill multiple words in the middle of a sentence. (See the bottom of this notebook for a demonstration).\n",
    "\n",
    "#### GPT2\n",
    "GPT2 was essentially trained on predicting the next word. Indeed, this is the task we want to achieve ourselves. However, in some cases, we may need to predict the middle word (if someone is editing the middle of a sentence they wrote). This is not a task GPT2 was designed for although this may still be possible due to the surprising generality of the model. Further research and experimentation will be needed.\n",
    "\n",
    "#### T5\n",
    "T5 is an extremely general purpose model than can adapt to many NLP tasks. Unlike bert Being a substantially larger model than both GPT2 and Bert, T5 is slower to retrain. Yet at the same time, T5 seems to do a much better job mask-filling between sentences. Yet, in a realistic scenario how often does one write in the middle of the sentence? Is the increased computing cost really worth it? These are the questions I hope to answer with the first stages of my research.\n",
    "\n",
    "#### The \"Distilled Version\"\n",
    "Models like Distilled-Bert and Distilled-GPT2 are indeed smaller. However, one *major* pitfall to this may be that the model may struggle to generalize to new tasks and during retraining. Retraining forms an essential component to this project and depending on the severity of this effected, the \"Distilled\" models may prove ineffective. Further experimentation is needed to make any conclusions, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Limitations\n",
    "* Compared to the N-gram approach, this new model cannot easily learn new words?\n",
    "* You may talk different with friends vs family vs boss. This training and results was done specifically for reddit. It may be the case that the model will not generalize as well to a broader domain in an actual key board app. (Still probability at least better than the ngram stuff right?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Comparison and Exploratory Between Various Models\n",
    "\n",
    "We begin with an exploratory between different promising transformer models that have been historically very successful with a variety of tasks. Namely, we will do a comparisons between Bert, GPT2, and T5 on various tasks.\n",
    "\n",
    "1. We compare between the following 5 sentences to see how well the models do. These results are just to get a basic idea of each model's capabilities. We will \"eyeball this result\". Note that the \"|\" token represents the current \"cursor\" location.\n",
    "\n",
    "    a. `After forcefully breaking into the bank, they|`\n",
    "\n",
    "    b. `Every |, my family and I visit Hawaii.`\n",
    "\n",
    "    c. `In my family, there is my |`\n",
    "\n",
    "    d. `My favorite | is apple.`\n",
    "\n",
    "    e. `It has been 2 months since I graduated. However, unfortunately I still haven't found a |. At this rate I won't be able to pay rent!`\n",
    "\n",
    "2. After that, we will test each model to see how well the model does in predicting this \"next\" word token. This task is the most important task for our proposed application to do well.\n",
    "\n",
    "3. Next, we will see how well each model does at predicting a randomly removed \"middle\" token.\n",
    "\n",
    "4. Then, we do a similar challenge by now comparing how each model does at predicting when multiple \"middle\" tokens have been deleted.\n",
    "\n",
    "5. Finally, we will choose the most promising model to develop a fine-tuning method for this continuous learning project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Setup: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:49:27.048900600Z",
     "start_time": "2023-12-22T03:49:19.379407600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /usr4/cs505ws/aseef/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all imports here\n",
    "from typing import Union\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Tuple, List, Set, Any, Union\n",
    "import statistics\n",
    "import random\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, PreTrainedTokenizerBase, PreTrainedModel, GPT2Config\n",
    "from transformers import pipeline\n",
    "from transformers import DistilBertForMaskedLM, DistilBertTokenizer, DistilBertConfig, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM\n",
    "from datasets import Dataset\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:49:27.052915900Z",
     "start_time": "2023-12-22T03:49:27.047897200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"After forcefully breaking into the bank, they |\", # predict the next word using context\n",
    "    \"In my family, there is my |\", # predict the next word using context\n",
    "    \"Every |, my family and I visit Hawaii.\",  # simple mask fill with one missing word\n",
    "    \"My favorite | is apple.\", # simple mask fill with one missing word\n",
    "    \"It has been 2 months since I graduated. However, unfortunately I still haven't found a | rate I won't be able to pay rent!\", # need multiple words here before sentence makes sense\n",
    "    \"Following the American Civil War, | assassinated.\",  # need multiple words here before sentence makes sense\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:49:27.056898200Z",
     "start_time": "2023-12-22T03:49:27.049897Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = \"/projectnb/cs505ws/projects/NextType/data\"\n",
    "\n",
    "def does_var_exists_gz(var_name: str) -> bool:\n",
    "    return os.path.isfile(F'{data_dir}/{var_name}.pkl.gz')\n",
    "\n",
    "def dump_var_gz(var_name: str, obj) -> None:\n",
    "    os.makedirs(f\"{data_dir}\", exist_ok=True)\n",
    "    with gzip.open(F'{data_dir}/{var_name}.pkl.gz', 'wb', compresslevel=1) as file:\n",
    "        pickle.dump(obj, file)\n",
    "\n",
    "\n",
    "def load_var_gz(var_name: str) -> Union[None, object]:\n",
    "    if not does_var_exists_gz(var_name):\n",
    "        return None\n",
    "\n",
    "    file_path = F'{data_dir}/{var_name}.pkl.gz'  # Updated file extension\n",
    "    with gzip.open(file_path, 'rb', compresslevel=1) as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:49:33.871196400Z",
     "start_time": "2023-12-22T03:49:27.055899100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load n_gram models\n",
    "reddit_2_grams_pmf: Dict[Tuple[str, str], Dict[str, float]] = load_var_gz(\"reddit_2_grams_pmf\")\n",
    "reddit_3_grams_pmf: Dict[Tuple[str, str], Dict[str, float]] = load_var_gz(\"reddit_3_grams_pmf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:50:00.504012800Z",
     "start_time": "2023-12-22T03:49:33.838179Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load author to lines data\n",
    "author_to_posts_dict: Dict[str, Tuple[int, str]] = load_var_gz(\"author_to_lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:50:00.535056200Z",
     "start_time": "2023-12-22T03:50:00.495010900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chicofaraby',\n",
       " 'ScotiaTide',\n",
       " 'balchynz',\n",
       " 'bookemdanno',\n",
       " 'cassander',\n",
       " 'Darrelc',\n",
       " 'duckandcover',\n",
       " 'Ranzera',\n",
       " 'infidel118i',\n",
       " 'chmod777',\n",
       " 'CylonGlitch',\n",
       " 'HotelCoralEssex',\n",
       " 'potatogun',\n",
       " 'allwaysnice',\n",
       " 'Frankocean2',\n",
       " 'xenetic',\n",
       " 'CunningAllusionment',\n",
       " 'erode',\n",
       " 'honusnuggie',\n",
       " 'Nicoon',\n",
       " 'cecikierk',\n",
       " 'RosieLalala',\n",
       " 'stimbus',\n",
       " 'punninglinguist',\n",
       " 'mrzack']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_user_sample = random.sample(list(author_to_posts_dict.keys()), 25)\n",
    "random_user_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:50:00.535056200Z",
     "start_time": "2023-12-22T03:50:00.495010900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sample up to 50 posts from each user\n",
    "random_post_samples = []\n",
    "for rand_user in random_user_sample:\n",
    "    all_posts = author_to_posts_dict[rand_user]\n",
    "    sampled_posts = random.sample(list(all_posts), 50)\n",
    "    random_post_samples += sampled_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:50:00.536035800Z",
     "start_time": "2023-12-22T03:50:00.496011Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device=cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device={device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T01:39:18.792009500Z",
     "start_time": "2023-12-22T01:39:16.721362700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this was the only small-ish grammar correction model I found.\n",
    "# had I more time, I would create my own model. But I don't so I will focus\n",
    "# on my primary task.\n",
    "# the downsides of this models is that besides correcting spellings, it often alters the\n",
    "# structure of the sentence which could fundamentally undermine our purpose.\n",
    "# so question: does benefits of correcting grammar using this outweighs the harms?\n",
    "# after all, if the model doesnt recgonize a word, it'll just ignore it and wont learn from it!\n",
    "grammar_corrector = pipeline(\n",
    "               'text2text-generation',\n",
    "               'pszemraj/grammar-synthesis-small',\n",
    "                 device=device\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T03:50:00.536035800Z",
     "start_time": "2023-12-22T03:50:00.496011Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import html\n",
    "def normalize_text(post_text: str):\n",
    "    # get rid of new lines\n",
    "    post_text = re.sub(\"\\n\", \" \", post_text)\n",
    "    # remove html characters\n",
    "    post_text = html.unescape(post_text)\n",
    "    # Remove bold and italic formatting\n",
    "    post_text = post_text.replace('*', \"\")\n",
    "    # Remove headers\n",
    "    post_text = re.sub(r'^#{1,6}\\s', '', post_text)\n",
    "    # Remove hyperlinks\n",
    "    post_text = re.sub(r'\\[([^\\]]+)\\]\\(([^)]+)\\)', r'\\1', post_text)\n",
    "    # Remove inline code\n",
    "    post_text = re.sub(r'`([^`]+)`', r'\\1', post_text)\n",
    "    # Remove block code\n",
    "    post_text = re.sub(r'```[^`]*```', '', post_text)\n",
    "    # Remove lists (unordered and ordered)\n",
    "    post_text = re.sub(r'^\\s*([\\*\\-\\+]\\s|(\\d+\\.)\\s)', '', post_text)\n",
    "    post_text = re.sub(\"(\\*\\*|__)(.*?)\\1|(\\*|_)(.*?)\\3\", \"\", post_text)\n",
    "    # remove double spaces\n",
    "    post_text = re.sub(\" {2,}\", \" \", post_text)\n",
    "    # replace urls\n",
    "    post_text = re.sub(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\", \"{URL}\", post_text)\n",
    "    # replace references to a specific subreddit but just the token \"{SUB_REDDIT}\"\n",
    "    post_text = re.sub(r\"(\\W)(r/[a-z0-9A-Z_]{2,10})(\\W)\", r\"\\1{SUB_REDDIT}\\3\", post_text)\n",
    "    post_text = re.sub(r\"(\\W)(/[a-z0-9A-Z_]{2,10})(\\W)\", r\"\\1{SUB_REDDIT}\\3\", post_text)\n",
    "    post_text = post_text.strip()\n",
    "    return post_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                 | 0/3794 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'normalize_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(user_posts_corrected))):\n\u001b[1;32m      3\u001b[0m     creation, message \u001b[38;5;241m=\u001b[39m user_posts_corrected[i]\n\u001b[0;32m----> 4\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_text\u001b[49m(message)\n\u001b[1;32m      5\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m sent_tokenize(message)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sentences)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normalize_text' is not defined"
     ]
    }
   ],
   "source": [
    "user_posts_corrected = list(user_posts)\n",
    "for i in tqdm(range(len(user_posts_corrected))):\n",
    "    creation, message = user_posts_corrected[i]\n",
    "    message = normalize_text(message)\n",
    "    sentences = sent_tokenize(message)\n",
    "    for j in range(len(sentences)):\n",
    "        sent = sentences[j]\n",
    "        updated_message = grammar_corrector(sent)[0]['generated_text']\n",
    "        sentences[j] = updated_message\n",
    "    updated_message = ' '.join(sentences)\n",
    "    user_posts_corrected[i] = (creation, updated_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_var_gz(f\"{random_key}-corrected-posts\", user_posts_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T04:16:48.915928500Z",
     "start_time": "2023-12-22T04:16:48.902998200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_posts_corrected = load_var_gz('The_Jackal-corrected-posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "index = 0\n",
    "for old_post, new_post in zip(user_posts, user_posts_corrected):\n",
    "    normalized_post = normalize_text(old_post[1])\n",
    "    if old_post[1].strip() != new_post[1].strip():\n",
    "        print(\"-=+=--=+=--=+=--=+=--=+=--=+=-\")\n",
    "        print(f'Old Post {index}:', normalized_post)\n",
    "        print(\"~~+~~~~+~~~~+~~~~+~~~~+~~~~+~~\")\n",
    "        print(f'New Post {index}:', new_post[1])\n",
    "        print(\"-=+=--=+=--=+=--=+=--=+=--=+=-\")\n",
    "        counter += 1\n",
    "    index += 1\n",
    "    if counter > 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Baseline (n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T17:35:56.123109700Z",
     "start_time": "2023-12-21T17:35:56.062574400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ngram_prediction(current_sent) -> Union[None, str]:\n",
    "    def tokenize_post(pre_tokenized_post_data):\n",
    "        return [word for sent in nltk.sent_tokenize(pre_tokenized_post_data) for word in nltk.word_tokenize(sent)]\n",
    "\n",
    "    current_sent = normalize_text(current_sent)\n",
    "    current_sent = current_sent.lower()\n",
    "    ngram_input = tokenize_post(current_sent)\n",
    "\n",
    "    if tuple(ngram_input[-2:]) in reddit_3_grams_pmf:\n",
    "        prediction = reddit_3_grams_pmf[tuple(ngram_input[-2:])]\n",
    "    elif tuple(ngram_input[-1:]) in reddit_2_grams_pmf:\n",
    "        prediction = reddit_2_grams_pmf[tuple(ngram_input[-1:])]\n",
    "    else:\n",
    "        prediction = None\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Baseline n-grams On the Sample Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T17:32:44.615245400Z",
     "start_time": "2023-12-21T17:32:44.605229500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: After forcefully breaking into the bank, they |\n",
      "Suggestions: {'are': 0.3346073933449349, \"'re\": 0.30994814463253, 'do': 0.12743342298159574, 'have': 0.12373499270509238, 'will': 0.104276046335847}\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: In my family, there is my |\n",
      "Suggestions: {'favorite': 0.5853830605651704, 'first': 0.1888119327439376, 'favourite': 0.0983645108370054, 'new': 0.06445652599929452, 'opinion': 0.06298396985459208}\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: Every |, my family and I visit Hawaii.\n",
      "Suggestions: {'time': 0.3896827529049508, 'day': 0.23419787074369317, 'single': 0.18737812391879125, 'other': 0.1147109820572633, 'year': 0.0740302703753015}\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: My favorite | is apple.\n",
      "Suggestions: {'.': 0.33868374032162, 'part': 0.25645473496128646, 'is': 0.17503722453841572, ',': 0.12518612269207863, 'thing': 0.10463817748659916}\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: It has been 2 months since I graduated. However, unfortunately I still haven't found a | rate I won't be able to pay rent!\n",
      "Suggestions: {'way': 0.4054198728671797, 'new': 0.1742165718746515, 'few': 0.1631091780974685, 'good': 0.14767480762796922, 'lot': 0.10957956953273112}\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: Following the American Civil War, | assassinated.\n",
      "Suggestions: {'and': 0.39923997633459246, 'but': 0.24832749283211214, 'the': 0.16813816957174715, 'i': 0.09372866700040959, 'it': 0.09056569426113867}\n",
      "-=+=--=+=--=+=--=+=--=+=-\n"
     ]
    }
   ],
   "source": [
    "for sentence in test_sentences:\n",
    "    # out ngram model can only consider left context\n",
    "    input_text = sentence[:sentence.index(\"|\")].strip()\n",
    "    suggestions = get_ngram_prediction(input_text)\n",
    "\n",
    "    print('Sentence:', sentence)\n",
    "    print('Suggestions:', suggestions)\n",
    "    print(\"-=+=--=+=--=+=--=+=--=+=-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Baseline n-grams on \"Predict the Next Token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T17:36:51.974502800Z",
     "start_time": "2023-12-21T17:36:22.130391200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:29<00:00, 41.95it/s]\n"
     ]
    }
   ],
   "source": [
    "baseline_correct_guesses = 0\n",
    "baseline_total_guesses = 0\n",
    "baseline_inference_times = []\n",
    "\n",
    "for creation, post in tqdm(random_post_samples, smoothing=0):\n",
    "    sent_tokenized = sent_tokenize(normalize_text(post))\n",
    "    tokenized_words = [word_tokenize(sentence) for sentence in sent_tokenized]\n",
    "    tokenized_words = [word for s in tokenized_words for word in s]\n",
    "\n",
    "    for i in range(1, len(tokenized_words) - 1):\n",
    "        start_time = time.time()\n",
    "        current_prompt = ' '.join(tokenized_words[:i])\n",
    "        current_prompt = re.sub(r\" ([!.?,;:\\\"')\\]}]{1,9})\", r\"\\1\", current_prompt)\n",
    "        current_prompt = re.sub(r\"([\\[({]{1,9}) \", r\"\\1\", current_prompt)\n",
    "        actual_next_word = tokenized_words[i]\n",
    "\n",
    "        predictions = get_ngram_prediction(current_prompt)\n",
    "        if predictions is not None and actual_next_word in predictions:\n",
    "            baseline_correct_guesses += 1\n",
    "        baseline_total_guesses += 1\n",
    "\n",
    "        baseline_inference_times += [time.time() - start_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T17:37:05.216969400Z",
     "start_time": "2023-12-21T17:37:05.183749800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38662746585735963\n"
     ]
    }
   ],
   "source": [
    "baseline_accuracy = baseline_correct_guesses / baseline_total_guesses\n",
    "print(baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Inference Time: 0.022976395781948235\n",
      "Inference Std: 0.00535418975672332\n"
     ]
    }
   ],
   "source": [
    "print('Avg Inference Time:', statistics.mean(baseline_inference_times))\n",
    "print('Inference Std:', statistics.stdev(baseline_inference_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### T5-Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T18:40:47.422233Z",
     "start_time": "2023-12-21T18:40:46.030432200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the t5 model\n",
    "T5_path = 't5-small'\n",
    "t5_config = T5Config.from_pretrained(T5_path)\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(T5_path, legacy=False)\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(T5_path, config=t5_config).to(device)\n",
    "t5_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### T5-Small On the Sample Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T18:45:53.425747900Z",
     "start_time": "2023-12-21T18:45:53.267704800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8238, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(1733, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(33, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(130, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(56, device='cuda:0')\n",
      "torch.Size([512])\n",
      "Sentence: After forcefully breaking into the bank, they |\n",
      "Suggestions: [('<pad> <extra_id_0> broke', 0.22146426141262054), ('<pad> <extra_id_0> break', 0.21711385250091553), ('<pad> <extra_id_0> are', 0.21013765037059784), ('<pad> <extra_id_0> were', 0.17779791355133057), ('<pad> <extra_id_0> will', 0.1734863519668579)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "tensor(384, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(293, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(3062, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(2039, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(234, device='cuda:0')\n",
      "torch.Size([512])\n",
      "Sentence: In my family, there is my |\n",
      "Suggestions: [('<pad> <extra_id_0> family', 0.27247941493988037), ('<pad> <extra_id_0> own', 0.25976160168647766), ('<pad> <extra_id_0> daughter', 0.15796756744384766), ('<pad> <extra_id_0> mother', 0.1555204540491104), ('<pad> <extra_id_0> home', 0.1542709767818451)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "tensor(215, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(239, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(847, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(471, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(97, device='cuda:0')\n",
      "torch.Size([512])\n",
      "Sentence: Every |, my family and I visit Hawaii.\n",
      "Suggestions: [('<pad> <extra_id_0> year', 0.3100126087665558), ('<pad> <extra_id_0> day', 0.2699778378009796), ('<pad> <extra_id_0> month', 0.1532614529132843), ('<pad> <extra_id_0> week', 0.14059576392173767), ('<pad> <extra_id_0> time', 0.12615235149860382)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "tensor(8947, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(2728, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(589, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(6253, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(2696, device='cuda:0')\n",
      "torch.Size([512])\n",
      "Sentence: My favorite | is apple.\n",
      "Suggestions: [('<pad> <extra_id_0> apple', 0.469388872385025), ('<pad> <extra_id_0> fruit', 0.16375479102134705), ('<pad> <extra_id_0> thing', 0.15048746764659882), ('<pad> <extra_id_0> pie', 0.11327831447124481), ('<pad> <extra_id_0> recipe', 0.10309050232172012)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "tensor(3170, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(1080, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(3599, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(3571, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(2667, device='cuda:0')\n",
      "torch.Size([512])\n",
      "Sentence: It has been 2 months since I graduated. However, unfortunately I still haven't found a | rate I won't be able to pay rent!\n",
      "Suggestions: [('<pad> <extra_id_0> rent', 0.24719730019569397), ('<pad> <extra_id_0> rate', 0.22261090576648712), ('<pad> <extra_id_0> fixed', 0.21800415217876434), ('<pad> <extra_id_0> rental', 0.16750206053256989), ('<pad> <extra_id_0> flat', 0.1446855515241623)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "tensor(8, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(3, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(797, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(186, device='cuda:0')\n",
      "torch.Size([512])\n",
      "tensor(46, device='cuda:0')\n",
      "torch.Size([512])\n",
      "Sentence: Following the American Civil War, | assassinated.\n",
      "Suggestions: [('<pad> <extra_id_0> the', 0.314527302980423), ('<pad> <extra_id_0> ', 0.2124253213405609), ('<pad> <extra_id_0> American', 0.2062595784664154), ('<pad> <extra_id_0> many', 0.13480444252490997), ('<pad> <extra_id_0> an', 0.13198336958885193)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n"
     ]
    }
   ],
   "source": [
    "for sentence in test_sentences:\n",
    "\n",
    "    input_text = sentence.replace(\"|\", \"<extra_id_0>\")\n",
    "    input_ids = t5_tokenizer(input_text, return_tensors=\"pt\").to(device).input_ids\n",
    "\n",
    "    # Generate predictions for the next token\n",
    "    num_samples = 5\n",
    "    with torch.no_grad():\n",
    "        output = t5_model.generate(\n",
    "            input_ids,\n",
    "            num_beams=num_samples,\n",
    "            min_new_tokens=2,\n",
    "            max_new_tokens=2,\n",
    "            num_return_sequences=num_samples,  # Generate multiple suggestions\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(output.sequences_scores, dim=-1)\n",
    "\n",
    "    # Decode and print the predicted token\n",
    "    suggestions = []\n",
    "    for sample_output, prob in zip(output.sequences, probabilities):\n",
    "        decoded_output = t5_tokenizer.decode(sample_output, skip_special_tokens=False)\n",
    "        suggestions += [(decoded_output, prob.item())]\n",
    "    print('Sentence:', sentence)\n",
    "    print('Suggestions:', suggestions)\n",
    "    print(\"-=+=--=+=--=+=--=+=--=+=-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### T5-Small on \"Predict the Next Token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T19:04:55.703081Z",
     "start_time": "2023-12-21T19:04:55.612548200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16497]\n",
      "[21353]\n",
      "tensor(730.3172, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: DELETE ME\n",
    "\n",
    "w1 = 'lol'\n",
    "w2 = 'quantum'\n",
    "\n",
    "def remove_special_tokens(token_list: List):\n",
    "    to_remove = []\n",
    "    for elem in token_list:\n",
    "        if elem in {0, 1, 2, 3, 32099}:\n",
    "            to_remove += [elem]\n",
    "    for elem in to_remove:\n",
    "        token_list.remove(elem)\n",
    "    return to_remove\n",
    "\n",
    "#print(t5_model.shared(sample_output[2]))\n",
    "w1_e = t5_tokenizer.encode(w1, return_tensors=\"pt\").to(device)[0].cpu().numpy().tolist()\n",
    "w2_e = t5_tokenizer.encode(w2, return_tensors=\"pt\").to(device)[0].cpu().numpy().tolist()\n",
    "remove_special_tokens(w1_e)\n",
    "remove_special_tokens(w2_e)\n",
    "print(w1_e)\n",
    "print(w2_e)\n",
    "\n",
    "w1_vec = t5_model.shared(torch.tensor(w1_e, device=device))\n",
    "w2_vec = t5_model.shared(torch.tensor(w2_e, device=device))\n",
    "print(torch.norm(w1_vec - w2_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T19:07:25.738568700Z",
     "start_time": "2023-12-21T19:06:49.107531700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▏                                                                                                                                                                    | 24/1250 [00:10<09:21,  2.18it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "  2%|████                                                                                                                                                                    | 30/1250 [00:36<24:31,  1.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# generate one word at a time\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[0;32m---> 24\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mt5_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Generate multiple suggestions\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(output\u001b[38;5;241m.\u001b[39msequences_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Decode and print the predicted token\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1752\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1746\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1747\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1748\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1750\u001b[0m     )\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# 13. run beam search\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE:\n\u001b[1;32m   1766\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config)\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/generation/utils.py:3091\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3087\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   3089\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 3091\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3096\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3099\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1746\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1746\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1761\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1113\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1099\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1100\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         output_attentions,\n\u001b[1;32m   1111\u001b[0m     )\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1113\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:694\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    704\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:601\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    592\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    599\u001b[0m ):\n\u001b[1;32m    600\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 601\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    611\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:543\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    541\u001b[0m         position_bias\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 543\u001b[0m     position_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_seq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# if key and values are already calculated\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;66;03m# we want only the last query position bias\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:443\u001b[0m, in \u001b[0;36mT5Attention.compute_bias\u001b[0;34m(self, query_length, key_length, device)\u001b[0m\n\u001b[1;32m    441\u001b[0m memory_position \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(key_length, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m    442\u001b[0m relative_position \u001b[38;5;241m=\u001b[39m memory_position \u001b[38;5;241m-\u001b[39m context_position  \u001b[38;5;66;03m# shape (query_length, key_length)\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m relative_position_bucket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_relative_position_bucket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# shape (query_length, key_length)\u001b[39;49;00m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_decoder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_buckets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_attention_num_buckets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_attention_max_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_attention_bias(relative_position_bucket)  \u001b[38;5;66;03m# shape (query_length, key_length, num_heads)\u001b[39;00m\n\u001b[1;32m    450\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mpermute([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (1, num_heads, query_length, key_length)\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:416\u001b[0m, in \u001b[0;36mT5Attention._relative_position_bucket\u001b[0;34m(relative_position, bidirectional, num_buckets, max_distance)\u001b[0m\n\u001b[1;32m    414\u001b[0m     relative_position \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(relative_position)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     relative_position \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmin(relative_position, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelative_position\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# now relative_position is in the range [0, inf)\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# half of the buckets are for exact increments in positions\u001b[39;00m\n\u001b[1;32m    420\u001b[0m max_exact \u001b[38;5;241m=\u001b[39m num_buckets \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t5_correct_guesses = 0\n",
    "t5_total_guesses = 0\n",
    "t5_inference_times = []\n",
    "\n",
    "for creation, post in tqdm(random_post_samples, smoothing=0):\n",
    "    sent_tokenized = sent_tokenize(normalize_text(post))\n",
    "    tokenized_words = [word_tokenize(sentence) for sentence in sent_tokenized]\n",
    "    tokenized_words = [word for s in tokenized_words for word in s]\n",
    "    for i in range(1, len(tokenized_words) - 1):\n",
    "        start_time = time.time()\n",
    "        current_prompt = ' '.join(tokenized_words[:i]) + \" <extra_id_0>\"\n",
    "        current_prompt = re.sub(r\" ([!.?,;:\\\"')\\]}]{1,9})\", r\"\\1\", current_prompt)\n",
    "        current_prompt = re.sub(r\"([\\[({]{1,9}) \", r\"\\1\", current_prompt)\n",
    "        actual_next_word = tokenized_words[i]\n",
    "        input_ids = t5_tokenizer(current_prompt, return_tensors=\"pt\").to(device).input_ids\n",
    "        # t5 can only accept up to 512 tokens so if our tensor is bigger than this\n",
    "        # we trim it before passing into the model\n",
    "        if input_ids[0].shape[0] > 512:\n",
    "            input_ids = input_ids[:, -512:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # generate one word at a time\n",
    "            num_samples = 7\n",
    "            output = t5_model.generate(\n",
    "                input_ids,\n",
    "                num_beams=num_samples,\n",
    "                min_new_tokens=2,\n",
    "                max_new_tokens=2,\n",
    "                num_return_sequences=num_samples,  # Generate multiple suggestions\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            )\n",
    "\n",
    "        probabilities = torch.nn.functional.softmax(output.sequences_scores, dim=-1)\n",
    "\n",
    "        # Decode and print the predicted token\n",
    "        suggestions = set()\n",
    "        for sample_output, prob in zip(output.sequences, probabilities):\n",
    "            if len(suggestions) >= 5:\n",
    "                break\n",
    "            decoded_output = t5_tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "            if decoded_output.strip() == '':\n",
    "                continue\n",
    "            suggestions.add(decoded_output)\n",
    "\n",
    "        if actual_next_word in suggestions:\n",
    "            t5_correct_guesses += 1\n",
    "        t5_total_guesses += 1\n",
    "        t5_inference_times += [time.time() - start_time]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T17:59:26.006531800Z",
     "start_time": "2023-12-21T17:59:26.001529100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37467754172989376\n"
     ]
    }
   ],
   "source": [
    "t5_accuracy = t5_correct_guesses / t5_total_guesses\n",
    "print(t5_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T17:59:26.198139Z",
     "start_time": "2023-12-21T17:59:26.007530800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Inference Time: 0.02229035642783812\n",
      "Inference Std: 0.0007565512458901443\n"
     ]
    }
   ],
   "source": [
    "print('Avg Inference Time:', statistics.mean(t5_inference_times))\n",
    "print('Inference Std:', statistics.stdev(t5_inference_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### T5-Small on \"Predict the Middle Token\"\n",
    "OK, predicting the next token is fun and all. But what if a user wants to add something to the middle of their sentence? Wouldn't it be nice to be able to both use left and right context?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T16:15:15.422994300Z",
     "start_time": "2023-12-11T16:15:15.419996100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "#### DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T18:04:34.651566200Z",
     "start_time": "2023-12-11T18:04:33.756145900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distbert_path = 'distilbert-base-cased'\n",
    "distbert_model = DistilBertForMaskedLM.from_pretrained(distbert_path).to(device=device)\n",
    "distbert_config = DistilBertConfig.from_pretrained(distbert_path)\n",
    "distbert_tokenizer = DistilBertTokenizer.from_pretrained(distbert_path, config=distbert_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### DistilBert On the Sample Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T16:15:16.485638800Z",
     "start_time": "2023-12-11T16:15:16.418844600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: After forcefully breaking into the bank, they |\n",
      "Suggestions: [('!', 7.7542314529418945), ('.', 7.455650806427002), ('escape', 6.470279693603516), (':', 6.367412567138672), ('find', 6.3458967208862305)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: In my family, there is my |\n",
      "Suggestions: [('heart', 6.815902233123779), ('destiny', 6.189598560333252), ('.', 6.164964199066162), ('love', 6.162736415863037), ('family', 6.145949363708496)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: Every |, my family and I visit Hawaii.\n",
      "Suggestions: [('##day', 6.442167282104492), ('day', 5.875978946685791), ('morning', 5.826064586639404), ('##night', 5.271539688110352), ('night', 5.13131046295166)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: My favorite | is apple.\n",
      "Suggestions: [('fruit', 11.054349899291992), ('apple', 10.834712028503418), ('tree', 10.448899269104004), ('grape', 8.978232383728027), ('vegetable', 8.545177459716797)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: It has been 2 months since I graduated. However, unfortunately I still haven't found a | rate I won't be able to pay rent!\n",
      "Suggestions: [('decent', 9.64558219909668), ('reasonable', 8.736651420593262), ('fixed', 7.847301006317139), ('satisfactory', 7.8360819816589355), ('flat', 7.648664474487305)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: Following the American Civil War, | assassinated.\n",
      "Suggestions: [('many', 5.271701812744141), ('he', 4.914363384246826), ('soldiers', 3.7219643592834473), ('rebels', 3.6212308406829834), ('others', 3.600987672805786)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: After forcefully breaking into the bank, they |\n",
      "Suggestions: [('!', 7.7542314529418945), ('.', 7.455650806427002), ('escape', 6.470279693603516), (':', 6.367412567138672), ('find', 6.3458967208862305)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: In my family, there is my |\n",
      "Suggestions: [('heart', 6.815902233123779), ('destiny', 6.189598560333252), ('.', 6.164964199066162), ('love', 6.162736415863037), ('family', 6.145949363708496)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: Every |, my family and I visit Hawaii.\n",
      "Suggestions: [('##day', 6.442167282104492), ('day', 5.875978946685791), ('morning', 5.826064586639404), ('##night', 5.271539688110352), ('night', 5.13131046295166)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: My favorite | is apple.\n",
      "Suggestions: [('fruit', 11.054349899291992), ('apple', 10.834712028503418), ('tree', 10.448899269104004), ('grape', 8.978232383728027), ('vegetable', 8.545177459716797)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: It has been 2 months since I graduated. However, unfortunately I still haven't found a | rate I won't be able to pay rent!\n",
      "Suggestions: [('decent', 9.64558219909668), ('reasonable', 8.736651420593262), ('fixed', 7.847301006317139), ('satisfactory', 7.8360819816589355), ('flat', 7.648664474487305)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n",
      "Sentence: Following the American Civil War, | assassinated.\n",
      "Suggestions: [('many', 5.271701812744141), ('he', 4.914363384246826), ('soldiers', 3.7219643592834473), ('rebels', 3.6212308406829834), ('others', 3.600987672805786)]\n",
      "-=+=--=+=--=+=--=+=--=+=-\n"
     ]
    }
   ],
   "source": [
    "for sentence in test_sentences:\n",
    "\n",
    "    input_text = sentence.replace(\"|\", \"[MASK]\")\n",
    "    input_ids = distbert_tokenizer(input_text, return_tensors=\"pt\").to(device).input_ids\n",
    "\n",
    "    # Get the position of the masked token\n",
    "    mask_token_index = torch.where(input_ids == distbert_tokenizer.mask_token_id)[1].tolist()[0]\n",
    "\n",
    "    # Generate predictions for the next token\n",
    "    with torch.no_grad():\n",
    "        output = distbert_model(input_ids)\n",
    "        predictions = output.logits\n",
    "\n",
    "    # Get the top-k predicted tokens and their probabilities\n",
    "    top_k = 5  # Adjust as needed\n",
    "    probs, indices = torch.topk(predictions[0, mask_token_index], k=top_k, dim=-1)\n",
    "\n",
    "    # Convert indices back to tokens\n",
    "    predicted_tokens = distbert_tokenizer.convert_ids_to_tokens(indices.tolist())\n",
    "\n",
    "    # Decode and print the predicted token\n",
    "    suggestions = []\n",
    "    for sample_output, prob in zip(predicted_tokens, probs.tolist()):\n",
    "        suggestions += [(sample_output, prob)]\n",
    "    print('Sentence:', sentence)\n",
    "    print('Suggestions:', suggestions)\n",
    "    print(\"-=+=--=+=--=+=--=+=--=+=-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### DistilBert on \"Predict the Next Token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T17:00:14.923844Z",
     "start_time": "2023-12-11T16:55:59.910583900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [04:14<00:00,  4.90it/s]\n"
     ]
    }
   ],
   "source": [
    "distbert_correct_guesses = 0\n",
    "distbert_total_guesses = 0\n",
    "distbert_inference_times = []\n",
    "\n",
    "for creation, post in tqdm(random_post_samples, smoothing=0):\n",
    "\n",
    "    sent_tokenized = sent_tokenize(normalize_text(post))\n",
    "    tokenized_words = [word_tokenize(sentence) for sentence in sent_tokenized]\n",
    "    tokenized_words = [word for s in tokenized_words for word in s]\n",
    "    for i in range(1, len(tokenized_words) - 1):\n",
    "        start_time = time.time()\n",
    "        current_prompt = ' '.join(tokenized_words[:i]) + \" [MASK]\"\n",
    "        current_prompt = re.sub(r\" ([!.?,;:\\\"')\\]}]{1,9})\", r\"\\1\", current_prompt)\n",
    "        current_prompt = re.sub(r\"([\\[({]{1,9}) \", r\"\\1\", current_prompt)\n",
    "        actual_next_word = tokenized_words[i]\n",
    "        input_ids: torch.Tensor = distbert_tokenizer(current_prompt, return_tensors=\"pt\").to(device).input_ids\n",
    "        # bert can only accept up to 512 tokens so if our tensor is bigger than this\n",
    "        # we trim it before passing into the model\n",
    "        if input_ids[0].shape[0] > 512:\n",
    "            input_ids = input_ids[:, -512:]\n",
    "        # Get the position of the masked token\n",
    "        mask_token_index = torch.where(input_ids == distbert_tokenizer.mask_token_id)[1].tolist()[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # generate one word at a time\n",
    "            output = distbert_model(input_ids)\n",
    "            predictions = output.logits\n",
    "\n",
    "        # Get the top-k predicted tokens and their probabilities\n",
    "        top_k = 8  # Adjust as needed\n",
    "        probs, indices = torch.topk(predictions[0, mask_token_index], k=top_k, dim=-1)\n",
    "\n",
    "        # Convert indices back to tokens\n",
    "        predicted_tokens = distbert_tokenizer.convert_ids_to_tokens(indices.tolist())\n",
    "\n",
    "        # Decode and print the predicted token\n",
    "        suggestions = set()\n",
    "        for decoded_output, prob in zip(predicted_tokens, probs.tolist()):\n",
    "            if len(suggestions) >= 5:\n",
    "                break\n",
    "            if prob < 0.04:\n",
    "                # avoid bizarre suggestions by simply filtering out low prob\n",
    "                # terms. We don't HAVE TO suggest exactly 5 words\n",
    "                break\n",
    "            # bert also suggests \"sub-words\". Ehh... we'll just ignore those.\n",
    "            # otherwise stuff will get too complicated\n",
    "            if decoded_output.startswith(\"##\"):\n",
    "                continue\n",
    "            if decoded_output.strip() == '':\n",
    "                continue\n",
    "            suggestions.add(decoded_output)\n",
    "\n",
    "        if actual_next_word in suggestions:\n",
    "            distbert_correct_guesses += 1\n",
    "        # since the way the bert tokenizer works, it can suggest \"sub-words\" - example: characteristically = characteristic + ##ally,\n",
    "        # so we will give bert half a point for suggest the same start of the word\n",
    "        for s in suggestions:\n",
    "            if actual_next_word.startswith(s):\n",
    "                distbert_correct_guesses += 0.5\n",
    "                break\n",
    "        distbert_total_guesses += 1\n",
    "        distbert_inference_times += [time.time() - start_time]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T17:00:20.001862900Z",
     "start_time": "2023-12-11T17:00:19.985839900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18298021889747967\n"
     ]
    }
   ],
   "source": [
    "bert_accuracy = distbert_correct_guesses / distbert_total_guesses\n",
    "print(bert_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T17:00:22.286787800Z",
     "start_time": "2023-12-11T17:00:22.234767400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Inference Time: 0.005107757104114663\n",
      "Inference Std: 0.001992808943326104\n"
     ]
    }
   ],
   "source": [
    "print('Avg Inference Time:', statistics.mean(distbert_inference_times))\n",
    "print('Inference Std:', statistics.stdev(distbert_inference_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### DistilBert on \"Predict the Middle Token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Distil-GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T04:38:30.807975100Z",
     "start_time": "2023-12-22T04:38:30.385562200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose the GPT-2 model variant\n",
    "distgpt2_model_name = \"distilgpt2\"\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "distgpt2_model: GPT2LMHeadModel = GPT2LMHeadModel.from_pretrained(distgpt2_model_name)\n",
    "distgpt2_tokenizer: PreTrainedTokenizerBase = GPT2Tokenizer.from_pretrained(distgpt2_model_name)\n",
    "# Move the model to the GPU (if available)\n",
    "distgpt2_model = distgpt2_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T19:09:22.420843400Z",
     "start_time": "2023-12-21T19:09:21.863161400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: After forcefully breaking into the bank, they |\n",
      "Suggestions: [(' were', 0.6859785914421082), (' found', 0.10938050597906113), (' had', 0.08820205926895142), (' took', 0.059164125472307205), (' began', 0.05727475509047508)]\n",
      "Sentence: In my family, there is my |\n",
      "Suggestions: [(' family', 0.27839019894599915), (' brother', 0.2245674729347229), (' mother', 0.18426108360290527), (' sister', 0.1591966301202774), (' wife', 0.1535845696926117)]\n",
      "Sentence: Every |, my family and I visit Hawaii.\n",
      "Suggestions: [(' The', 0.40960025787353516), ('.', 0.16524524986743927), (' A', 0.15191836655139923), ('\\n', 0.13858996331691742), ('The', 0.13464611768722534)]\n",
      "Sentence: My favorite | is apple.\n",
      "Suggestions: [(' favorite', 0.44314318895339966), (' part', 0.18813173472881317), (' thing', 0.16900213062763214), (' of', 0.11418430507183075), ('.', 0.08553868532180786)]\n",
      "Sentence: It has been 2 months since I graduated. However, unfortunately I still haven't found a | rate I won't be able to pay rent!\n",
      "Suggestions: [(' way', 0.38864630460739136), (' job', 0.33211749792099), (' place', 0.1317850798368454), (' new', 0.09153558313846588), (' good', 0.055915530771017075)]\n",
      "Sentence: Following the American Civil War, | assassinated.\n",
      "Suggestions: [(' the', 0.7203230857849121), (' a', 0.11123217642307281), (' it', 0.07635104656219482), (' and', 0.05197402089834213), (' in', 0.04011968895792961)]\n"
     ]
    }
   ],
   "source": [
    "for sentence in test_sentences:\n",
    "    # delete everything including and after |\n",
    "    # GPT2 is physically unable to consider right context\n",
    "    input_text = sentence[:sentence.index(\"|\")].strip()\n",
    "    # Tokenize the prompt\n",
    "    input_ids = distgpt2_tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    # Generate probabilities for the next words\n",
    "    with torch.no_grad():\n",
    "        outputs = distgpt2_model(input_ids)\n",
    "        logits = outputs.logits\n",
    "    # we are only interested in either the top 5 words or words with a probability of > 1%\n",
    "    # after all, we don't want to suggest too many words!\n",
    "    top_k = 5\n",
    "    # Get the probability distribution for the next word\n",
    "    next_word_probs = torch.nn.functional.softmax(logits[:, -1, :], dim=-1)\n",
    "    top_k_values, top_k_indices = torch.topk(next_word_probs, k=top_k, dim=-1)\n",
    "    # Normalize probabilities\n",
    "    top_k_probs_normalized = top_k_values / top_k_values.sum()\n",
    "\n",
    "    # Convert the probabilities to a list\n",
    "    top_k_probs_list: List = top_k_probs_normalized.tolist()[0]\n",
    "    top_k_indices_list: List = top_k_indices.tolist()[0]\n",
    "\n",
    "    # Decode and print the predicted token\n",
    "    suggestions = []\n",
    "    for sample_output, prob in zip(top_k_indices_list, top_k_probs_list):\n",
    "        decoded_output = distgpt2_tokenizer.decode(sample_output)\n",
    "        suggestions += [(decoded_output, prob)]\n",
    "    print('Sentence:', sentence)\n",
    "    print('Suggestions:', suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T19:07:41.365317200Z",
     "start_time": "2023-12-21T19:07:40.619814600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                 | 0/1250 [00:00<?, ?it/s]../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [142,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [84,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [141,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "  0%|                                                                                                                                                                                 | 0/1250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Generate probabilities for the next words\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 32\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdistgpt2_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# we are only interested in either the top 5 words or words with a probability of > 1%\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# after all, we don't want to suggest too many words!\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1074\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1074\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:888\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    876\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    877\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    878\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    885\u001b[0m         output_attentions,\n\u001b[1;32m    886\u001b[0m     )\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:390\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    388\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    389\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 390\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    399\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:331\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    329\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_heads(attn_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    334\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(attn_output)\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:201\u001b[0m, in \u001b[0;36mGPT2Attention._attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    198\u001b[0m     mask_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfinfo(attn_weights\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mmin\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     mask_value \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(causal_mask, attn_weights\u001b[38;5;241m.\u001b[39mto(attn_weights\u001b[38;5;241m.\u001b[39mdtype), mask_value)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# Apply the attention mask\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "distilgpt2_correct_predictions = 0\n",
    "distilgpt2_total_predictions = 0\n",
    "distilgpt2_inference_times = []\n",
    "\n",
    "#distgpt2_tokenizer.pad_token = distgpt2_tokenizer.eos_token\n",
    "distgpt2_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "for creation, post in tqdm(random_post_samples, smoothing=0):\n",
    "    sent_tokenized = sent_tokenize(normalize_text(post))\n",
    "    tokenized_words = [word_tokenize(sentence) for sentence in sent_tokenized]\n",
    "    tokenized_words = [word for s in tokenized_words for word in s]\n",
    "\n",
    "    current_batch_prompt = []\n",
    "    current_batch_answer = []\n",
    "    for i in range(1, len(tokenized_words) - 1):\n",
    "        start_time = time.time()\n",
    "        current_prompt = ' '.join(tokenized_words[:i]).strip()\n",
    "        current_prompt = re.sub(r\" ([!.?,;:\\\"')\\]}]{1,9})\", r\"\\1\", current_prompt)\n",
    "        current_prompt = re.sub(r\"([\\[({]{1,9}) \", r\"\\1\", current_prompt)\n",
    "        actual_next_word = tokenized_words[i]\n",
    "        current_batch_prompt += [current_prompt]\n",
    "        current_batch_answer += [actual_next_word]\n",
    "\n",
    "        assert len(current_batch_prompt) == len(current_batch_answer)\n",
    "        if len(current_batch_prompt) < 8:\n",
    "            continue\n",
    "\n",
    "        # Tokenize the prompt\n",
    "        input_ids = distgpt2_tokenizer.batch_encode_plus(current_batch_prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024, truncation_strategy=\"longest_first\").input_ids.to(device)\n",
    "\n",
    "        # Generate probabilities for the next words\n",
    "        with torch.no_grad():\n",
    "            outputs = distgpt2_model(input_ids)\n",
    "            logits = outputs.logits\n",
    "        # we are only interested in either the top 5 words or words with a probability of > 1%\n",
    "        # after all, we don't want to suggest too many words!\n",
    "        top_k = 5\n",
    "        top_p = 0.04  # don't suggest 5 words just for the sake of suggesting 5 words\n",
    "        # Get the probability distribution for the next word\n",
    "        next_word_probs = torch.nn.functional.softmax(logits[:, -1, :], dim=-1)\n",
    "        top_k_values, top_k_indices = torch.topk(next_word_probs, k=top_k, dim=-1)\n",
    "        # Normalize probabilities\n",
    "        top_k_probs_normalized = top_k_values / top_k_values.sum()\n",
    "        # Convert the probabilities to a list\n",
    "        top_k_probs_list: List = top_k_probs_normalized.tolist()\n",
    "        top_k_indices_list: List = top_k_indices.tolist()\n",
    "\n",
    "        # for each element in the batch\n",
    "        for current_prompt, top_k_probs, top_k_indices, actual_next_word in zip(current_batch_prompt, top_k_probs_list, top_k_indices_list, current_batch_answer):\n",
    "\n",
    "            guesses = set()\n",
    "            for token_id, prob in zip(top_k_indices, top_k_probs):\n",
    "                # ignore bizarre suggestions\n",
    "                if prob < top_p:\n",
    "                    continue\n",
    "                token = distgpt2_tokenizer.decode([token_id])\n",
    "                guesses.add(token)\n",
    "\n",
    "            # we consider a prediction correct if the actual word was\n",
    "            # one of the (up to) 5 words suggested\n",
    "            if (' ' + actual_next_word) in guesses:\n",
    "                distilgpt2_correct_predictions += 1\n",
    "            distilgpt2_total_predictions += 1\n",
    "\n",
    "            print('prompt:', current_prompt)\n",
    "            print('suggestions:', guesses)\n",
    "            print('answer:', actual_next_word)\n",
    "\n",
    "        distilgpt2_inference_times += [time.time() - start_time]\n",
    "        # clear the batch\n",
    "        current_batch_prompt = []\n",
    "        current_batch_answer = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T19:13:50.059494800Z",
     "start_time": "2023-12-21T19:09:27.834935Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████████████████████████████████▌                                                                                           | 566/1250 [01:41<02:03,  5.56it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [04:22<00:00,  4.77it/s]\n"
     ]
    }
   ],
   "source": [
    "distilgpt2_correct_predictions = 0\n",
    "distilgpt2_total_predictions = 0\n",
    "distilgpt2_inference_times = []\n",
    "\n",
    "for creation, post in tqdm(random_post_samples, smoothing=0):\n",
    "    sent_tokenized = sent_tokenize(normalize_text(post))\n",
    "    tokenized_words = [word_tokenize(sentence) for sentence in sent_tokenized]\n",
    "    tokenized_words = [word for s in tokenized_words for word in s]\n",
    "    for i in range(1, len(tokenized_words) - 1):\n",
    "        start_time = time.time()\n",
    "        current_prompt = ' '.join(tokenized_words[:i])\n",
    "        current_prompt = re.sub(r\" ([!.?,;:\\\"')\\]}]{1,9})\", r\"\\1\", current_prompt)\n",
    "        current_prompt = re.sub(r\"([\\[({]{1,9}) \", r\"\\1\", current_prompt)\n",
    "        actual_next_word = tokenized_words[i]\n",
    "        # Tokenize the prompt\n",
    "        input_ids = distgpt2_tokenizer.encode(current_prompt, return_tensors=\"pt\").to(device)\n",
    "        if input_ids.shape[1] == 0:\n",
    "            continue\n",
    "        # gpt2 can only accept up to 1024 tokens so if our tensor is bigger than this\n",
    "        # we trim it before passing into the model\n",
    "        if input_ids[0].shape[0] > 1024:\n",
    "            input_ids = input_ids[:, -1024:]\n",
    "        # Generate probabilities for the next words\n",
    "        with torch.no_grad():\n",
    "            outputs = distgpt2_model(input_ids)\n",
    "            logits = outputs.logits\n",
    "        # we are only interested in either the top 5 words or words with a probability of > 1%\n",
    "        # after all, we don't want to suggest too many words!\n",
    "        top_k = 5\n",
    "        top_p = 0.04  # don't suggest 5 words just for the sake of suggesting 5 words\n",
    "        # Get the probability distribution for the next word\n",
    "        next_word_probs = torch.nn.functional.softmax(logits[:, -1, :], dim=-1)\n",
    "        top_k_values, top_k_indices = torch.topk(next_word_probs, k=top_k, dim=-1)\n",
    "        # Normalize probabilities\n",
    "        top_k_probs_normalized = top_k_values / top_k_values.sum()\n",
    "\n",
    "        # Convert the probabilities to a list\n",
    "        top_k_probs_list: List = top_k_probs_normalized.tolist()[0]\n",
    "        top_k_indices_list: List = top_k_indices.tolist()[0]\n",
    "\n",
    "        # filter to only words with a probability greater than p%\n",
    "        removal_marked = []\n",
    "        for j in range(len(top_k_probs_list)):\n",
    "            if top_k_probs_list[j] < top_p:\n",
    "                removal_marked += [(top_k_probs_list[j], top_k_indices_list[j])]\n",
    "\n",
    "        for to_remove in removal_marked:\n",
    "            top_k_probs_list.remove(to_remove[0])\n",
    "            top_k_indices_list.remove(to_remove[1])\n",
    "\n",
    "        guesses = set()\n",
    "        for token_id, prob in zip(top_k_indices_list, top_k_probs_list):\n",
    "            token = distgpt2_tokenizer.decode([token_id])\n",
    "            guesses.add(token)\n",
    "\n",
    "        # we consider a prediction correct if the actual word was\n",
    "        # one of the (up to) 5 words suggested\n",
    "        if ' ' + actual_next_word in guesses:\n",
    "            distilgpt2_correct_predictions += 1\n",
    "        distilgpt2_total_predictions += 1\n",
    "        distilgpt2_inference_times += [time.time() - start_time]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T19:13:50.064494100Z",
     "start_time": "2023-12-21T19:13:50.062513200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36095087922396757\n"
     ]
    }
   ],
   "source": [
    "gpt2_accuracy = distilgpt2_correct_predictions / distilgpt2_total_predictions\n",
    "print(gpt2_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T19:13:50.153521100Z",
     "start_time": "2023-12-21T19:13:50.064494100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Inference Time: 0.0052210369432941625\n",
      "Inference Std: 0.002328083751368582\n"
     ]
    }
   ],
   "source": [
    "print('Avg Inference Time:', statistics.mean(distilgpt2_inference_times))\n",
    "print('Inference Std:', statistics.stdev(distilgpt2_inference_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Summary of the results from Model Comparison\n",
    "\n",
    "* T5 was the slowest model\n",
    "GPU\n",
    "* 24:39 - T5-Small\n",
    "* 5:10 - DistilBert\n",
    "* 5:32 - DistilGPT2\n",
    "CPU\n",
    "* 3:19:43: T5-Small\n",
    "* 1:41:39 - DistilBert\n",
    "* 2:29:33 - DistilGPT2\n",
    "Accuracy:\n",
    "* 37.27% - T5-Small\n",
    "* 17.73% - DistilBert\n",
    "* 35.86% - DistilGPT2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### The Problem of Catastrophic Forgetting\n",
    "So far, in the examples we have tested, we have trained our model on the entire dataset at ones (as opposed to training the model on the data sequentially). That is, in the real world, in the type of application we want to develop, our model would be exposed to snippets of data over a long period of time. However, this introduces the problem of \"catastrophic forgetting\" where the model, while optimizing the weights on the new data forgets about the old tasks it learned to do.\n",
    "\n",
    "To overcome this problem, we turn to DeepMind research paper titled [\"Overcoming catastrophic forgetting in neural networks\"](https://arxiv.org/abs/1612.00796). This paper arrives upon 3 key insights to help develop an algorithm for the aforementioned problem:\n",
    "1. Many optimal configurations of the set of weights and biases θ exist.\n",
    "2. It is likely that one those optimal configurations is close to the previous learned tasks.\n",
    "3. It is therefore possible to constraint parameters to stay in a region of low error for previous learned tasks during training.\n",
    "\n",
    "Inspired by biological mechanisms found in real life, the paper refers to this algorithm as elastic weight consolidation (EWC). EWC is essentially a new loss function. This is exactly what we are looking for because:\n",
    "1. Ofcourse now we can learn new tasks with out forgetting the others.\n",
    "2. EWC allows us to define the importance of each tasks relative to each other. In theory, this means we could classify more recent examples as more important! This gives us a lot of power.\n",
    "3. EWC can be trained for an arbitrary number of new tasks.\n",
    "\n",
    "https://github.com/moskomule/ewc.pytorch/blob/master/demo.ipynb\n",
    "https://github.com/kuc2477/pytorch-ewc\n",
    "https://github.com/ContinualAI/colab/blob/master/notebooks/intro_to_continual_learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:23:40.934383700Z",
     "start_time": "2023-12-22T20:23:40.920383Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The_Jackal'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly select a user to train with\n",
    "random_user = random.choice(list(author_to_posts_dict.keys()))\n",
    "random_user = 'The_Jackal'\n",
    "random_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:23:41.302954600Z",
     "start_time": "2023-12-22T20:23:41.261676900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3787"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entire_dataset_list = user_posts_corrected\n",
    "# filter out posts with just a single word\n",
    "entire_dataset_list = [data for data in entire_dataset_list if len(data[1].split(\" \")) > 1]\n",
    "\n",
    "entire_dataset_list = [{\"post\": x[1], \"time\": x[0]} for x in entire_dataset_list]\n",
    "len(entire_dataset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:23:42.825283400Z",
     "start_time": "2023-12-22T20:23:41.715374300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 89805\n"
     ]
    }
   ],
   "source": [
    "total_words = 0\n",
    "for data_entry in entire_dataset_list:\n",
    "    post = data_entry[\"post\"]\n",
    "    sent_tokenized = sent_tokenize(normalize_text(post))\n",
    "    tokenized_words = [word_tokenize(sentence) for sentence in sent_tokenized]\n",
    "    tokenized_words = [word for s in tokenized_words for word in s]\n",
    "    total_words += len(tokenized_words)\n",
    "print('Total words:', total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:23:43.724450800Z",
     "start_time": "2023-12-22T20:23:43.715449400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort the list based on the \"time\" key\n",
    "entire_dataset_list = sorted(entire_dataset_list, key=lambda x: x[\"time\"])\n",
    "# make sure data is ordered by time\n",
    "prev = None\n",
    "for data in entire_dataset_list:\n",
    "    assert prev is None or data['time'] >= prev['time'], f\"Prev:{prev}, Current:{data}\"\n",
    "    prev = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:23:44.401828300Z",
     "start_time": "2023-12-22T20:23:44.371264300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entire_dataset = Dataset.from_list(entire_dataset_list)\n",
    "split_sets = entire_dataset.train_test_split(train_size=0.85, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:23:45.085604Z",
     "start_time": "2023-12-22T20:23:45.053590800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['post', 'time'],\n",
       "        num_rows: 3218\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['post', 'time'],\n",
       "        num_rows: 569\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:23:47.101892600Z",
     "start_time": "2023-12-22T20:23:46.888323500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d747fb4c5034a25b32a761956dc65b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3218 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e94054dcd7478d85c3c01c05b216bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/569 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_sets.save_to_disk(f\"{data_dir}/dataset-{random_user}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:23:50.698514300Z",
     "start_time": "2023-12-22T20:23:47.712878Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 3218\n",
      "Validation dataset size: 569\n",
      "Example from training dataset: {'post': 'Croatia is a beautiful country. As a result, Croatia is in the world. Only been to Croatian night, in a quatrain.', 'time': '1316851713'}\n",
      "Example from validation dataset: {'post': 'That is utter crap. . It was quite clear to everyone what was going on, who was represented and where he was heading.', 'time': '1309203597'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "\n",
    "model_name = \"distilgpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model_original = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trained_dataset = load_from_disk(f\"{data_dir}/dataset-{random_user}\")['train']\n",
    "validation_dataset = load_from_disk(f\"{data_dir}/dataset-{random_user}\")['test']\n",
    "\n",
    "print(\"Training dataset size:\", len(trained_dataset))\n",
    "print(\"Validation dataset size:\", len(validation_dataset))\n",
    "print(\"Example from training dataset:\", trained_dataset[0])\n",
    "print(\"Example from validation dataset:\", validation_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:23:53.834355800Z",
     "start_time": "2023-12-22T20:23:50.696486600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8197d227c0294db4815451f1c798b082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3218 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b272503b55a84978a033dd6ae7c381fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/569 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def encode(batch):\n",
    "    return tokenizer([x.strip('\\n\\r') for x in batch['post']], truncation=True, padding=True)\n",
    "trained_dataset_processed = trained_dataset.map(encode, batched=True, batch_size=len(trained_dataset))\n",
    "trained_dataset_processed.set_format('torch', columns=['input_ids', 'attention_mask'])\n",
    "validation_dataset_processed = validation_dataset.map(encode, batched=True, batch_size=len(validation_dataset))\n",
    "validation_dataset_processed.set_format('torch', columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:23:58.441303600Z",
     "start_time": "2023-12-22T20:23:58.429230400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['post', 'time', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 3218\n",
       "})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_dataset_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:29:41.128423100Z",
     "start_time": "2023-12-22T20:24:16.724917Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1074' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/1074 : < :, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1074, training_loss=3.683864481178298, metrics={'train_runtime': 317.6142, 'train_samples_per_second': 20.264, 'train_steps_per_second': 3.381, 'total_flos': 1346678542172160.0, 'train_loss': 3.683864481178298, 'epoch': 2.0})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data collator for language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # we're not using masked language modeling here\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{data_dir}/gpt2-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=2,  # adjust as needed\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=12,\n",
    "    logging_steps=1,\n",
    "    save_steps=1_000,  # adjust as needed\n",
    "    save_total_limit=2,\n",
    "    weight_decay=0.01,\n",
    "    prediction_loss_only=True,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=trained_dataset_processed,\n",
    "    #eval_dataset=validation_dataset_processed,  #TODO\n",
    ")\n",
    "\n",
    "# Fine-tune the GPT-2 model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:29:41.136419400Z",
     "start_time": "2023-12-22T20:29:41.128423100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model_accuracy(test_model, data):\n",
    "    distilgpt2_correct_predictions = 0\n",
    "    distilgpt2_total_predictions = 0\n",
    "    distilgpt2_inference_times = []\n",
    "\n",
    "    for creation, post in tqdm(data, smoothing=0):\n",
    "        sent_tokenized = sent_tokenize(normalize_text(post))\n",
    "        tokenized_words = [word_tokenize(sentence) for sentence in sent_tokenized]\n",
    "        tokenized_words = [word for s in tokenized_words for word in s]\n",
    "        for i in range(1, len(tokenized_words) - 1):\n",
    "            start_time = time.time()\n",
    "            current_prompt = ' '.join(tokenized_words[:i])\n",
    "            current_prompt = re.sub(r\" ([!.?,;:\\\"')\\]}]{1,9})\", r\"\\1\", current_prompt)\n",
    "            current_prompt = re.sub(r\"([\\[({]{1,9}) \", r\"\\1\", current_prompt)\n",
    "            actual_next_word = tokenized_words[i]\n",
    "            # Tokenize the prompt\n",
    "            input_ids = distgpt2_tokenizer.encode(current_prompt, return_tensors=\"pt\").to(device)\n",
    "            if input_ids.shape[1] == 0:\n",
    "                continue\n",
    "            # gpt2 can only accept up to 1024 tokens so if our tensor is bigger than this\n",
    "            # we trim it before passing into the model\n",
    "            if input_ids[0].shape[0] > 1024:\n",
    "                input_ids = input_ids[:, -1024:]\n",
    "            # Generate probabilities for the next words\n",
    "            with torch.no_grad():\n",
    "                outputs = test_model(input_ids)\n",
    "                logits = outputs.logits\n",
    "            # we are only interested in either the top 5 words or words with a probability of > 1%\n",
    "            # after all, we don't want to suggest too many words!\n",
    "            top_k = 5\n",
    "            top_p = 0.04  # don't suggest 5 words just for the sake of suggesting 5 words\n",
    "            # Get the probability distribution for the next word\n",
    "            next_word_probs = torch.nn.functional.softmax(logits[:, -1, :], dim=-1)\n",
    "            top_k_values, top_k_indices = torch.topk(next_word_probs, k=top_k, dim=-1)\n",
    "            # Normalize probabilities\n",
    "            top_k_probs_normalized = top_k_values / top_k_values.sum()\n",
    "\n",
    "            # Convert the probabilities to a list\n",
    "            top_k_probs_list: List = top_k_probs_normalized.tolist()[0]\n",
    "            top_k_indices_list: List = top_k_indices.tolist()[0]\n",
    "\n",
    "            # filter to only words with a probability greater than p%\n",
    "            removal_marked = []\n",
    "            for j in range(len(top_k_probs_list)):\n",
    "                if top_k_probs_list[j] < top_p:\n",
    "                    removal_marked += [(top_k_probs_list[j], top_k_indices_list[j])]\n",
    "\n",
    "            for to_remove in removal_marked:\n",
    "                top_k_probs_list.remove(to_remove[0])\n",
    "                top_k_indices_list.remove(to_remove[1])\n",
    "\n",
    "            guesses = set()\n",
    "            for token_id, prob in zip(top_k_indices_list, top_k_probs_list):\n",
    "                token = distgpt2_tokenizer.decode([token_id])\n",
    "                guesses.add(token)\n",
    "\n",
    "            # we consider a prediction correct if the actual word was\n",
    "            # one of the (up to) 5 words suggested\n",
    "            if ' ' + actual_next_word in guesses:\n",
    "                distilgpt2_correct_predictions += 1\n",
    "            distilgpt2_total_predictions += 1\n",
    "            distilgpt2_inference_times += [time.time() - start_time]\n",
    "\n",
    "    return (distilgpt2_correct_predictions, distilgpt2_total_predictions, distilgpt2_inference_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:36:15.400602200Z",
     "start_time": "2023-12-22T20:29:41.135419600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3794/3794 [06:34<00:00,  9.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33800,\n",
       " 82231,\n",
       " [0.05942559242248535,\n",
       "  0.0049364566802978516,\n",
       "  0.0044901371002197266,\n",
       "  0.004277467727661133,\n",
       "  0.0044727325439453125,\n",
       "  0.004408121109008789,\n",
       "  0.004529237747192383,\n",
       "  0.004476070404052734,\n",
       "  0.004547834396362305,\n",
       "  0.0043697357177734375,\n",
       "  0.004462242126464844,\n",
       "  0.004505157470703125,\n",
       "  0.004400968551635742,\n",
       "  0.0043735504150390625,\n",
       "  0.004430055618286133,\n",
       "  0.00442957878112793,\n",
       "  0.004351615905761719,\n",
       "  0.004349946975708008,\n",
       "  0.004443645477294922,\n",
       "  0.004306316375732422,\n",
       "  0.004242658615112305,\n",
       "  0.004299163818359375,\n",
       "  0.004357099533081055,\n",
       "  0.004377603530883789,\n",
       "  0.004376411437988281,\n",
       "  0.004340171813964844,\n",
       "  0.004552602767944336,\n",
       "  0.004436969757080078,\n",
       "  0.004405975341796875,\n",
       "  0.004414081573486328,\n",
       "  0.004419088363647461,\n",
       "  0.004429340362548828,\n",
       "  0.004522562026977539,\n",
       "  0.0045850276947021484,\n",
       "  0.004542112350463867,\n",
       "  0.00446629524230957,\n",
       "  0.004487514495849609,\n",
       "  0.004516124725341797,\n",
       "  0.004617214202880859,\n",
       "  0.0045049190521240234,\n",
       "  0.0044481754302978516,\n",
       "  0.004536867141723633,\n",
       "  0.0045511722564697266,\n",
       "  0.0045430660247802734,\n",
       "  0.004528522491455078,\n",
       "  0.01235342025756836,\n",
       "  0.0046651363372802734,\n",
       "  0.0046062469482421875,\n",
       "  0.004523038864135742,\n",
       "  0.0046460628509521484,\n",
       "  0.0048427581787109375,\n",
       "  0.004912137985229492,\n",
       "  0.004804372787475586,\n",
       "  0.004979610443115234,\n",
       "  0.004755496978759766,\n",
       "  0.004761457443237305,\n",
       "  0.0047473907470703125,\n",
       "  0.004981040954589844,\n",
       "  0.005033016204833984,\n",
       "  0.005007028579711914,\n",
       "  0.004956960678100586,\n",
       "  0.004954099655151367,\n",
       "  0.0050623416900634766,\n",
       "  0.004889249801635742,\n",
       "  0.004947185516357422,\n",
       "  0.004937410354614258,\n",
       "  0.004763126373291016,\n",
       "  0.004822492599487305,\n",
       "  0.004194736480712891,\n",
       "  0.004220247268676758,\n",
       "  0.004245758056640625,\n",
       "  0.004288911819458008,\n",
       "  0.004374265670776367,\n",
       "  0.00436854362487793,\n",
       "  0.004342079162597656,\n",
       "  0.0043964385986328125,\n",
       "  0.004402637481689453,\n",
       "  0.004408121109008789,\n",
       "  0.004476308822631836,\n",
       "  0.004603385925292969,\n",
       "  0.004484891891479492,\n",
       "  0.004498481750488281,\n",
       "  0.004375457763671875,\n",
       "  0.004407644271850586,\n",
       "  0.004580974578857422,\n",
       "  0.004210233688354492,\n",
       "  0.0042760372161865234,\n",
       "  0.004267454147338867,\n",
       "  0.004372835159301758,\n",
       "  0.004416942596435547,\n",
       "  0.004333972930908203,\n",
       "  0.004389524459838867,\n",
       "  0.0044097900390625,\n",
       "  0.004538774490356445,\n",
       "  0.004416465759277344,\n",
       "  0.004416465759277344,\n",
       "  0.0044193267822265625,\n",
       "  0.0044803619384765625,\n",
       "  0.004420042037963867,\n",
       "  0.004362821578979492,\n",
       "  0.004492521286010742,\n",
       "  0.00440216064453125,\n",
       "  0.0046234130859375,\n",
       "  0.004422426223754883,\n",
       "  0.004444599151611328,\n",
       "  0.0044672489166259766,\n",
       "  0.00439143180847168,\n",
       "  0.004431962966918945,\n",
       "  0.00417780876159668,\n",
       "  0.004202842712402344,\n",
       "  0.004206180572509766,\n",
       "  0.004334926605224609,\n",
       "  0.004486560821533203,\n",
       "  0.0042383670806884766,\n",
       "  0.004287004470825195,\n",
       "  0.004505157470703125,\n",
       "  0.0044481754302978516,\n",
       "  0.0042994022369384766,\n",
       "  0.004565238952636719,\n",
       "  0.0044062137603759766,\n",
       "  0.004451274871826172,\n",
       "  0.0043904781341552734,\n",
       "  0.004408597946166992,\n",
       "  0.0044133663177490234,\n",
       "  0.004393815994262695,\n",
       "  0.004576683044433594,\n",
       "  0.004404544830322266,\n",
       "  0.004375934600830078,\n",
       "  0.004452705383300781,\n",
       "  0.004624366760253906,\n",
       "  0.004487752914428711,\n",
       "  0.004464149475097656,\n",
       "  0.004601478576660156,\n",
       "  0.004485130310058594,\n",
       "  0.004602909088134766,\n",
       "  0.004506826400756836,\n",
       "  0.004241466522216797,\n",
       "  0.004149436950683594,\n",
       "  0.004343748092651367,\n",
       "  0.0042836666107177734,\n",
       "  0.004454851150512695,\n",
       "  0.004400730133056641,\n",
       "  0.0043795108795166016,\n",
       "  0.004335641860961914,\n",
       "  0.0044803619384765625,\n",
       "  0.0043773651123046875,\n",
       "  0.004359245300292969,\n",
       "  0.004479646682739258,\n",
       "  0.004423856735229492,\n",
       "  0.0043964385986328125,\n",
       "  0.004386425018310547,\n",
       "  0.004500150680541992,\n",
       "  0.004490375518798828,\n",
       "  0.004454851150512695,\n",
       "  0.004485607147216797,\n",
       "  0.004462242126464844,\n",
       "  0.004651546478271484,\n",
       "  0.0046596527099609375,\n",
       "  0.004620552062988281,\n",
       "  0.004535675048828125,\n",
       "  0.004487276077270508,\n",
       "  0.00471806526184082,\n",
       "  0.004529476165771484,\n",
       "  0.004683017730712891,\n",
       "  0.004441261291503906,\n",
       "  0.004239320755004883,\n",
       "  0.0042765140533447266,\n",
       "  0.004282951354980469,\n",
       "  0.004348278045654297,\n",
       "  0.00422215461730957,\n",
       "  0.004429817199707031,\n",
       "  0.00426483154296875,\n",
       "  0.0043795108795166016,\n",
       "  0.004285097122192383,\n",
       "  0.004374027252197266,\n",
       "  0.004601240158081055,\n",
       "  0.00439143180847168,\n",
       "  0.004148244857788086,\n",
       "  0.004155397415161133,\n",
       "  0.004296779632568359,\n",
       "  0.004334211349487305,\n",
       "  0.004294395446777344,\n",
       "  0.0043413639068603516,\n",
       "  0.0043201446533203125,\n",
       "  0.004487276077270508,\n",
       "  0.004363298416137695,\n",
       "  0.004348278045654297,\n",
       "  0.0046122074127197266,\n",
       "  0.004319190979003906,\n",
       "  0.0045397281646728516,\n",
       "  0.004374980926513672,\n",
       "  0.004348278045654297,\n",
       "  0.004443168640136719,\n",
       "  0.004338979721069336,\n",
       "  0.004227638244628906,\n",
       "  0.004298210144042969,\n",
       "  0.0043370723724365234,\n",
       "  0.004273176193237305,\n",
       "  0.0044515132904052734,\n",
       "  0.004345417022705078,\n",
       "  0.004382133483886719,\n",
       "  0.0043926239013671875,\n",
       "  0.004506587982177734,\n",
       "  0.0044384002685546875,\n",
       "  0.004437446594238281,\n",
       "  0.004431009292602539,\n",
       "  0.004422903060913086,\n",
       "  0.004255771636962891,\n",
       "  0.0041484832763671875,\n",
       "  0.004350185394287109,\n",
       "  0.004281520843505859,\n",
       "  0.004408121109008789,\n",
       "  0.004444599151611328,\n",
       "  0.004206657409667969,\n",
       "  0.004190206527709961,\n",
       "  0.004278659820556641,\n",
       "  0.004523038864135742,\n",
       "  0.00438380241394043,\n",
       "  0.004327058792114258,\n",
       "  0.004431962966918945,\n",
       "  0.004622220993041992,\n",
       "  0.004633665084838867,\n",
       "  0.0043866634368896484,\n",
       "  0.004419803619384766,\n",
       "  0.004446744918823242,\n",
       "  0.004531145095825195,\n",
       "  0.0044422149658203125,\n",
       "  0.004218101501464844,\n",
       "  0.004286527633666992,\n",
       "  0.004400491714477539,\n",
       "  0.004387855529785156,\n",
       "  0.004256248474121094,\n",
       "  0.004563808441162109,\n",
       "  0.004560708999633789,\n",
       "  0.004416465759277344,\n",
       "  0.004487037658691406,\n",
       "  0.004529237747192383,\n",
       "  0.0043947696685791016,\n",
       "  0.004190921783447266,\n",
       "  0.004348278045654297,\n",
       "  0.00427556037902832,\n",
       "  0.0042951107025146484,\n",
       "  0.0043506622314453125,\n",
       "  0.004450559616088867,\n",
       "  0.004328250885009766,\n",
       "  0.0043942928314208984,\n",
       "  0.004366636276245117,\n",
       "  0.0044367313385009766,\n",
       "  0.004544496536254883,\n",
       "  0.004381656646728516,\n",
       "  0.00449061393737793,\n",
       "  0.0044403076171875,\n",
       "  0.004323720932006836,\n",
       "  0.0042493343353271484,\n",
       "  0.004289150238037109,\n",
       "  0.004359006881713867,\n",
       "  0.0043675899505615234,\n",
       "  0.004524946212768555,\n",
       "  0.004331111907958984,\n",
       "  0.004379749298095703,\n",
       "  0.0043985843658447266,\n",
       "  0.004458189010620117,\n",
       "  0.004330635070800781,\n",
       "  0.0041997432708740234,\n",
       "  0.0042438507080078125,\n",
       "  0.004504203796386719,\n",
       "  0.004579782485961914,\n",
       "  0.0043218135833740234,\n",
       "  0.004250049591064453,\n",
       "  0.004370689392089844,\n",
       "  0.0045337677001953125,\n",
       "  0.004547834396362305,\n",
       "  0.004454374313354492,\n",
       "  0.004410982131958008,\n",
       "  0.004468202590942383,\n",
       "  0.004626750946044922,\n",
       "  0.004327535629272461,\n",
       "  0.004530191421508789,\n",
       "  0.004632711410522461,\n",
       "  0.004589080810546875,\n",
       "  0.0046520233154296875,\n",
       "  0.004608869552612305,\n",
       "  0.004711151123046875,\n",
       "  0.004656553268432617,\n",
       "  0.004503488540649414,\n",
       "  0.004471778869628906,\n",
       "  0.004490375518798828,\n",
       "  0.004518985748291016,\n",
       "  0.004628419876098633,\n",
       "  0.0046596527099609375,\n",
       "  0.00464630126953125,\n",
       "  0.004588127136230469,\n",
       "  0.00458836555480957,\n",
       "  0.004609346389770508,\n",
       "  0.004714488983154297,\n",
       "  0.004760026931762695,\n",
       "  0.0047342777252197266,\n",
       "  0.004850625991821289,\n",
       "  0.004732370376586914,\n",
       "  0.00416254997253418,\n",
       "  0.004281282424926758,\n",
       "  0.004282951354980469,\n",
       "  0.004316806793212891,\n",
       "  0.004292488098144531,\n",
       "  0.004328727722167969,\n",
       "  0.004358053207397461,\n",
       "  0.004406452178955078,\n",
       "  0.004426717758178711,\n",
       "  0.004499912261962891,\n",
       "  0.004408359527587891,\n",
       "  0.0042154788970947266,\n",
       "  0.004207134246826172,\n",
       "  0.004274606704711914,\n",
       "  0.004478931427001953,\n",
       "  0.004369258880615234,\n",
       "  0.004377603530883789,\n",
       "  0.004360675811767578,\n",
       "  0.004380702972412109,\n",
       "  0.004403352737426758,\n",
       "  0.004457235336303711,\n",
       "  0.004392385482788086,\n",
       "  0.004416704177856445,\n",
       "  0.004406452178955078,\n",
       "  0.004460573196411133,\n",
       "  0.004423379898071289,\n",
       "  0.0044078826904296875,\n",
       "  0.004475593566894531,\n",
       "  0.004515886306762695,\n",
       "  0.004521608352661133,\n",
       "  0.004469871520996094,\n",
       "  0.004465579986572266,\n",
       "  0.0046079158782958984,\n",
       "  0.004717111587524414,\n",
       "  0.004595041275024414,\n",
       "  0.004453420639038086,\n",
       "  0.004528999328613281,\n",
       "  0.0045015811920166016,\n",
       "  0.004605770111083984,\n",
       "  0.004338264465332031,\n",
       "  0.004237174987792969,\n",
       "  0.004265308380126953,\n",
       "  0.004286050796508789,\n",
       "  0.004549503326416016,\n",
       "  0.004268646240234375,\n",
       "  0.004357099533081055,\n",
       "  0.004377841949462891,\n",
       "  0.004445075988769531,\n",
       "  0.004405498504638672,\n",
       "  0.004401206970214844,\n",
       "  0.00438237190246582,\n",
       "  0.004398822784423828,\n",
       "  0.004649639129638672,\n",
       "  0.004496097564697266,\n",
       "  0.004431724548339844,\n",
       "  0.004570960998535156,\n",
       "  0.004554033279418945,\n",
       "  0.004576444625854492,\n",
       "  0.0045337677001953125,\n",
       "  0.004594087600708008,\n",
       "  0.004518032073974609,\n",
       "  0.00418853759765625,\n",
       "  0.0041959285736083984,\n",
       "  0.004216432571411133,\n",
       "  0.00428318977355957,\n",
       "  0.00439000129699707,\n",
       "  0.004274845123291016,\n",
       "  0.004293680191040039,\n",
       "  0.0043675899505615234,\n",
       "  0.004415750503540039,\n",
       "  0.004438877105712891,\n",
       "  0.0043675899505615234,\n",
       "  0.004359722137451172,\n",
       "  0.004402637481689453,\n",
       "  0.0044558048248291016,\n",
       "  0.004205465316772461,\n",
       "  0.004260540008544922,\n",
       "  0.004345893859863281,\n",
       "  0.004461765289306641,\n",
       "  0.004491329193115234,\n",
       "  0.004408836364746094,\n",
       "  0.004381418228149414,\n",
       "  0.004447460174560547,\n",
       "  0.004552125930786133,\n",
       "  0.004667520523071289,\n",
       "  0.0044634342193603516,\n",
       "  0.004426240921020508,\n",
       "  0.004458904266357422,\n",
       "  0.004582881927490234,\n",
       "  0.004400491714477539,\n",
       "  0.004389047622680664,\n",
       "  0.004415035247802734,\n",
       "  0.004580259323120117,\n",
       "  0.004465818405151367,\n",
       "  0.004477262496948242,\n",
       "  0.004436492919921875,\n",
       "  0.0045223236083984375,\n",
       "  0.004627704620361328,\n",
       "  0.0045278072357177734,\n",
       "  0.004446744918823242,\n",
       "  0.004396677017211914,\n",
       "  0.004529714584350586,\n",
       "  0.0045261383056640625,\n",
       "  0.004481077194213867,\n",
       "  0.00448918342590332,\n",
       "  0.004541873931884766,\n",
       "  0.004472017288208008,\n",
       "  0.004518985748291016,\n",
       "  0.004525899887084961,\n",
       "  0.004529476165771484,\n",
       "  0.004621982574462891,\n",
       "  0.004566669464111328,\n",
       "  0.0044803619384765625,\n",
       "  0.004556179046630859,\n",
       "  0.0046844482421875,\n",
       "  0.004747629165649414,\n",
       "  0.004759788513183594,\n",
       "  0.004749298095703125,\n",
       "  0.004842281341552734,\n",
       "  0.004848957061767578,\n",
       "  0.004801511764526367,\n",
       "  0.0048639774322509766,\n",
       "  0.004825592041015625,\n",
       "  0.0047948360443115234,\n",
       "  0.004752635955810547,\n",
       "  0.0047495365142822266,\n",
       "  0.004759311676025391,\n",
       "  0.0048274993896484375,\n",
       "  0.004690408706665039,\n",
       "  0.004660129547119141,\n",
       "  0.004744291305541992,\n",
       "  0.004856586456298828,\n",
       "  0.004753589630126953,\n",
       "  0.004852771759033203,\n",
       "  0.004192829132080078,\n",
       "  0.004214763641357422,\n",
       "  0.004385709762573242,\n",
       "  0.004241466522216797,\n",
       "  0.004334449768066406,\n",
       "  0.004378557205200195,\n",
       "  0.0043544769287109375,\n",
       "  0.004302978515625,\n",
       "  0.0044116973876953125,\n",
       "  0.004355192184448242,\n",
       "  0.004389762878417969,\n",
       "  0.004507780075073242,\n",
       "  0.004405498504638672,\n",
       "  0.0043773651123046875,\n",
       "  0.004419803619384766,\n",
       "  0.004446268081665039,\n",
       "  0.004468441009521484,\n",
       "  0.004435539245605469,\n",
       "  0.0044710636138916016,\n",
       "  0.004479646682739258,\n",
       "  0.004525661468505859,\n",
       "  0.004537105560302734,\n",
       "  0.0045621395111083984,\n",
       "  0.0046083927154541016,\n",
       "  0.0046656131744384766,\n",
       "  0.004645586013793945,\n",
       "  0.00464940071105957,\n",
       "  0.004524946212768555,\n",
       "  0.0047245025634765625,\n",
       "  0.0048105716705322266,\n",
       "  0.00475001335144043,\n",
       "  0.0047359466552734375,\n",
       "  0.004755258560180664,\n",
       "  0.004758358001708984,\n",
       "  0.004761457443237305,\n",
       "  0.004736185073852539,\n",
       "  0.004826784133911133,\n",
       "  0.004819154739379883,\n",
       "  0.004756927490234375,\n",
       "  0.004244565963745117,\n",
       "  0.00429081916809082,\n",
       "  0.004248142242431641,\n",
       "  0.004306316375732422,\n",
       "  0.004294395446777344,\n",
       "  0.0043506622314453125,\n",
       "  0.004339456558227539,\n",
       "  0.004351615905761719,\n",
       "  0.00436854362487793,\n",
       "  0.0044097900390625,\n",
       "  0.004403829574584961,\n",
       "  0.004394054412841797,\n",
       "  0.004614830017089844,\n",
       "  0.004619598388671875,\n",
       "  0.004404306411743164,\n",
       "  0.004435300827026367,\n",
       "  0.004302024841308594,\n",
       "  0.0042705535888671875,\n",
       "  0.004236698150634766,\n",
       "  0.004267692565917969,\n",
       "  0.0043506622314453125,\n",
       "  0.004423856735229492,\n",
       "  0.004487514495849609,\n",
       "  0.004329681396484375,\n",
       "  0.004410743713378906,\n",
       "  0.004408836364746094,\n",
       "  0.00436091423034668,\n",
       "  0.004403114318847656,\n",
       "  0.004173755645751953,\n",
       "  0.004208087921142578,\n",
       "  0.004253387451171875,\n",
       "  0.004388570785522461,\n",
       "  0.004519462585449219,\n",
       "  0.0044825077056884766,\n",
       "  0.004358768463134766,\n",
       "  0.004462242126464844,\n",
       "  0.00446629524230957,\n",
       "  0.004414081573486328,\n",
       "  0.004317522048950195,\n",
       "  0.004349231719970703,\n",
       "  0.00435328483581543,\n",
       "  0.00441288948059082,\n",
       "  0.004399776458740234,\n",
       "  0.0045049190521240234,\n",
       "  0.0044744014739990234,\n",
       "  0.004540920257568359,\n",
       "  0.004445552825927734,\n",
       "  0.004435062408447266,\n",
       "  0.004169464111328125,\n",
       "  0.004346132278442383,\n",
       "  0.004199504852294922,\n",
       "  0.004248380661010742,\n",
       "  0.00435185432434082,\n",
       "  0.004446744918823242,\n",
       "  0.0043179988861083984,\n",
       "  0.00433802604675293,\n",
       "  0.004350900650024414,\n",
       "  0.004396677017211914,\n",
       "  0.004469633102416992,\n",
       "  0.0044727325439453125,\n",
       "  0.004658222198486328,\n",
       "  0.004475593566894531,\n",
       "  0.004441738128662109,\n",
       "  0.004587650299072266,\n",
       "  0.004445314407348633,\n",
       "  0.004453420639038086,\n",
       "  0.004385232925415039,\n",
       "  0.00453495979309082,\n",
       "  0.004418849945068359,\n",
       "  0.004452943801879883,\n",
       "  0.004494905471801758,\n",
       "  0.0045316219329833984,\n",
       "  0.0046234130859375,\n",
       "  0.004502296447753906,\n",
       "  0.0044591426849365234,\n",
       "  0.0044901371002197266,\n",
       "  0.004629611968994141,\n",
       "  0.0045719146728515625,\n",
       "  0.00447845458984375,\n",
       "  0.004570484161376953,\n",
       "  0.00453948974609375,\n",
       "  0.004895448684692383,\n",
       "  0.004734992980957031,\n",
       "  0.004727602005004883,\n",
       "  0.004731655120849609,\n",
       "  0.00482177734375,\n",
       "  0.004678964614868164,\n",
       "  0.0048046112060546875,\n",
       "  0.0048580169677734375,\n",
       "  0.004819631576538086,\n",
       "  0.004709720611572266,\n",
       "  0.004770994186401367,\n",
       "  0.004730701446533203,\n",
       "  0.004906654357910156,\n",
       "  0.004892826080322266,\n",
       "  0.004734516143798828,\n",
       "  0.0049152374267578125,\n",
       "  0.0049169063568115234,\n",
       "  0.0049343109130859375,\n",
       "  0.004804372787475586,\n",
       "  0.004766702651977539,\n",
       "  0.004503011703491211,\n",
       "  0.004372119903564453,\n",
       "  0.004290580749511719,\n",
       "  0.0043332576751708984,\n",
       "  0.004325389862060547,\n",
       "  0.004300832748413086,\n",
       "  0.004384279251098633,\n",
       "  0.004394054412841797,\n",
       "  0.004464149475097656,\n",
       "  0.004414558410644531,\n",
       "  0.0045299530029296875,\n",
       "  0.004506587982177734,\n",
       "  0.004434823989868164,\n",
       "  0.00443577766418457,\n",
       "  0.004464149475097656,\n",
       "  0.0043866634368896484,\n",
       "  0.004212617874145508,\n",
       "  0.004367828369140625,\n",
       "  0.0043714046478271484,\n",
       "  0.004349231719970703,\n",
       "  0.0043604373931884766,\n",
       "  0.0043811798095703125,\n",
       "  0.004326820373535156,\n",
       "  0.004478931427001953,\n",
       "  0.0046575069427490234,\n",
       "  0.004456520080566406,\n",
       "  0.004446983337402344,\n",
       "  0.004474639892578125,\n",
       "  0.004442930221557617,\n",
       "  0.004450082778930664,\n",
       "  0.004416227340698242,\n",
       "  0.004522800445556641,\n",
       "  0.004538059234619141,\n",
       "  0.004729509353637695,\n",
       "  0.004475593566894531,\n",
       "  0.004540205001831055,\n",
       "  0.004484653472900391,\n",
       "  0.004542112350463867,\n",
       "  0.004509925842285156,\n",
       "  0.0044977664947509766,\n",
       "  0.004475593566894531,\n",
       "  0.00450444221496582,\n",
       "  0.0045430660247802734,\n",
       "  0.004483461380004883,\n",
       "  0.004477262496948242,\n",
       "  0.004542112350463867,\n",
       "  0.00461125373840332,\n",
       "  0.004502773284912109,\n",
       "  0.004511117935180664,\n",
       "  0.004520416259765625,\n",
       "  0.0045623779296875,\n",
       "  0.00419926643371582,\n",
       "  0.004218101501464844,\n",
       "  0.004305839538574219,\n",
       "  0.004349470138549805,\n",
       "  0.004504680633544922,\n",
       "  0.00443720817565918,\n",
       "  0.004267454147338867,\n",
       "  0.004385709762573242,\n",
       "  0.004441738128662109,\n",
       "  0.004488706588745117,\n",
       "  0.004400491714477539,\n",
       "  0.0045318603515625,\n",
       "  0.004477500915527344,\n",
       "  0.0046350955963134766,\n",
       "  0.004467487335205078,\n",
       "  0.004420757293701172,\n",
       "  0.004523754119873047,\n",
       "  0.004502773284912109,\n",
       "  0.004492998123168945,\n",
       "  0.004448652267456055,\n",
       "  0.004469871520996094,\n",
       "  0.004496574401855469,\n",
       "  0.004586935043334961,\n",
       "  0.0045757293701171875,\n",
       "  0.004494905471801758,\n",
       "  0.0045087337493896484,\n",
       "  0.0045163631439208984,\n",
       "  0.004692792892456055,\n",
       "  0.004623889923095703,\n",
       "  0.0045528411865234375,\n",
       "  0.004521369934082031,\n",
       "  0.0047075748443603516,\n",
       "  0.004718303680419922,\n",
       "  0.0047376155853271484,\n",
       "  0.0047419071197509766,\n",
       "  0.004771232604980469,\n",
       "  0.004731416702270508,\n",
       "  0.004694461822509766,\n",
       "  0.004818916320800781,\n",
       "  0.004765987396240234,\n",
       "  0.004848957061767578,\n",
       "  0.004738569259643555,\n",
       "  0.0047414302825927734,\n",
       "  0.004763126373291016,\n",
       "  0.005031585693359375,\n",
       "  0.00467681884765625,\n",
       "  0.004809141159057617,\n",
       "  0.004731655120849609,\n",
       "  0.004946470260620117,\n",
       "  0.0047588348388671875,\n",
       "  0.004805803298950195,\n",
       "  0.004817008972167969,\n",
       "  0.004971027374267578,\n",
       "  0.004871368408203125,\n",
       "  0.004796028137207031,\n",
       "  0.004924774169921875,\n",
       "  0.004968166351318359,\n",
       "  0.004868984222412109,\n",
       "  0.005149364471435547,\n",
       "  0.004824161529541016,\n",
       "  0.004921913146972656,\n",
       "  0.004965305328369141,\n",
       "  0.005009889602661133,\n",
       "  0.004833221435546875,\n",
       "  0.005087614059448242,\n",
       "  0.005190372467041016,\n",
       "  0.005210161209106445,\n",
       "  0.005109310150146484,\n",
       "  0.005185604095458984,\n",
       "  0.005158185958862305,\n",
       "  0.005054950714111328,\n",
       "  0.00506901741027832,\n",
       "  0.0050275325775146484,\n",
       "  0.0051190853118896484,\n",
       "  0.005095005035400391,\n",
       "  0.005088329315185547,\n",
       "  0.005159616470336914,\n",
       "  0.0053751468658447266,\n",
       "  0.005090951919555664,\n",
       "  0.005115032196044922,\n",
       "  0.005187511444091797,\n",
       "  0.005098581314086914,\n",
       "  0.005128145217895508,\n",
       "  0.005121707916259766,\n",
       "  0.0051305294036865234,\n",
       "  0.005227804183959961,\n",
       "  0.005105018615722656,\n",
       "  0.005138874053955078,\n",
       "  0.00530695915222168,\n",
       "  0.0052912235260009766,\n",
       "  0.0051767826080322266,\n",
       "  0.005157947540283203,\n",
       "  0.005305290222167969,\n",
       "  0.005201578140258789,\n",
       "  0.005218505859375,\n",
       "  0.0053827762603759766,\n",
       "  0.005360126495361328,\n",
       "  0.0052716732025146484,\n",
       "  0.005228281021118164,\n",
       "  0.005253314971923828,\n",
       "  0.005290985107421875,\n",
       "  0.005239963531494141,\n",
       "  0.005240201950073242,\n",
       "  0.005361795425415039,\n",
       "  0.0053539276123046875,\n",
       "  0.0053026676177978516,\n",
       "  0.0052678585052490234,\n",
       "  0.005315065383911133,\n",
       "  0.005384206771850586,\n",
       "  0.0052759647369384766,\n",
       "  0.004476785659790039,\n",
       "  0.004317760467529297,\n",
       "  0.004374504089355469,\n",
       "  0.004355192184448242,\n",
       "  0.0044078826904296875,\n",
       "  0.004391908645629883,\n",
       "  0.004506111145019531,\n",
       "  0.004342317581176758,\n",
       "  0.0043985843658447266,\n",
       "  0.00441288948059082,\n",
       "  0.004482746124267578,\n",
       "  0.004416465759277344,\n",
       "  0.004401445388793945,\n",
       "  0.004512310028076172,\n",
       "  0.004410266876220703,\n",
       "  0.004508256912231445,\n",
       "  0.004416704177856445,\n",
       "  0.004436492919921875,\n",
       "  0.004437923431396484,\n",
       "  0.004542350769042969,\n",
       "  0.0044858455657958984,\n",
       "  0.004494428634643555,\n",
       "  0.004534482955932617,\n",
       "  0.004567861557006836,\n",
       "  0.004504203796386719,\n",
       "  0.00450897216796875,\n",
       "  0.004592180252075195,\n",
       "  0.004561662673950195,\n",
       "  0.004594564437866211,\n",
       "  0.004517555236816406,\n",
       "  0.004529476165771484,\n",
       "  0.004706382751464844,\n",
       "  0.004795074462890625,\n",
       "  0.004649639129638672,\n",
       "  0.00466156005859375,\n",
       "  0.004173755645751953,\n",
       "  0.004255771636962891,\n",
       "  0.004233598709106445,\n",
       "  0.00418400764465332,\n",
       "  0.004212617874145508,\n",
       "  0.004254579544067383,\n",
       "  0.004453420639038086,\n",
       "  0.004371166229248047,\n",
       "  0.0044057369232177734,\n",
       "  0.004366874694824219,\n",
       "  0.0043981075286865234,\n",
       "  0.0045795440673828125,\n",
       "  0.004385709762573242,\n",
       "  0.004415035247802734,\n",
       "  0.0044100284576416016,\n",
       "  0.004524707794189453,\n",
       "  0.004515409469604492,\n",
       "  0.004542827606201172,\n",
       "  0.004520416259765625,\n",
       "  0.004443645477294922,\n",
       "  0.004470348358154297,\n",
       "  0.004609346389770508,\n",
       "  0.00458216667175293,\n",
       "  0.004565238952636719,\n",
       "  0.004467487335205078,\n",
       "  0.004527091979980469,\n",
       "  0.004531145095825195,\n",
       "  0.004509925842285156,\n",
       "  0.004506349563598633,\n",
       "  0.0046579837799072266,\n",
       "  0.004505157470703125,\n",
       "  0.004584074020385742,\n",
       "  0.004556179046630859,\n",
       "  0.004736900329589844,\n",
       "  0.004609584808349609,\n",
       "  0.004153728485107422,\n",
       "  0.004219770431518555,\n",
       "  0.004232168197631836,\n",
       "  0.0044748783111572266,\n",
       "  0.004378080368041992,\n",
       "  0.004418849945068359,\n",
       "  0.004446268081665039,\n",
       "  0.004413127899169922,\n",
       "  0.004437685012817383,\n",
       "  0.004343748092651367,\n",
       "  0.004407644271850586,\n",
       "  0.0044116973876953125,\n",
       "  0.004480600357055664,\n",
       "  0.004452943801879883,\n",
       "  0.0045092105865478516,\n",
       "  0.0044612884521484375,\n",
       "  0.004454135894775391,\n",
       "  0.0045015811920166016,\n",
       "  0.004555463790893555,\n",
       "  0.00448298454284668,\n",
       "  0.004487514495849609,\n",
       "  0.0045812129974365234,\n",
       "  0.004496574401855469,\n",
       "  0.004517316818237305,\n",
       "  0.0045168399810791016,\n",
       "  0.004524707794189453,\n",
       "  0.004567384719848633,\n",
       "  0.004536628723144531,\n",
       "  0.004183769226074219,\n",
       "  0.0042057037353515625,\n",
       "  0.004294157028198242,\n",
       "  0.0042917728424072266,\n",
       "  0.0042667388916015625,\n",
       "  0.004326820373535156,\n",
       "  0.004397869110107422,\n",
       "  0.004370212554931641,\n",
       "  0.004370689392089844,\n",
       "  0.004172086715698242,\n",
       "  0.0042018890380859375,\n",
       "  0.00427556037902832,\n",
       "  0.004311323165893555,\n",
       "  0.004350900650024414,\n",
       "  0.004370212554931641,\n",
       "  0.00431513786315918,\n",
       "  0.004472970962524414,\n",
       "  0.004399299621582031,\n",
       "  0.004484653472900391,\n",
       "  0.004437923431396484,\n",
       "  0.004535675048828125,\n",
       "  0.004340410232543945,\n",
       "  0.004409313201904297,\n",
       "  0.004412412643432617,\n",
       "  0.004434347152709961,\n",
       "  0.004525423049926758,\n",
       "  0.004477739334106445,\n",
       "  0.004456758499145508,\n",
       "  0.004488945007324219,\n",
       "  0.0045053958892822266,\n",
       "  0.0045621395111083984,\n",
       "  0.004472255706787109,\n",
       "  0.004446506500244141,\n",
       "  0.004534006118774414,\n",
       "  0.004641532897949219,\n",
       "  0.004537343978881836,\n",
       "  0.004534482955932617,\n",
       "  0.004507303237915039,\n",
       "  0.0047338008880615234,\n",
       "  0.004797458648681641,\n",
       "  0.0046956539154052734,\n",
       "  0.004689931869506836,\n",
       "  0.004776716232299805,\n",
       "  0.004700422286987305,\n",
       "  0.004670143127441406,\n",
       "  0.004754304885864258,\n",
       "  0.004722118377685547,\n",
       "  0.004855632781982422,\n",
       "  0.004815101623535156,\n",
       "  0.004888296127319336,\n",
       "  0.004717826843261719,\n",
       "  0.004949808120727539,\n",
       "  0.004427671432495117,\n",
       "  0.004192829132080078,\n",
       "  0.004158496856689453,\n",
       "  0.004350423812866211,\n",
       "  0.004347085952758789,\n",
       "  0.004163026809692383,\n",
       "  0.004210472106933594,\n",
       "  0.0042345523834228516,\n",
       "  0.004374504089355469,\n",
       "  0.004341840744018555,\n",
       "  0.004346370697021484,\n",
       "  0.004244327545166016,\n",
       "  0.004417896270751953,\n",
       "  0.004514455795288086,\n",
       "  0.00440526008605957,\n",
       "  0.004362821578979492,\n",
       "  0.004385709762573242,\n",
       "  0.004505157470703125,\n",
       "  0.0044841766357421875,\n",
       "  0.004402637481689453,\n",
       "  0.0045337677001953125,\n",
       "  0.004396677017211914,\n",
       "  0.004507541656494141,\n",
       "  0.0044422149658203125,\n",
       "  0.004419803619384766,\n",
       "  0.004525184631347656,\n",
       "  0.004572391510009766,\n",
       "  0.0041637420654296875,\n",
       "  0.004153013229370117,\n",
       "  0.004217624664306641,\n",
       "  0.004265785217285156,\n",
       "  0.004394054412841797,\n",
       "  0.004406452178955078,\n",
       "  0.004322528839111328,\n",
       "  0.004362344741821289,\n",
       "  0.004444122314453125,\n",
       "  0.004392862319946289,\n",
       "  0.0043680667877197266,\n",
       "  0.004391193389892578,\n",
       "  0.004466056823730469,\n",
       "  0.004458189010620117,\n",
       "  0.0044515132904052734,\n",
       "  0.004436016082763672,\n",
       "  0.0043849945068359375,\n",
       "  0.0044994354248046875,\n",
       "  0.004652261734008789,\n",
       "  0.004504203796386719,\n",
       "  0.004678487777709961,\n",
       "  0.00446772575378418,\n",
       "  0.0045511722564697266,\n",
       "  0.0046002864837646484,\n",
       "  0.004549980163574219,\n",
       "  0.004498720169067383,\n",
       "  0.004542112350463867,\n",
       "  0.00423884391784668,\n",
       "  0.004421234130859375,\n",
       "  0.004428386688232422,\n",
       "  0.004392385482788086,\n",
       "  0.004363059997558594,\n",
       "  0.0044057369232177734,\n",
       "  0.004340648651123047,\n",
       "  0.004140615463256836,\n",
       "  0.0042650699615478516,\n",
       "  0.004183769226074219,\n",
       "  0.004213571548461914,\n",
       "  0.004247903823852539,\n",
       "  0.004250288009643555,\n",
       "  0.004324674606323242,\n",
       "  0.0043811798095703125,\n",
       "  0.004332065582275391,\n",
       "  0.004377603530883789,\n",
       "  0.004397869110107422,\n",
       "  0.004354715347290039,\n",
       "  0.004151105880737305,\n",
       "  0.004210472106933594,\n",
       "  0.0041942596435546875,\n",
       "  0.004315614700317383,\n",
       "  0.004412174224853516,\n",
       "  0.004327535629272461,\n",
       "  0.00426793098449707,\n",
       "  0.004458904266357422,\n",
       "  0.004547119140625,\n",
       "  0.004279375076293945,\n",
       "  0.0043256282806396484,\n",
       "  0.004332304000854492,\n",
       "  0.004375457763671875,\n",
       "  0.004362821578979492,\n",
       "  0.004375457763671875,\n",
       "  0.004498958587646484,\n",
       "  0.004439115524291992,\n",
       "  0.004487276077270508,\n",
       "  0.004363059997558594,\n",
       "  0.004315614700317383,\n",
       "  0.004414796829223633,\n",
       "  0.004509449005126953,\n",
       "  0.004508495330810547,\n",
       "  0.004473447799682617,\n",
       "  0.004434108734130859,\n",
       "  0.004478931427001953,\n",
       "  0.004544258117675781,\n",
       "  0.004163265228271484,\n",
       "  0.004198789596557617,\n",
       "  0.004181861877441406,\n",
       "  0.0043447017669677734,\n",
       "  0.004347801208496094,\n",
       "  0.0043179988861083984,\n",
       "  0.0043718814849853516,\n",
       "  0.004130363464355469,\n",
       "  0.004350185394287109,\n",
       "  0.0042877197265625,\n",
       "  0.004285573959350586,\n",
       "  0.0043103694915771484,\n",
       "  0.004331111907958984,\n",
       "  0.004386425018310547,\n",
       "  0.004383563995361328,\n",
       "  0.004513978958129883,\n",
       "  ...])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilgpt2_correct_predictions, distilgpt2_total_predictions, distilgpt2_inference_times = test_model_accuracy(trainer.model, user_posts_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T01:38:32.600418300Z",
     "start_time": "2023-12-22T01:38:32.593417700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal 0.36095087922396757\n"
     ]
    }
   ],
   "source": [
    "gpt2_accuracy = distilgpt2_correct_predictions / distilgpt2_total_predictions\n",
    "print('normal', gpt2_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T02:22:23.219644600Z",
     "start_time": "2023-12-22T02:22:23.166644700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned 0.318835951378216\n"
     ]
    }
   ],
   "source": [
    "gpt2_accuracy = distilgpt2_correct_predictions / distilgpt2_total_predictions\n",
    "print('finetuned', gpt2_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T20:36:15.414683300Z",
     "start_time": "2023-12-22T20:36:15.399611Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distilgpt2_correct_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gpt2_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mdistilgpt2_correct_predictions\u001b[49m \u001b[38;5;241m/\u001b[39m distilgpt2_total_predictions\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinetuned\u001b[39m\u001b[38;5;124m'\u001b[39m, gpt2_accuracy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distilgpt2_correct_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "gpt2_accuracy = distilgpt2_correct_predictions / distilgpt2_total_predictions\n",
    "print('finetuned', gpt2_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T02:54:42.078953400Z",
     "start_time": "2023-12-22T02:54:42.075953200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned 0.5071201858180006\n"
     ]
    }
   ],
   "source": [
    "gpt2_accuracy = distilgpt2_correct_predictions / distilgpt2_total_predictions\n",
    "print('finetuned', gpt2_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Vocab updated??\n",
    "https://github.com/huggingface/tokenizers/issues/1160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### EWC - Elastic Weight Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T21:00:52.907903800Z",
     "start_time": "2023-12-22T21:00:51.686960Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 73 different task sets.\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into different \"tasks\" where each task is composed of at least 1200 words\n",
    "# every 1200 words we update the model using ewc\n",
    "# at the end of each task set, we see how well the model is able to predict the words in the next task set\n",
    "# we consider a single post the smallest divisible unit\n",
    "task_sets = []\n",
    "current_set_len = 0\n",
    "current_task_set = []\n",
    "for data_entry in entire_dataset_list:\n",
    "    post = data_entry[\"post\"]\n",
    "    sent_tokenized = sent_tokenize(normalize_text(post))\n",
    "    tokenized_words = [word_tokenize(sentence) for sentence in sent_tokenized]\n",
    "    tokenized_words = [word for s in tokenized_words for word in s]\n",
    "    current_set_len += len(tokenized_words)\n",
    "    current_task_set += [data_entry]\n",
    "    if current_set_len >= 1200:\n",
    "        task_sets += [current_task_set]\n",
    "        current_task_set = []\n",
    "        current_set_len = 0\n",
    "task_sets += [current_task_set]  # last task set may have less than 1000 words\n",
    "\n",
    "task_datasets = []\n",
    "for task_set in task_sets:\n",
    "    # no need to split this data into training and eval\n",
    "    # because we next task is the evaluation\n",
    "    task_datasets += [Dataset.from_list(entire_dataset_list)]\n",
    "\n",
    "print(f'Created {len(task_datasets)} different task sets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T05:49:11.864260300Z",
     "start_time": "2023-12-22T05:49:11.822639Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_data_loader = DataLoader(\n",
    "    dataset=trained_dataset_processed,\n",
    "    batch_size=6,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    ")\n",
    "eval_data_loader = DataLoader(\n",
    "    dataset=validation_dataset_processed,\n",
    "    batch_size=6,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T21:00:45.219152400Z",
     "start_time": "2023-12-22T21:00:45.212080900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T21:00:41.611687600Z",
     "start_time": "2023-12-22T21:00:40.369930400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device=device)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T05:54:52.712980200Z",
     "start_time": "2023-12-22T05:49:26.714493100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|                                                                                                                                                                                    | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                                                                  | 0/537 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                                                                                                         | 1/537 [00:00<04:51,  1.84it/s]\u001b[A\n",
      "  0%|▋                                                                                                                                                                         | 2/537 [00:00<03:32,  2.52it/s]\u001b[A\n",
      "  1%|▉                                                                                                                                                                         | 3/537 [00:01<03:07,  2.86it/s]\u001b[A\n",
      "  1%|█▎                                                                                                                                                                        | 4/537 [00:01<02:54,  3.05it/s]\u001b[A\n",
      "  1%|█▌                                                                                                                                                                        | 5/537 [00:01<02:48,  3.17it/s]\u001b[A\n",
      "  1%|█▉                                                                                                                                                                        | 6/537 [00:02<02:43,  3.24it/s]\u001b[A\n",
      "  1%|██▏                                                                                                                                                                       | 7/537 [00:02<02:41,  3.29it/s]\u001b[A\n",
      "  1%|██▌                                                                                                                                                                       | 8/537 [00:02<02:39,  3.32it/s]\u001b[A\n",
      "  2%|██▊                                                                                                                                                                       | 9/537 [00:02<02:37,  3.35it/s]\u001b[A\n",
      "  2%|███▏                                                                                                                                                                     | 10/537 [00:03<02:36,  3.36it/s]\u001b[A\n",
      "  2%|███▍                                                                                                                                                                     | 11/537 [00:03<02:36,  3.37it/s]\u001b[A\n",
      "  2%|███▊                                                                                                                                                                     | 12/537 [00:03<02:35,  3.37it/s]\u001b[A\n",
      "  2%|████                                                                                                                                                                     | 13/537 [00:04<02:34,  3.38it/s]\u001b[A\n",
      "  3%|████▍                                                                                                                                                                    | 14/537 [00:04<02:34,  3.38it/s]\u001b[A\n",
      "  3%|████▋                                                                                                                                                                    | 15/537 [00:04<02:34,  3.38it/s]\u001b[A\n",
      "  3%|█████                                                                                                                                                                    | 16/537 [00:04<02:33,  3.39it/s]\u001b[A\n",
      "  3%|█████▎                                                                                                                                                                   | 17/537 [00:05<02:33,  3.39it/s]\u001b[A\n",
      "  3%|█████▋                                                                                                                                                                   | 18/537 [00:05<02:33,  3.39it/s]\u001b[A\n",
      "  4%|█████▉                                                                                                                                                                   | 19/537 [00:05<02:32,  3.39it/s]\u001b[A\n",
      "  4%|██████▎                                                                                                                                                                  | 20/537 [00:06<02:32,  3.39it/s]\u001b[A\n",
      "  4%|██████▌                                                                                                                                                                  | 21/537 [00:06<02:32,  3.38it/s]\u001b[A\n",
      "  4%|██████▉                                                                                                                                                                  | 22/537 [00:06<02:32,  3.38it/s]\u001b[A\n",
      "  4%|███████▏                                                                                                                                                                 | 23/537 [00:07<02:31,  3.38it/s]\u001b[A\n",
      "  4%|███████▌                                                                                                                                                                 | 24/537 [00:07<02:31,  3.38it/s]\u001b[A\n",
      "  5%|███████▊                                                                                                                                                                 | 25/537 [00:07<02:30,  3.39it/s]\u001b[A\n",
      "  5%|████████▏                                                                                                                                                                | 26/537 [00:07<02:30,  3.39it/s]\u001b[A\n",
      "  5%|████████▍                                                                                                                                                                | 27/537 [00:08<02:30,  3.38it/s]\u001b[A\n",
      "  5%|████████▊                                                                                                                                                                | 28/537 [00:08<02:30,  3.38it/s]\u001b[A\n",
      "  5%|█████████▏                                                                                                                                                               | 29/537 [00:08<02:30,  3.38it/s]\u001b[A\n",
      "  6%|█████████▍                                                                                                                                                               | 30/537 [00:09<02:29,  3.39it/s]\u001b[A\n",
      "  6%|█████████▊                                                                                                                                                               | 31/537 [00:09<02:29,  3.38it/s]\u001b[A\n",
      "  6%|██████████                                                                                                                                                               | 32/537 [00:09<02:29,  3.39it/s]\u001b[A\n",
      "  6%|██████████▍                                                                                                                                                              | 33/537 [00:09<02:28,  3.38it/s]\u001b[A\n",
      "  6%|██████████▋                                                                                                                                                              | 34/537 [00:10<02:28,  3.38it/s]\u001b[A\n",
      "  7%|███████████                                                                                                                                                              | 35/537 [00:10<02:28,  3.38it/s]\u001b[A\n",
      "  7%|███████████▎                                                                                                                                                             | 36/537 [00:10<02:28,  3.37it/s]\u001b[A\n",
      "  7%|███████████▋                                                                                                                                                             | 37/537 [00:11<02:28,  3.37it/s]\u001b[A\n",
      "  7%|███████████▉                                                                                                                                                             | 38/537 [00:11<02:28,  3.37it/s]\u001b[A\n",
      "  7%|████████████▎                                                                                                                                                            | 39/537 [00:11<02:27,  3.37it/s]\u001b[A\n",
      "  7%|████████████▌                                                                                                                                                            | 40/537 [00:12<02:27,  3.37it/s]\u001b[A\n",
      "  8%|████████████▉                                                                                                                                                            | 41/537 [00:12<02:27,  3.37it/s]\u001b[A\n",
      "  8%|█████████████▏                                                                                                                                                           | 42/537 [00:12<02:26,  3.37it/s]\u001b[A\n",
      "  8%|█████████████▌                                                                                                                                                           | 43/537 [00:12<02:26,  3.37it/s]\u001b[A\n",
      "  8%|█████████████▊                                                                                                                                                           | 44/537 [00:13<02:26,  3.37it/s]\u001b[A\n",
      "  8%|██████████████▏                                                                                                                                                          | 45/537 [00:13<02:25,  3.38it/s]\u001b[A\n",
      "  9%|██████████████▍                                                                                                                                                          | 46/537 [00:13<02:25,  3.38it/s]\u001b[A\n",
      "  9%|██████████████▊                                                                                                                                                          | 47/537 [00:14<02:25,  3.38it/s]\u001b[A\n",
      "  9%|███████████████                                                                                                                                                          | 48/537 [00:14<02:25,  3.37it/s]\u001b[A\n",
      "  9%|███████████████▍                                                                                                                                                         | 49/537 [00:14<02:24,  3.37it/s]\u001b[A\n",
      "  9%|███████████████▋                                                                                                                                                         | 50/537 [00:15<02:24,  3.37it/s]\u001b[A\n",
      "  9%|████████████████                                                                                                                                                         | 51/537 [00:15<02:24,  3.37it/s]\u001b[A\n",
      " 10%|████████████████▎                                                                                                                                                        | 52/537 [00:15<02:23,  3.37it/s]\u001b[A\n",
      " 10%|████████████████▋                                                                                                                                                        | 53/537 [00:15<02:23,  3.38it/s]\u001b[A\n",
      " 10%|████████████████▉                                                                                                                                                        | 54/537 [00:16<02:23,  3.38it/s]\u001b[A\n",
      " 10%|█████████████████▎                                                                                                                                                       | 55/537 [00:16<02:22,  3.37it/s]\u001b[A\n",
      " 10%|█████████████████▌                                                                                                                                                       | 56/537 [00:16<02:22,  3.38it/s]\u001b[A\n",
      " 11%|█████████████████▉                                                                                                                                                       | 57/537 [00:17<02:22,  3.37it/s]\u001b[A\n",
      " 11%|██████████████████▎                                                                                                                                                      | 58/537 [00:17<02:22,  3.36it/s]\u001b[A\n",
      " 11%|██████████████████▌                                                                                                                                                      | 59/537 [00:17<02:22,  3.37it/s]\u001b[A\n",
      " 11%|██████████████████▉                                                                                                                                                      | 60/537 [00:17<02:21,  3.37it/s]\u001b[A\n",
      " 11%|███████████████████▏                                                                                                                                                     | 61/537 [00:18<02:21,  3.37it/s]\u001b[A\n",
      " 12%|███████████████████▌                                                                                                                                                     | 62/537 [00:18<02:21,  3.37it/s]\u001b[A\n",
      " 12%|███████████████████▊                                                                                                                                                     | 63/537 [00:18<02:20,  3.37it/s]\u001b[A\n",
      " 12%|████████████████████▏                                                                                                                                                    | 64/537 [00:19<02:20,  3.37it/s]\u001b[A\n",
      " 12%|████████████████████▍                                                                                                                                                    | 65/537 [00:19<02:20,  3.36it/s]\u001b[A\n",
      " 12%|████████████████████▊                                                                                                                                                    | 66/537 [00:19<02:20,  3.36it/s]\u001b[A\n",
      " 12%|█████████████████████                                                                                                                                                    | 67/537 [00:20<02:20,  3.36it/s]\u001b[A\n",
      " 13%|█████████████████████▍                                                                                                                                                   | 68/537 [00:20<02:19,  3.36it/s]\u001b[A\n",
      " 13%|█████████████████████▋                                                                                                                                                   | 69/537 [00:20<02:19,  3.36it/s]\u001b[A\n",
      " 13%|██████████████████████                                                                                                                                                   | 70/537 [00:20<02:18,  3.37it/s]\u001b[A\n",
      " 13%|██████████████████████▎                                                                                                                                                  | 71/537 [00:21<02:18,  3.36it/s]\u001b[A\n",
      " 13%|██████████████████████▋                                                                                                                                                  | 72/537 [00:21<02:18,  3.36it/s]\u001b[A\n",
      " 14%|██████████████████████▉                                                                                                                                                  | 73/537 [00:21<02:18,  3.36it/s]\u001b[A\n",
      " 14%|███████████████████████▎                                                                                                                                                 | 74/537 [00:22<02:17,  3.36it/s]\u001b[A\n",
      " 14%|███████████████████████▌                                                                                                                                                 | 75/537 [00:22<02:17,  3.36it/s]\u001b[A\n",
      " 14%|███████████████████████▉                                                                                                                                                 | 76/537 [00:22<02:17,  3.36it/s]\u001b[A\n",
      " 14%|████████████████████████▏                                                                                                                                                | 77/537 [00:23<02:16,  3.36it/s]\u001b[A\n",
      " 15%|████████████████████████▌                                                                                                                                                | 78/537 [00:23<02:16,  3.36it/s]\u001b[A\n",
      " 15%|████████████████████████▊                                                                                                                                                | 79/537 [00:23<02:16,  3.36it/s]\u001b[A\n",
      " 15%|█████████████████████████▏                                                                                                                                               | 80/537 [00:23<02:16,  3.35it/s]\u001b[A\n",
      " 15%|█████████████████████████▍                                                                                                                                               | 81/537 [00:24<02:16,  3.35it/s]\u001b[A\n",
      " 15%|█████████████████████████▊                                                                                                                                               | 82/537 [00:24<02:15,  3.35it/s]\u001b[A\n",
      " 15%|██████████████████████████                                                                                                                                               | 83/537 [00:24<02:14,  3.36it/s]\u001b[A\n",
      " 16%|██████████████████████████▍                                                                                                                                              | 84/537 [00:25<02:14,  3.36it/s]\u001b[A\n",
      " 16%|██████████████████████████▊                                                                                                                                              | 85/537 [00:25<02:14,  3.36it/s]\u001b[A\n",
      " 16%|███████████████████████████                                                                                                                                              | 86/537 [00:25<02:14,  3.36it/s]\u001b[A\n",
      " 16%|███████████████████████████▍                                                                                                                                             | 87/537 [00:26<02:13,  3.37it/s]\u001b[A\n",
      " 16%|███████████████████████████▋                                                                                                                                             | 88/537 [00:26<02:13,  3.36it/s]\u001b[A\n",
      " 17%|████████████████████████████                                                                                                                                             | 89/537 [00:26<02:13,  3.36it/s]\u001b[A\n",
      " 17%|████████████████████████████▎                                                                                                                                            | 90/537 [00:26<02:13,  3.36it/s]\u001b[A\n",
      " 17%|████████████████████████████▋                                                                                                                                            | 91/537 [00:27<02:12,  3.35it/s]\u001b[A\n",
      " 17%|████████████████████████████▉                                                                                                                                            | 92/537 [00:27<02:12,  3.35it/s]\u001b[A\n",
      " 17%|█████████████████████████████▎                                                                                                                                           | 93/537 [00:27<02:12,  3.35it/s]\u001b[A\n",
      " 18%|█████████████████████████████▌                                                                                                                                           | 94/537 [00:28<02:12,  3.34it/s]\u001b[A\n",
      " 18%|█████████████████████████████▉                                                                                                                                           | 95/537 [00:28<02:12,  3.35it/s]\u001b[A\n",
      " 18%|██████████████████████████████▏                                                                                                                                          | 96/537 [00:28<02:11,  3.36it/s]\u001b[A\n",
      " 18%|██████████████████████████████▌                                                                                                                                          | 97/537 [00:29<02:11,  3.36it/s]\u001b[A\n",
      " 18%|██████████████████████████████▊                                                                                                                                          | 98/537 [00:29<02:10,  3.36it/s]\u001b[A\n",
      " 18%|███████████████████████████████▏                                                                                                                                         | 99/537 [00:29<02:10,  3.36it/s]\u001b[A\n",
      " 19%|███████████████████████████████▎                                                                                                                                        | 100/537 [00:29<02:09,  3.36it/s]\u001b[A\n",
      " 19%|███████████████████████████████▌                                                                                                                                        | 101/537 [00:30<02:09,  3.36it/s]\u001b[A\n",
      " 19%|███████████████████████████████▉                                                                                                                                        | 102/537 [00:30<02:09,  3.36it/s]\u001b[A\n",
      " 19%|████████████████████████████████▏                                                                                                                                       | 103/537 [00:30<02:09,  3.35it/s]\u001b[A\n",
      " 19%|████████████████████████████████▌                                                                                                                                       | 104/537 [00:31<02:09,  3.36it/s]\u001b[A\n",
      " 20%|████████████████████████████████▊                                                                                                                                       | 105/537 [00:31<02:08,  3.35it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▏                                                                                                                                      | 106/537 [00:31<02:08,  3.35it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▍                                                                                                                                      | 107/537 [00:31<02:08,  3.34it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▊                                                                                                                                      | 108/537 [00:32<02:08,  3.35it/s]\u001b[A\n",
      " 20%|██████████████████████████████████                                                                                                                                      | 109/537 [00:32<02:07,  3.36it/s]\u001b[A\n",
      " 20%|██████████████████████████████████▍                                                                                                                                     | 110/537 [00:32<02:07,  3.35it/s]\u001b[A\n",
      " 21%|██████████████████████████████████▋                                                                                                                                     | 111/537 [00:33<02:07,  3.35it/s]\u001b[A\n",
      " 21%|███████████████████████████████████                                                                                                                                     | 112/537 [00:33<02:07,  3.34it/s]\u001b[A\n",
      " 21%|███████████████████████████████████▎                                                                                                                                    | 113/537 [00:33<02:06,  3.35it/s]\u001b[A\n",
      " 21%|███████████████████████████████████▋                                                                                                                                    | 114/537 [00:34<02:06,  3.35it/s]\u001b[A\n",
      " 21%|███████████████████████████████████▉                                                                                                                                    | 115/537 [00:34<02:06,  3.35it/s]\u001b[A\n",
      " 22%|████████████████████████████████████▎                                                                                                                                   | 116/537 [00:34<02:05,  3.34it/s]\u001b[A\n",
      " 22%|████████████████████████████████████▌                                                                                                                                   | 117/537 [00:34<02:05,  3.34it/s]\u001b[A\n",
      " 22%|████████████████████████████████████▉                                                                                                                                   | 118/537 [00:35<02:05,  3.34it/s]\u001b[A\n",
      " 22%|█████████████████████████████████████▏                                                                                                                                  | 119/537 [00:35<02:04,  3.35it/s]\u001b[A\n",
      " 22%|█████████████████████████████████████▌                                                                                                                                  | 120/537 [00:35<02:04,  3.35it/s]\u001b[A\n",
      " 23%|█████████████████████████████████████▊                                                                                                                                  | 121/537 [00:36<02:04,  3.35it/s]\u001b[A\n",
      " 23%|██████████████████████████████████████▏                                                                                                                                 | 122/537 [00:36<02:04,  3.34it/s]\u001b[A\n",
      " 23%|██████████████████████████████████████▍                                                                                                                                 | 123/537 [00:36<02:03,  3.35it/s]\u001b[A\n",
      " 23%|██████████████████████████████████████▊                                                                                                                                 | 124/537 [00:37<02:03,  3.34it/s]\u001b[A\n",
      " 23%|███████████████████████████████████████                                                                                                                                 | 125/537 [00:37<02:03,  3.34it/s]\u001b[A\n",
      " 23%|███████████████████████████████████████▍                                                                                                                                | 126/537 [00:37<02:03,  3.33it/s]\u001b[A\n",
      " 24%|███████████████████████████████████████▋                                                                                                                                | 127/537 [00:37<02:02,  3.34it/s]\u001b[A\n",
      " 24%|████████████████████████████████████████                                                                                                                                | 128/537 [00:38<02:02,  3.34it/s]\u001b[A\n",
      " 24%|████████████████████████████████████████▎                                                                                                                               | 129/537 [00:38<02:01,  3.35it/s]\u001b[A\n",
      " 24%|████████████████████████████████████████▋                                                                                                                               | 130/537 [00:38<02:01,  3.35it/s]\u001b[A\n",
      " 24%|████████████████████████████████████████▉                                                                                                                               | 131/537 [00:39<02:01,  3.35it/s]\u001b[A\n",
      " 25%|█████████████████████████████████████████▎                                                                                                                              | 132/537 [00:39<02:01,  3.34it/s]\u001b[A\n",
      " 25%|█████████████████████████████████████████▌                                                                                                                              | 133/537 [00:39<02:00,  3.34it/s]\u001b[A\n",
      " 25%|█████████████████████████████████████████▉                                                                                                                              | 134/537 [00:40<02:00,  3.34it/s]\u001b[A\n",
      " 25%|██████████████████████████████████████████▏                                                                                                                             | 135/537 [00:40<02:00,  3.34it/s]\u001b[A\n",
      " 25%|██████████████████████████████████████████▌                                                                                                                             | 136/537 [00:40<02:00,  3.33it/s]\u001b[A\n",
      " 26%|██████████████████████████████████████████▊                                                                                                                             | 137/537 [00:40<02:00,  3.33it/s]\u001b[A\n",
      " 26%|███████████████████████████████████████████▏                                                                                                                            | 138/537 [00:41<02:00,  3.32it/s]\u001b[A\n",
      " 26%|███████████████████████████████████████████▍                                                                                                                            | 139/537 [00:41<01:59,  3.33it/s]\u001b[A\n",
      " 26%|███████████████████████████████████████████▊                                                                                                                            | 140/537 [00:41<01:58,  3.34it/s]\u001b[A\n",
      " 26%|████████████████████████████████████████████                                                                                                                            | 141/537 [00:42<01:58,  3.34it/s]\u001b[A\n",
      " 26%|████████████████████████████████████████████▍                                                                                                                           | 142/537 [00:42<01:58,  3.34it/s]\u001b[A\n",
      " 27%|████████████████████████████████████████████▋                                                                                                                           | 143/537 [00:42<01:57,  3.34it/s]\u001b[A\n",
      " 27%|█████████████████████████████████████████████                                                                                                                           | 144/537 [00:43<01:57,  3.34it/s]\u001b[A\n",
      " 27%|█████████████████████████████████████████████▎                                                                                                                          | 145/537 [00:43<01:57,  3.34it/s]\u001b[A\n",
      " 27%|█████████████████████████████████████████████▋                                                                                                                          | 146/537 [00:43<01:57,  3.34it/s]\u001b[A\n",
      " 27%|█████████████████████████████████████████████▉                                                                                                                          | 147/537 [00:43<01:56,  3.34it/s]\u001b[A\n",
      " 28%|██████████████████████████████████████████████▎                                                                                                                         | 148/537 [00:44<01:56,  3.34it/s]\u001b[A\n",
      " 28%|██████████████████████████████████████████████▌                                                                                                                         | 149/537 [00:44<01:56,  3.33it/s]\u001b[A\n",
      " 28%|██████████████████████████████████████████████▉                                                                                                                         | 150/537 [00:44<01:56,  3.33it/s]\u001b[A\n",
      " 28%|███████████████████████████████████████████████▏                                                                                                                        | 151/537 [00:45<01:55,  3.33it/s]\u001b[A\n",
      " 28%|███████████████████████████████████████████████▌                                                                                                                        | 152/537 [00:45<01:55,  3.33it/s]\u001b[A\n",
      " 28%|███████████████████████████████████████████████▊                                                                                                                        | 153/537 [00:45<01:55,  3.34it/s]\u001b[A\n",
      " 29%|████████████████████████████████████████████████▏                                                                                                                       | 154/537 [00:46<01:54,  3.35it/s]\u001b[A\n",
      " 29%|████████████████████████████████████████████████▍                                                                                                                       | 155/537 [00:46<01:54,  3.35it/s]\u001b[A\n",
      " 29%|████████████████████████████████████████████████▊                                                                                                                       | 156/537 [00:46<01:54,  3.34it/s]\u001b[A\n",
      " 29%|█████████████████████████████████████████████████                                                                                                                       | 157/537 [00:46<01:53,  3.34it/s]\u001b[A\n",
      " 29%|█████████████████████████████████████████████████▍                                                                                                                      | 158/537 [00:47<01:53,  3.34it/s]\u001b[A\n",
      " 30%|█████████████████████████████████████████████████▋                                                                                                                      | 159/537 [00:47<01:52,  3.35it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████████                                                                                                                      | 160/537 [00:47<01:52,  3.34it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████████▎                                                                                                                     | 161/537 [00:48<01:52,  3.34it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████████▋                                                                                                                     | 162/537 [00:48<01:52,  3.33it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████████▉                                                                                                                     | 163/537 [00:48<01:51,  3.34it/s]\u001b[A\n",
      " 31%|███████████████████████████████████████████████████▎                                                                                                                    | 164/537 [00:49<01:51,  3.34it/s]\u001b[A\n",
      " 31%|███████████████████████████████████████████████████▌                                                                                                                    | 165/537 [00:49<01:51,  3.34it/s]\u001b[A\n",
      " 31%|███████████████████████████████████████████████████▉                                                                                                                    | 166/537 [00:49<01:50,  3.34it/s]\u001b[A\n",
      " 31%|████████████████████████████████████████████████████▏                                                                                                                   | 167/537 [00:49<01:50,  3.34it/s]\u001b[A\n",
      " 31%|████████████████████████████████████████████████████▌                                                                                                                   | 168/537 [00:50<01:50,  3.34it/s]\u001b[A\n",
      " 31%|████████████████████████████████████████████████████▊                                                                                                                   | 169/537 [00:50<01:50,  3.33it/s]\u001b[A\n",
      " 32%|█████████████████████████████████████████████████████▏                                                                                                                  | 170/537 [00:50<01:49,  3.34it/s]\u001b[A\n",
      " 32%|█████████████████████████████████████████████████████▍                                                                                                                  | 171/537 [00:51<01:49,  3.34it/s]\u001b[A\n",
      " 32%|█████████████████████████████████████████████████████▊                                                                                                                  | 172/537 [00:51<01:49,  3.35it/s]\u001b[A\n",
      " 32%|██████████████████████████████████████████████████████                                                                                                                  | 173/537 [00:51<01:48,  3.35it/s]\u001b[A\n",
      " 32%|██████████████████████████████████████████████████████▍                                                                                                                 | 174/537 [00:52<01:48,  3.35it/s]\u001b[A\n",
      " 33%|██████████████████████████████████████████████████████▋                                                                                                                 | 175/537 [00:52<01:48,  3.34it/s]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████                                                                                                                 | 176/537 [00:52<01:47,  3.34it/s]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████▎                                                                                                                | 177/537 [00:52<01:47,  3.34it/s]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████▋                                                                                                                | 178/537 [00:53<01:47,  3.35it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████                                                                                                                | 179/537 [00:53<01:47,  3.34it/s]\u001b[A\n",
      " 34%|████████████████████████████████████████████████████████▎                                                                                                               | 180/537 [00:53<01:47,  3.33it/s]\u001b[A\n",
      " 34%|████████████████████████████████████████████████████████▋                                                                                                               | 181/537 [00:54<01:47,  3.33it/s]\u001b[A\n",
      " 34%|████████████████████████████████████████████████████████▉                                                                                                               | 182/537 [00:54<01:46,  3.32it/s]\u001b[A\n",
      " 34%|█████████████████████████████████████████████████████████▎                                                                                                              | 183/537 [00:54<01:46,  3.32it/s]\u001b[A\n",
      " 34%|█████████████████████████████████████████████████████████▌                                                                                                              | 184/537 [00:55<01:45,  3.33it/s]\u001b[A\n",
      " 34%|█████████████████████████████████████████████████████████▉                                                                                                              | 185/537 [00:55<01:45,  3.34it/s]\u001b[A\n",
      " 35%|██████████████████████████████████████████████████████████▏                                                                                                             | 186/537 [00:55<01:44,  3.35it/s]\u001b[A\n",
      " 35%|██████████████████████████████████████████████████████████▌                                                                                                             | 187/537 [00:55<01:44,  3.34it/s]\u001b[A\n",
      " 35%|██████████████████████████████████████████████████████████▊                                                                                                             | 188/537 [00:56<01:44,  3.34it/s]\u001b[A\n",
      " 35%|███████████████████████████████████████████████████████████▏                                                                                                            | 189/537 [00:56<01:44,  3.34it/s]\u001b[A\n",
      " 35%|███████████████████████████████████████████████████████████▍                                                                                                            | 190/537 [00:56<01:44,  3.33it/s]\u001b[A\n",
      " 36%|███████████████████████████████████████████████████████████▊                                                                                                            | 191/537 [00:57<01:43,  3.33it/s]\u001b[A\n",
      " 36%|████████████████████████████████████████████████████████████                                                                                                            | 192/537 [00:57<01:43,  3.34it/s]\u001b[A\n",
      " 36%|████████████████████████████████████████████████████████████▍                                                                                                           | 193/537 [00:57<01:42,  3.35it/s]\u001b[A\n",
      " 36%|████████████████████████████████████████████████████████████▋                                                                                                           | 194/537 [00:58<01:42,  3.34it/s]\u001b[A\n",
      " 36%|█████████████████████████████████████████████████████████████                                                                                                           | 195/537 [00:58<01:42,  3.33it/s]\u001b[A\n",
      " 36%|█████████████████████████████████████████████████████████████▎                                                                                                          | 196/537 [00:58<01:42,  3.33it/s]\u001b[A\n",
      " 37%|█████████████████████████████████████████████████████████████▋                                                                                                          | 197/537 [00:58<01:42,  3.33it/s]\u001b[A\n",
      " 37%|█████████████████████████████████████████████████████████████▉                                                                                                          | 198/537 [00:59<01:41,  3.33it/s]\u001b[A\n",
      " 37%|██████████████████████████████████████████████████████████████▎                                                                                                         | 199/537 [00:59<01:41,  3.33it/s]\u001b[A\n",
      " 37%|██████████████████████████████████████████████████████████████▌                                                                                                         | 200/537 [00:59<01:41,  3.33it/s]\u001b[A\n",
      " 37%|██████████████████████████████████████████████████████████████▉                                                                                                         | 201/537 [01:00<01:41,  3.32it/s]\u001b[A\n",
      " 38%|███████████████████████████████████████████████████████████████▏                                                                                                        | 202/537 [01:00<01:40,  3.32it/s]\u001b[A\n",
      " 38%|███████████████████████████████████████████████████████████████▌                                                                                                        | 203/537 [01:00<01:40,  3.33it/s]\u001b[A\n",
      " 38%|███████████████████████████████████████████████████████████████▊                                                                                                        | 204/537 [01:01<01:39,  3.33it/s]\u001b[A\n",
      " 38%|████████████████████████████████████████████████████████████████▏                                                                                                       | 205/537 [01:01<01:39,  3.34it/s]\u001b[A\n",
      " 38%|████████████████████████████████████████████████████████████████▍                                                                                                       | 206/537 [01:01<01:39,  3.34it/s]\u001b[A\n",
      " 39%|████████████████████████████████████████████████████████████████▊                                                                                                       | 207/537 [01:01<01:38,  3.34it/s]\u001b[A\n",
      " 39%|█████████████████████████████████████████████████████████████████                                                                                                       | 208/537 [01:02<01:38,  3.34it/s]\u001b[A\n",
      " 39%|█████████████████████████████████████████████████████████████████▍                                                                                                      | 209/537 [01:02<01:38,  3.34it/s]\u001b[A\n",
      " 39%|█████████████████████████████████████████████████████████████████▋                                                                                                      | 210/537 [01:02<01:37,  3.35it/s]\u001b[A\n",
      " 39%|██████████████████████████████████████████████████████████████████                                                                                                      | 211/537 [01:03<01:37,  3.34it/s]\u001b[A\n",
      " 39%|██████████████████████████████████████████████████████████████████▎                                                                                                     | 212/537 [01:03<01:37,  3.33it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████████▋                                                                                                     | 213/537 [01:03<01:37,  3.33it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████████▉                                                                                                     | 214/537 [01:04<01:36,  3.33it/s]\u001b[A\n",
      " 40%|███████████████████████████████████████████████████████████████████▎                                                                                                    | 215/537 [01:04<01:36,  3.33it/s]\u001b[A\n",
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                    | 216/537 [01:04<01:36,  3.33it/s]\u001b[A\n",
      " 40%|███████████████████████████████████████████████████████████████████▉                                                                                                    | 217/537 [01:04<01:36,  3.33it/s]\u001b[A\n",
      " 41%|████████████████████████████████████████████████████████████████████▏                                                                                                   | 218/537 [01:05<01:35,  3.33it/s]\u001b[A\n",
      " 41%|████████████████████████████████████████████████████████████████████▌                                                                                                   | 219/537 [01:05<01:35,  3.33it/s]\u001b[A\n",
      " 41%|████████████████████████████████████████████████████████████████████▊                                                                                                   | 220/537 [01:05<01:35,  3.33it/s]\u001b[A\n",
      " 41%|█████████████████████████████████████████████████████████████████████▏                                                                                                  | 221/537 [01:06<01:34,  3.34it/s]\u001b[A\n",
      " 41%|█████████████████████████████████████████████████████████████████████▍                                                                                                  | 222/537 [01:06<01:34,  3.33it/s]\u001b[A\n",
      " 42%|█████████████████████████████████████████████████████████████████████▊                                                                                                  | 223/537 [01:06<01:34,  3.33it/s]\u001b[A\n",
      " 42%|██████████████████████████████████████████████████████████████████████                                                                                                  | 224/537 [01:07<01:34,  3.32it/s]\u001b[A\n",
      " 42%|██████████████████████████████████████████████████████████████████████▍                                                                                                 | 225/537 [01:07<01:34,  3.32it/s]\u001b[A\n",
      " 42%|██████████████████████████████████████████████████████████████████████▋                                                                                                 | 226/537 [01:07<01:33,  3.32it/s]\u001b[A\n",
      " 42%|███████████████████████████████████████████████████████████████████████                                                                                                 | 227/537 [01:07<01:33,  3.33it/s]\u001b[A\n",
      " 42%|███████████████████████████████████████████████████████████████████████▎                                                                                                | 228/537 [01:08<01:32,  3.33it/s]\u001b[A\n",
      " 43%|███████████████████████████████████████████████████████████████████████▋                                                                                                | 229/537 [01:08<01:32,  3.32it/s]\u001b[A\n",
      " 43%|███████████████████████████████████████████████████████████████████████▉                                                                                                | 230/537 [01:08<01:32,  3.33it/s]\u001b[A\n",
      " 43%|████████████████████████████████████████████████████████████████████████▎                                                                                               | 231/537 [01:09<01:31,  3.34it/s]\u001b[A\n",
      " 43%|████████████████████████████████████████████████████████████████████████▌                                                                                               | 232/537 [01:09<01:31,  3.34it/s]\u001b[A\n",
      " 43%|████████████████████████████████████████████████████████████████████████▉                                                                                               | 233/537 [01:09<01:31,  3.34it/s]\u001b[A\n",
      " 44%|█████████████████████████████████████████████████████████████████████████▏                                                                                              | 234/537 [01:10<01:30,  3.34it/s]\u001b[A\n",
      " 44%|█████████████████████████████████████████████████████████████████████████▌                                                                                              | 235/537 [01:10<01:30,  3.33it/s]\u001b[A\n",
      " 44%|█████████████████████████████████████████████████████████████████████████▊                                                                                              | 236/537 [01:10<01:30,  3.33it/s]\u001b[A\n",
      " 44%|██████████████████████████████████████████████████████████████████████████▏                                                                                             | 237/537 [01:10<01:30,  3.33it/s]\u001b[A\n",
      " 44%|██████████████████████████████████████████████████████████████████████████▍                                                                                             | 238/537 [01:11<01:29,  3.33it/s]\u001b[A\n",
      " 45%|██████████████████████████████████████████████████████████████████████████▊                                                                                             | 239/537 [01:11<01:29,  3.34it/s]\u001b[A\n",
      " 45%|███████████████████████████████████████████████████████████████████████████                                                                                             | 240/537 [01:11<01:29,  3.34it/s]\u001b[A\n",
      " 45%|███████████████████████████████████████████████████████████████████████████▍                                                                                            | 241/537 [01:12<01:28,  3.34it/s]\u001b[A\n",
      " 45%|███████████████████████████████████████████████████████████████████████████▋                                                                                            | 242/537 [01:12<01:28,  3.34it/s]\u001b[A\n",
      " 45%|████████████████████████████████████████████████████████████████████████████                                                                                            | 243/537 [01:12<01:28,  3.34it/s]\u001b[A\n",
      " 45%|████████████████████████████████████████████████████████████████████████████▎                                                                                           | 244/537 [01:13<01:27,  3.33it/s]\u001b[A\n",
      " 46%|████████████████████████████████████████████████████████████████████████████▋                                                                                           | 245/537 [01:13<01:27,  3.33it/s]\u001b[A\n",
      " 46%|████████████████████████████████████████████████████████████████████████████▉                                                                                           | 246/537 [01:13<01:27,  3.33it/s]\u001b[A\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▎                                                                                          | 247/537 [01:13<01:27,  3.33it/s]\u001b[A\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▌                                                                                          | 248/537 [01:14<01:26,  3.33it/s]\u001b[A\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▉                                                                                          | 249/537 [01:14<01:26,  3.34it/s]\u001b[A\n",
      " 47%|██████████████████████████████████████████████████████████████████████████████▏                                                                                         | 250/537 [01:14<01:25,  3.34it/s]\u001b[A\n",
      " 47%|██████████████████████████████████████████████████████████████████████████████▌                                                                                         | 251/537 [01:15<01:25,  3.34it/s]\u001b[A\n",
      " 47%|██████████████████████████████████████████████████████████████████████████████▊                                                                                         | 252/537 [01:15<01:25,  3.33it/s]\u001b[A\n",
      " 47%|███████████████████████████████████████████████████████████████████████████████▏                                                                                        | 253/537 [01:15<01:25,  3.34it/s]\u001b[A\n",
      " 47%|███████████████████████████████████████████████████████████████████████████████▍                                                                                        | 254/537 [01:16<01:24,  3.34it/s]\u001b[A\n",
      " 47%|███████████████████████████████████████████████████████████████████████████████▊                                                                                        | 255/537 [01:16<01:24,  3.34it/s]\u001b[A\n",
      " 48%|████████████████████████████████████████████████████████████████████████████████                                                                                        | 256/537 [01:16<01:24,  3.34it/s]\u001b[A\n",
      " 48%|████████████████████████████████████████████████████████████████████████████████▍                                                                                       | 257/537 [01:16<01:23,  3.33it/s]\u001b[A\n",
      " 48%|████████████████████████████████████████████████████████████████████████████████▋                                                                                       | 258/537 [01:17<01:23,  3.34it/s]\u001b[A\n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████                                                                                       | 259/537 [01:17<01:23,  3.33it/s]\u001b[A\n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████▎                                                                                      | 260/537 [01:17<01:23,  3.33it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 261/537 [01:18<01:22,  3.33it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████████████████████████████████████████████████▉                                                                                      | 262/537 [01:18<01:22,  3.33it/s]\u001b[A\n",
      " 49%|██████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 263/537 [01:18<01:22,  3.34it/s]\u001b[A\n",
      " 49%|██████████████████████████████████████████████████████████████████████████████████▌                                                                                     | 264/537 [01:19<01:21,  3.34it/s]\u001b[A\n",
      " 49%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                     | 265/537 [01:19<01:21,  3.34it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████▏                                                                                    | 266/537 [01:19<01:21,  3.33it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 267/537 [01:19<01:21,  3.32it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 268/537 [01:20<01:20,  3.32it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 269/537 [01:20<01:20,  3.33it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 270/537 [01:20<01:20,  3.33it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 271/537 [01:21<01:19,  3.33it/s]\u001b[A\n",
      " 51%|█████████████████████████████████████████████████████████████████████████████████████                                                                                   | 272/537 [01:21<01:19,  3.33it/s]\u001b[A\n",
      " 51%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 273/537 [01:21<01:19,  3.32it/s]\u001b[A\n",
      " 51%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 274/537 [01:22<01:19,  3.33it/s]\u001b[A\n",
      " 51%|██████████████████████████████████████████████████████████████████████████████████████                                                                                  | 275/537 [01:22<01:18,  3.33it/s]\u001b[A\n",
      " 51%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 276/537 [01:22<01:18,  3.33it/s]\u001b[A\n",
      " 52%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 277/537 [01:22<01:18,  3.33it/s]\u001b[A\n",
      " 52%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 278/537 [01:23<01:17,  3.33it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 279/537 [01:23<01:17,  3.33it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 280/537 [01:23<01:17,  3.33it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 281/537 [01:24<01:16,  3.34it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 282/537 [01:24<01:16,  3.34it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████████████████████████████████████████████████████▌                                                                               | 283/537 [01:24<01:16,  3.33it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 284/537 [01:25<01:15,  3.33it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████▏                                                                              | 285/537 [01:25<01:15,  3.33it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 286/537 [01:25<01:15,  3.34it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████▊                                                                              | 287/537 [01:25<01:14,  3.34it/s]\u001b[A\n",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████                                                                              | 288/537 [01:26<01:14,  3.34it/s]\u001b[A\n",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████▍                                                                             | 289/537 [01:26<01:14,  3.34it/s]\u001b[A\n",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████▋                                                                             | 290/537 [01:26<01:13,  3.34it/s]\u001b[A\n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████                                                                             | 291/537 [01:27<01:13,  3.34it/s]\u001b[A\n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                            | 292/537 [01:27<01:13,  3.33it/s]\u001b[A\n",
      " 55%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                            | 293/537 [01:27<01:13,  3.34it/s]\u001b[A\n",
      " 55%|███████████████████████████████████████████████████████████████████████████████████████████▉                                                                            | 294/537 [01:28<01:12,  3.33it/s]\u001b[A\n",
      " 55%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                           | 295/537 [01:28<01:12,  3.33it/s]\u001b[A\n",
      " 55%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                           | 296/537 [01:28<01:12,  3.34it/s]\u001b[A\n",
      " 55%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 297/537 [01:28<01:11,  3.34it/s]\u001b[A\n",
      " 55%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                          | 298/537 [01:29<01:11,  3.34it/s]\u001b[A\n",
      " 56%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 299/537 [01:29<01:11,  3.33it/s]\u001b[A\n",
      " 56%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                          | 300/537 [01:29<01:11,  3.33it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 301/537 [01:30<01:10,  3.33it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                         | 302/537 [01:30<01:10,  3.33it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 303/537 [01:30<01:10,  3.33it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 304/537 [01:31<01:10,  3.32it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 305/537 [01:31<01:09,  3.32it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 306/537 [01:31<01:09,  3.33it/s]\u001b[A\n",
      " 57%|████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 307/537 [01:31<01:09,  3.33it/s]\u001b[A\n",
      " 57%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 308/537 [01:32<01:08,  3.33it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 309/537 [01:32<01:08,  3.33it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 310/537 [01:32<01:08,  3.33it/s]\u001b[A\n",
      " 58%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 311/537 [01:33<01:07,  3.33it/s]\u001b[A\n",
      " 58%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 312/537 [01:33<01:07,  3.33it/s]\u001b[A\n",
      " 58%|█████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 313/537 [01:33<01:07,  3.33it/s]\u001b[A\n",
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 314/537 [01:34<01:07,  3.32it/s]\u001b[A\n",
      " 59%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 315/537 [01:34<01:06,  3.32it/s]\u001b[A\n",
      " 59%|██████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 316/537 [01:34<01:06,  3.32it/s]\u001b[A\n",
      " 59%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 317/537 [01:34<01:06,  3.33it/s]\u001b[A\n",
      " 59%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 318/537 [01:35<01:05,  3.33it/s]\u001b[A\n",
      " 59%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                    | 319/537 [01:35<01:05,  3.33it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 320/537 [01:35<01:05,  3.33it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 321/537 [01:36<01:04,  3.33it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 322/537 [01:36<01:04,  3.33it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 323/537 [01:36<01:04,  3.33it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 324/537 [01:37<01:03,  3.33it/s]\u001b[A\n",
      " 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                  | 325/537 [01:37<01:03,  3.33it/s]\u001b[A\n",
      " 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                  | 326/537 [01:37<01:03,  3.34it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                 | 327/537 [01:37<01:02,  3.34it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                 | 328/537 [01:38<01:02,  3.34it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                 | 329/537 [01:38<01:02,  3.33it/s]\u001b[A\n",
      " 61%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                | 330/537 [01:38<01:02,  3.34it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                | 331/537 [01:39<01:01,  3.33it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                | 332/537 [01:39<01:01,  3.33it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 333/537 [01:39<01:01,  3.33it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                               | 334/537 [01:40<01:01,  3.33it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 335/537 [01:40<01:00,  3.33it/s]\u001b[A\n",
      " 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 336/537 [01:40<01:00,  3.33it/s]\u001b[A\n",
      " 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 337/537 [01:40<01:00,  3.33it/s]\u001b[A\n",
      " 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                              | 338/537 [01:41<00:59,  3.33it/s]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 339/537 [01:41<00:59,  3.33it/s]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                             | 340/537 [01:41<00:59,  3.32it/s]\u001b[A\n",
      " 64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 341/537 [01:42<00:58,  3.33it/s]\u001b[A\n",
      " 64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 342/537 [01:42<00:58,  3.33it/s]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 343/537 [01:42<00:57,  3.35it/s]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 344/537 [01:43<00:57,  3.35it/s]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 345/537 [01:43<00:57,  3.35it/s]\u001b[A\n",
      " 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 346/537 [01:43<00:57,  3.34it/s]\u001b[A\n",
      " 65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 347/537 [01:43<00:56,  3.34it/s]\u001b[A\n",
      " 65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 348/537 [01:44<00:56,  3.34it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 349/537 [01:44<00:56,  3.34it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 350/537 [01:44<00:55,  3.34it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 351/537 [01:45<00:55,  3.33it/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 352/537 [01:45<00:55,  3.33it/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 353/537 [01:45<00:55,  3.34it/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 354/537 [01:46<00:54,  3.33it/s]\u001b[A\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 355/537 [01:46<00:54,  3.33it/s]\u001b[A\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 356/537 [01:46<00:54,  3.33it/s]\u001b[A\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 357/537 [01:46<00:54,  3.33it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                        | 358/537 [01:47<00:53,  3.33it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 359/537 [01:47<00:53,  3.34it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                       | 360/537 [01:47<00:52,  3.34it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                       | 361/537 [01:48<00:52,  3.34it/s]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 362/537 [01:48<00:52,  3.33it/s]\u001b[A\n",
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                      | 363/537 [01:48<00:52,  3.34it/s]\u001b[A\n",
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 364/537 [01:49<00:51,  3.33it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                     | 365/537 [01:49<00:51,  3.33it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 366/537 [01:49<00:51,  3.33it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                     | 367/537 [01:49<00:51,  3.33it/s]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 368/537 [01:50<00:50,  3.34it/s]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                    | 369/537 [01:50<00:50,  3.33it/s]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 370/537 [01:50<00:50,  3.33it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 371/537 [01:51<00:49,  3.33it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 372/537 [01:51<00:49,  3.34it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 373/537 [01:51<00:49,  3.34it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 374/537 [01:52<00:48,  3.34it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 375/537 [01:52<00:48,  3.34it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 376/537 [01:52<00:48,  3.34it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 377/537 [01:52<00:47,  3.34it/s]\u001b[A\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 378/537 [01:53<00:47,  3.34it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 379/537 [01:53<00:47,  3.34it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 380/537 [01:53<00:47,  3.34it/s]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 381/537 [01:54<00:46,  3.33it/s]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 382/537 [01:54<00:46,  3.33it/s]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 383/537 [01:54<00:46,  3.33it/s]\u001b[A\n",
      " 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                               | 384/537 [01:55<00:45,  3.33it/s]\u001b[A\n",
      " 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 385/537 [01:55<00:45,  3.34it/s]\u001b[A\n",
      " 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 386/537 [01:55<00:45,  3.34it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 387/537 [01:55<00:44,  3.34it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                              | 388/537 [01:56<00:44,  3.34it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 389/537 [01:56<00:44,  3.34it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                              | 390/537 [01:56<00:43,  3.34it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                             | 391/537 [01:57<00:43,  3.35it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 392/537 [01:57<00:43,  3.34it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                             | 393/537 [01:57<00:43,  3.34it/s]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                            | 394/537 [01:58<00:42,  3.34it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                            | 395/537 [01:58<00:42,  3.34it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                            | 396/537 [01:58<00:42,  3.34it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                           | 397/537 [01:58<00:41,  3.34it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 398/537 [01:59<00:41,  3.34it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                           | 399/537 [01:59<00:41,  3.33it/s]\u001b[A\n",
      " 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 400/537 [01:59<00:41,  3.33it/s]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                          | 401/537 [02:00<00:40,  3.33it/s]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 402/537 [02:00<00:40,  3.33it/s]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                          | 403/537 [02:00<00:40,  3.34it/s]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 404/537 [02:01<00:39,  3.35it/s]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                         | 405/537 [02:01<00:39,  3.35it/s]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 406/537 [02:01<00:39,  3.34it/s]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 407/537 [02:01<00:38,  3.35it/s]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 408/537 [02:02<00:38,  3.34it/s]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 409/537 [02:02<00:38,  3.35it/s]\u001b[A\n",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 410/537 [02:02<00:38,  3.34it/s]\u001b[A\n",
      " 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 411/537 [02:03<00:37,  3.34it/s]\u001b[A\n",
      " 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 412/537 [02:03<00:37,  3.34it/s]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 413/537 [02:03<00:37,  3.34it/s]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 414/537 [02:04<00:36,  3.33it/s]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 415/537 [02:04<00:36,  3.33it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 416/537 [02:04<00:36,  3.34it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 417/537 [02:04<00:35,  3.34it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 418/537 [02:05<00:35,  3.34it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 419/537 [02:05<00:35,  3.34it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 420/537 [02:05<00:35,  3.33it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 421/537 [02:06<00:34,  3.33it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                    | 422/537 [02:06<00:34,  3.32it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 423/537 [02:06<00:34,  3.33it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                   | 424/537 [02:07<00:33,  3.33it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 425/537 [02:07<00:33,  3.33it/s]\u001b[A\n",
      " 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                  | 426/537 [02:07<00:33,  3.34it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 427/537 [02:07<00:32,  3.34it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                  | 428/537 [02:08<00:32,  3.33it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 429/537 [02:08<00:32,  3.33it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 430/537 [02:08<00:32,  3.33it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 431/537 [02:09<00:31,  3.33it/s]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                | 432/537 [02:09<00:31,  3.34it/s]\u001b[A\n",
      " 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                | 433/537 [02:09<00:31,  3.34it/s]\u001b[A\n",
      " 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 434/537 [02:10<00:30,  3.34it/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                | 435/537 [02:10<00:30,  3.34it/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 436/537 [02:10<00:30,  3.34it/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                               | 437/537 [02:10<00:29,  3.34it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 438/537 [02:11<00:29,  3.33it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                              | 439/537 [02:11<00:29,  3.33it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 440/537 [02:11<00:29,  3.33it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                              | 441/537 [02:12<00:28,  3.34it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 442/537 [02:12<00:28,  3.35it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 443/537 [02:12<00:28,  3.35it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 444/537 [02:13<00:27,  3.35it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 445/537 [02:13<00:27,  3.34it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 446/537 [02:13<00:27,  3.34it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 447/537 [02:13<00:26,  3.34it/s]\u001b[A\n",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 448/537 [02:14<00:26,  3.33it/s]\u001b[A\n",
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 449/537 [02:14<00:26,  3.34it/s]\u001b[A\n",
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 450/537 [02:14<00:26,  3.34it/s]\u001b[A\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 451/537 [02:15<00:25,  3.34it/s]\u001b[A\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 452/537 [02:15<00:25,  3.33it/s]\u001b[A\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 453/537 [02:15<00:25,  3.33it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 454/537 [02:16<00:24,  3.33it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 455/537 [02:16<00:24,  3.34it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                         | 456/537 [02:16<00:24,  3.34it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 457/537 [02:16<00:23,  3.34it/s]\u001b[A\n",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                        | 458/537 [02:17<00:23,  3.34it/s]\u001b[A\n",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 459/537 [02:17<00:23,  3.34it/s]\u001b[A\n",
      " 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                        | 460/537 [02:17<00:23,  3.35it/s]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 461/537 [02:18<00:22,  3.34it/s]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                       | 462/537 [02:18<00:22,  3.35it/s]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 463/537 [02:18<00:22,  3.34it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                      | 464/537 [02:19<00:21,  3.34it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                      | 465/537 [02:19<00:21,  3.35it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                      | 466/537 [02:19<00:21,  3.34it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 467/537 [02:19<00:20,  3.34it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 468/537 [02:20<00:20,  3.34it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                     | 469/537 [02:20<00:20,  3.34it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                     | 470/537 [02:20<00:20,  3.35it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                    | 471/537 [02:21<00:19,  3.34it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 472/537 [02:21<00:19,  3.33it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                    | 473/537 [02:21<00:19,  3.33it/s]\u001b[A\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 474/537 [02:22<00:18,  3.33it/s]\u001b[A\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                   | 475/537 [02:22<00:18,  3.33it/s]\u001b[A\n",
      " 89%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 476/537 [02:22<00:18,  3.33it/s]\u001b[A\n",
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                  | 477/537 [02:22<00:18,  3.33it/s]\u001b[A\n",
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 478/537 [02:23<00:17,  3.34it/s]\u001b[A\n",
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 479/537 [02:23<00:17,  3.34it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 480/537 [02:23<00:17,  3.34it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 481/537 [02:24<00:16,  3.33it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 482/537 [02:24<00:16,  3.33it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 483/537 [02:24<00:16,  3.34it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 484/537 [02:25<00:15,  3.34it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 485/537 [02:25<00:15,  3.35it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 486/537 [02:25<00:15,  3.34it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 487/537 [02:25<00:14,  3.34it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 488/537 [02:26<00:14,  3.34it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 489/537 [02:26<00:14,  3.33it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 490/537 [02:26<00:14,  3.34it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 491/537 [02:27<00:13,  3.33it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 492/537 [02:27<00:13,  3.33it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 493/537 [02:27<00:13,  3.34it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 494/537 [02:28<00:12,  3.33it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 495/537 [02:28<00:12,  3.33it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 496/537 [02:28<00:12,  3.33it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 497/537 [02:28<00:11,  3.33it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 498/537 [02:29<00:11,  3.33it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 499/537 [02:29<00:11,  3.34it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 500/537 [02:29<00:11,  3.34it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 501/537 [02:30<00:10,  3.34it/s]\u001b[A\n",
      " 93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 502/537 [02:30<00:10,  3.34it/s]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 503/537 [02:30<00:10,  3.34it/s]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 504/537 [02:31<00:09,  3.33it/s]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 505/537 [02:31<00:09,  3.33it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 506/537 [02:31<00:09,  3.33it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌         | 507/537 [02:31<00:08,  3.34it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 508/537 [02:32<00:08,  3.35it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 509/537 [02:32<00:08,  3.35it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 510/537 [02:32<00:08,  3.35it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 511/537 [02:33<00:07,  3.35it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 512/537 [02:33<00:07,  3.34it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 513/537 [02:33<00:07,  3.34it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 514/537 [02:33<00:06,  3.34it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 515/537 [02:34<00:06,  3.34it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 516/537 [02:34<00:06,  3.34it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 517/537 [02:34<00:05,  3.34it/s]\u001b[A\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 518/537 [02:35<00:05,  3.34it/s]\u001b[A\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 519/537 [02:35<00:05,  3.33it/s]\u001b[A\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 520/537 [02:35<00:05,  3.34it/s]\u001b[A\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 521/537 [02:36<00:04,  3.34it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 522/537 [02:36<00:04,  3.34it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 523/537 [02:36<00:04,  3.34it/s]\u001b[A\n",
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 524/537 [02:36<00:03,  3.33it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 525/537 [02:37<00:03,  3.34it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 526/537 [02:37<00:03,  3.35it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 527/537 [02:37<00:02,  3.34it/s]\u001b[A\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 528/537 [02:38<00:02,  3.34it/s]\u001b[A\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 529/537 [02:38<00:02,  3.34it/s]\u001b[A\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 530/537 [02:38<00:02,  3.33it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 531/537 [02:39<00:01,  3.34it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 532/537 [02:39<00:01,  3.34it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 533/537 [02:39<00:01,  3.34it/s]\u001b[A\n",
      " 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 534/537 [02:39<00:00,  3.34it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 535/537 [02:40<00:00,  3.35it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 536/537 [02:40<00:00,  3.34it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 537/537 [02:40<00:00,  3.34it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                                     | 1/2 [02:40<02:40, 160.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Average Loss: 0.1495675720357695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                  | 0/537 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                                                                                                         | 1/537 [00:00<04:44,  1.88it/s]\u001b[A\n",
      "  0%|▋                                                                                                                                                                         | 2/537 [00:00<03:31,  2.53it/s]\u001b[A\n",
      "  1%|▉                                                                                                                                                                         | 3/537 [00:01<03:07,  2.85it/s]\u001b[A\n",
      "  1%|█▎                                                                                                                                                                        | 4/537 [00:01<02:55,  3.03it/s]\u001b[A\n",
      "  1%|█▌                                                                                                                                                                        | 5/537 [00:01<02:49,  3.13it/s]\u001b[A\n",
      "  1%|█▉                                                                                                                                                                        | 6/537 [00:02<02:45,  3.20it/s]\u001b[A\n",
      "  1%|██▏                                                                                                                                                                       | 7/537 [00:02<02:43,  3.25it/s]\u001b[A\n",
      "  1%|██▌                                                                                                                                                                       | 8/537 [00:02<02:41,  3.28it/s]\u001b[A\n",
      "  2%|██▊                                                                                                                                                                       | 9/537 [00:02<02:40,  3.30it/s]\u001b[A\n",
      "  2%|███▏                                                                                                                                                                     | 10/537 [00:03<02:38,  3.32it/s]\u001b[A\n",
      "  2%|███▍                                                                                                                                                                     | 11/537 [00:03<02:38,  3.33it/s]\u001b[A\n",
      "  2%|███▊                                                                                                                                                                     | 12/537 [00:03<02:37,  3.34it/s]\u001b[A\n",
      "  2%|████                                                                                                                                                                     | 13/537 [00:04<02:37,  3.33it/s]\u001b[A\n",
      "  3%|████▍                                                                                                                                                                    | 14/537 [00:04<02:36,  3.33it/s]\u001b[A\n",
      "  3%|████▋                                                                                                                                                                    | 15/537 [00:04<02:36,  3.33it/s]\u001b[A\n",
      "  3%|█████                                                                                                                                                                    | 16/537 [00:05<02:36,  3.33it/s]\u001b[A\n",
      "  3%|█████▎                                                                                                                                                                   | 17/537 [00:05<02:35,  3.33it/s]\u001b[A\n",
      "  3%|█████▋                                                                                                                                                                   | 18/537 [00:05<02:35,  3.33it/s]\u001b[A\n",
      "  4%|█████▉                                                                                                                                                                   | 19/537 [00:05<02:35,  3.33it/s]\u001b[A\n",
      "  4%|██████▎                                                                                                                                                                  | 20/537 [00:06<02:35,  3.33it/s]\u001b[A\n",
      "  4%|██████▌                                                                                                                                                                  | 21/537 [00:06<02:34,  3.33it/s]\u001b[A\n",
      "  4%|██████▉                                                                                                                                                                  | 22/537 [00:06<02:34,  3.33it/s]\u001b[A\n",
      "  4%|███████▏                                                                                                                                                                 | 23/537 [00:07<02:34,  3.33it/s]\u001b[A\n",
      "  4%|███████▌                                                                                                                                                                 | 24/537 [00:07<02:33,  3.33it/s]\u001b[A\n",
      "  5%|███████▊                                                                                                                                                                 | 25/537 [00:07<02:33,  3.34it/s]\u001b[A\n",
      "  5%|████████▏                                                                                                                                                                | 26/537 [00:08<02:32,  3.34it/s]\u001b[A\n",
      "  5%|████████▍                                                                                                                                                                | 27/537 [00:08<02:32,  3.34it/s]\u001b[A\n",
      "  5%|████████▊                                                                                                                                                                | 28/537 [00:08<02:32,  3.34it/s]\u001b[A\n",
      "  5%|█████████▏                                                                                                                                                               | 29/537 [00:08<02:31,  3.35it/s]\u001b[A\n",
      "  6%|█████████▍                                                                                                                                                               | 30/537 [00:09<02:31,  3.35it/s]\u001b[A\n",
      "  6%|█████████▊                                                                                                                                                               | 31/537 [00:09<02:31,  3.34it/s]\u001b[A\n",
      "  6%|██████████                                                                                                                                                               | 32/537 [00:09<02:31,  3.34it/s]\u001b[A\n",
      "  6%|██████████▍                                                                                                                                                              | 33/537 [00:10<02:30,  3.35it/s]\u001b[A\n",
      "  6%|██████████▋                                                                                                                                                              | 34/537 [00:10<02:30,  3.35it/s]\u001b[A\n",
      "  7%|███████████                                                                                                                                                              | 35/537 [00:10<02:30,  3.34it/s]\u001b[A\n",
      "  7%|███████████▎                                                                                                                                                             | 36/537 [00:11<02:30,  3.34it/s]\u001b[A\n",
      "  7%|███████████▋                                                                                                                                                             | 37/537 [00:11<02:29,  3.34it/s]\u001b[A\n",
      "  7%|███████████▉                                                                                                                                                             | 38/537 [00:11<02:29,  3.34it/s]\u001b[A\n",
      "  7%|████████████▎                                                                                                                                                            | 39/537 [00:11<02:28,  3.34it/s]\u001b[A\n",
      "  7%|████████████▌                                                                                                                                                            | 40/537 [00:12<02:28,  3.34it/s]\u001b[A\n",
      "  8%|████████████▉                                                                                                                                                            | 41/537 [00:12<02:28,  3.34it/s]\u001b[A\n",
      "  8%|█████████████▏                                                                                                                                                           | 42/537 [00:12<02:28,  3.34it/s]\u001b[A\n",
      "  8%|█████████████▌                                                                                                                                                           | 43/537 [00:13<02:27,  3.35it/s]\u001b[A\n",
      "  8%|█████████████▊                                                                                                                                                           | 44/537 [00:13<02:27,  3.34it/s]\u001b[A\n",
      "  8%|██████████████▏                                                                                                                                                          | 45/537 [00:13<02:27,  3.34it/s]\u001b[A\n",
      "  9%|██████████████▍                                                                                                                                                          | 46/537 [00:13<02:27,  3.34it/s]\u001b[A\n",
      "  9%|██████████████▊                                                                                                                                                          | 47/537 [00:14<02:27,  3.33it/s]\u001b[A\n",
      "  9%|███████████████                                                                                                                                                          | 48/537 [00:14<02:26,  3.33it/s]\u001b[A\n",
      "  9%|███████████████▍                                                                                                                                                         | 49/537 [00:14<02:26,  3.34it/s]\u001b[A\n",
      "  9%|███████████████▋                                                                                                                                                         | 50/537 [00:15<02:25,  3.35it/s]\u001b[A\n",
      "  9%|████████████████                                                                                                                                                         | 51/537 [00:15<02:25,  3.34it/s]\u001b[A\n",
      " 10%|████████████████▎                                                                                                                                                        | 52/537 [00:15<02:24,  3.35it/s]\u001b[A\n",
      " 10%|████████████████▋                                                                                                                                                        | 53/537 [00:16<02:24,  3.35it/s]\u001b[A\n",
      " 10%|████████████████▉                                                                                                                                                        | 54/537 [00:16<02:24,  3.35it/s]\u001b[A\n",
      " 10%|█████████████████▎                                                                                                                                                       | 55/537 [00:16<02:24,  3.35it/s]\u001b[A\n",
      " 10%|█████████████████▌                                                                                                                                                       | 56/537 [00:16<02:23,  3.35it/s]\u001b[A\n",
      " 11%|█████████████████▉                                                                                                                                                       | 57/537 [00:17<02:23,  3.34it/s]\u001b[A\n",
      " 11%|██████████████████▎                                                                                                                                                      | 58/537 [00:17<02:23,  3.34it/s]\u001b[A\n",
      " 11%|██████████████████▌                                                                                                                                                      | 59/537 [00:17<02:23,  3.34it/s]\u001b[A\n",
      " 11%|██████████████████▉                                                                                                                                                      | 60/537 [00:18<02:22,  3.34it/s]\u001b[A\n",
      " 11%|███████████████████▏                                                                                                                                                     | 61/537 [00:18<02:22,  3.34it/s]\u001b[A\n",
      " 12%|███████████████████▌                                                                                                                                                     | 62/537 [00:18<02:22,  3.34it/s]\u001b[A\n",
      " 12%|███████████████████▊                                                                                                                                                     | 63/537 [00:19<02:21,  3.34it/s]\u001b[A\n",
      " 12%|████████████████████▏                                                                                                                                                    | 64/537 [00:19<02:21,  3.34it/s]\u001b[A\n",
      " 12%|████████████████████▍                                                                                                                                                    | 65/537 [00:19<02:20,  3.35it/s]\u001b[A\n",
      " 12%|████████████████████▊                                                                                                                                                    | 66/537 [00:19<02:20,  3.35it/s]\u001b[A\n",
      " 12%|█████████████████████                                                                                                                                                    | 67/537 [00:20<02:20,  3.36it/s]\u001b[A\n",
      " 13%|█████████████████████▍                                                                                                                                                   | 68/537 [00:20<02:19,  3.35it/s]\u001b[A\n",
      " 13%|█████████████████████▋                                                                                                                                                   | 69/537 [00:20<02:19,  3.35it/s]\u001b[A\n",
      " 13%|██████████████████████                                                                                                                                                   | 70/537 [00:21<02:19,  3.35it/s]\u001b[A\n",
      " 13%|██████████████████████▎                                                                                                                                                  | 71/537 [00:21<02:19,  3.34it/s]\u001b[A\n",
      " 13%|██████████████████████▋                                                                                                                                                  | 72/537 [00:21<02:18,  3.35it/s]\u001b[A\n",
      " 14%|██████████████████████▉                                                                                                                                                  | 73/537 [00:22<02:18,  3.36it/s]\u001b[A\n",
      " 14%|███████████████████████▎                                                                                                                                                 | 74/537 [00:22<02:18,  3.35it/s]\u001b[A\n",
      " 14%|███████████████████████▌                                                                                                                                                 | 75/537 [00:22<02:17,  3.35it/s]\u001b[A\n",
      " 14%|███████████████████████▉                                                                                                                                                 | 76/537 [00:22<02:17,  3.34it/s]\u001b[A\n",
      " 14%|████████████████████████▏                                                                                                                                                | 77/537 [00:23<02:17,  3.35it/s]\u001b[A\n",
      " 15%|████████████████████████▌                                                                                                                                                | 78/537 [00:23<02:17,  3.35it/s]\u001b[A\n",
      " 15%|████████████████████████▊                                                                                                                                                | 79/537 [00:23<02:16,  3.35it/s]\u001b[A\n",
      " 15%|█████████████████████████▏                                                                                                                                               | 80/537 [00:24<02:16,  3.35it/s]\u001b[A\n",
      " 15%|█████████████████████████▍                                                                                                                                               | 81/537 [00:24<02:16,  3.35it/s]\u001b[A\n",
      " 15%|█████████████████████████▊                                                                                                                                               | 82/537 [00:24<02:15,  3.35it/s]\u001b[A\n",
      " 15%|██████████████████████████                                                                                                                                               | 83/537 [00:25<02:15,  3.35it/s]\u001b[A\n",
      " 16%|██████████████████████████▍                                                                                                                                              | 84/537 [00:25<02:15,  3.34it/s]\u001b[A\n",
      " 16%|██████████████████████████▊                                                                                                                                              | 85/537 [00:25<02:15,  3.35it/s]\u001b[A\n",
      " 16%|███████████████████████████                                                                                                                                              | 86/537 [00:25<02:14,  3.35it/s]\u001b[A\n",
      " 16%|███████████████████████████▍                                                                                                                                             | 87/537 [00:26<02:14,  3.34it/s]\u001b[A\n",
      " 16%|███████████████████████████▋                                                                                                                                             | 88/537 [00:26<02:14,  3.34it/s]\u001b[A\n",
      " 17%|████████████████████████████                                                                                                                                             | 89/537 [00:26<02:14,  3.34it/s]\u001b[A\n",
      " 17%|████████████████████████████▎                                                                                                                                            | 90/537 [00:27<02:13,  3.34it/s]\u001b[A\n",
      " 17%|████████████████████████████▋                                                                                                                                            | 91/537 [00:27<02:13,  3.35it/s]\u001b[A\n",
      " 17%|████████████████████████████▉                                                                                                                                            | 92/537 [00:27<02:12,  3.35it/s]\u001b[A\n",
      " 17%|█████████████████████████████▎                                                                                                                                           | 93/537 [00:28<02:12,  3.35it/s]\u001b[A\n",
      " 18%|█████████████████████████████▌                                                                                                                                           | 94/537 [00:28<02:12,  3.34it/s]\u001b[A\n",
      " 18%|█████████████████████████████▉                                                                                                                                           | 95/537 [00:28<02:12,  3.34it/s]\u001b[A\n",
      " 18%|██████████████████████████████▏                                                                                                                                          | 96/537 [00:28<02:11,  3.34it/s]\u001b[A\n",
      " 18%|██████████████████████████████▌                                                                                                                                          | 97/537 [00:29<02:11,  3.35it/s]\u001b[A\n",
      " 18%|██████████████████████████████▊                                                                                                                                          | 98/537 [00:29<02:10,  3.35it/s]\u001b[A\n",
      " 18%|███████████████████████████████▏                                                                                                                                         | 99/537 [00:29<02:10,  3.35it/s]\u001b[A\n",
      " 19%|███████████████████████████████▎                                                                                                                                        | 100/537 [00:30<02:10,  3.34it/s]\u001b[A\n",
      " 19%|███████████████████████████████▌                                                                                                                                        | 101/537 [00:30<02:10,  3.34it/s]\u001b[A\n",
      " 19%|███████████████████████████████▉                                                                                                                                        | 102/537 [00:30<02:10,  3.34it/s]\u001b[A\n",
      " 19%|████████████████████████████████▏                                                                                                                                       | 103/537 [00:31<02:09,  3.35it/s]\u001b[A\n",
      " 19%|████████████████████████████████▌                                                                                                                                       | 104/537 [00:31<02:09,  3.35it/s]\u001b[A\n",
      " 20%|████████████████████████████████▊                                                                                                                                       | 105/537 [00:31<02:09,  3.34it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▏                                                                                                                                      | 106/537 [00:31<02:08,  3.34it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▍                                                                                                                                      | 107/537 [00:32<02:08,  3.34it/s]\u001b[A\n",
      " 20%|█████████████████████████████████▊                                                                                                                                      | 108/537 [00:32<02:08,  3.34it/s]\u001b[A\n",
      " 20%|██████████████████████████████████                                                                                                                                      | 109/537 [00:32<02:07,  3.35it/s]\u001b[A\n",
      " 20%|██████████████████████████████████▍                                                                                                                                     | 110/537 [00:33<02:07,  3.35it/s]\u001b[A\n",
      " 21%|██████████████████████████████████▋                                                                                                                                     | 111/537 [00:33<02:07,  3.35it/s]\u001b[A\n",
      " 21%|███████████████████████████████████                                                                                                                                     | 112/537 [00:33<02:06,  3.35it/s]\u001b[A\n",
      " 21%|███████████████████████████████████▎                                                                                                                                    | 113/537 [00:34<02:06,  3.35it/s]\u001b[A\n",
      " 21%|███████████████████████████████████▋                                                                                                                                    | 114/537 [00:34<02:06,  3.35it/s]\u001b[A\n",
      " 21%|███████████████████████████████████▉                                                                                                                                    | 115/537 [00:34<02:05,  3.36it/s]\u001b[A\n",
      " 22%|████████████████████████████████████▎                                                                                                                                   | 116/537 [00:34<02:05,  3.35it/s]\u001b[A\n",
      " 22%|████████████████████████████████████▌                                                                                                                                   | 117/537 [00:35<02:05,  3.35it/s]\u001b[A\n",
      " 22%|████████████████████████████████████▉                                                                                                                                   | 118/537 [00:35<02:05,  3.34it/s]\u001b[A\n",
      " 22%|█████████████████████████████████████▏                                                                                                                                  | 119/537 [00:35<02:04,  3.35it/s]\u001b[A\n",
      " 22%|█████████████████████████████████████▌                                                                                                                                  | 120/537 [00:36<02:04,  3.35it/s]\u001b[A\n",
      " 23%|█████████████████████████████████████▊                                                                                                                                  | 121/537 [00:36<02:04,  3.35it/s]\u001b[A\n",
      " 23%|██████████████████████████████████████▏                                                                                                                                 | 122/537 [00:36<02:04,  3.34it/s]\u001b[A\n",
      " 23%|██████████████████████████████████████▍                                                                                                                                 | 123/537 [00:37<02:03,  3.34it/s]\u001b[A\n",
      " 23%|██████████████████████████████████████▊                                                                                                                                 | 124/537 [00:37<02:03,  3.34it/s]\u001b[A\n",
      " 23%|███████████████████████████████████████                                                                                                                                 | 125/537 [00:37<02:03,  3.34it/s]\u001b[A\n",
      " 23%|███████████████████████████████████████▍                                                                                                                                | 126/537 [00:37<02:03,  3.33it/s]\u001b[A\n",
      " 24%|███████████████████████████████████████▋                                                                                                                                | 127/537 [00:38<02:02,  3.34it/s]\u001b[A\n",
      " 24%|████████████████████████████████████████                                                                                                                                | 128/537 [00:38<02:02,  3.34it/s]\u001b[A\n",
      " 24%|████████████████████████████████████████▎                                                                                                                               | 129/537 [00:38<02:01,  3.35it/s]\u001b[A\n",
      " 24%|████████████████████████████████████████▋                                                                                                                               | 130/537 [00:39<02:01,  3.34it/s]\u001b[A\n",
      " 24%|████████████████████████████████████████▉                                                                                                                               | 131/537 [00:39<02:01,  3.35it/s]\u001b[A\n",
      " 25%|█████████████████████████████████████████▎                                                                                                                              | 132/537 [00:39<02:00,  3.35it/s]\u001b[A\n",
      " 25%|█████████████████████████████████████████▌                                                                                                                              | 133/537 [00:39<02:00,  3.36it/s]\u001b[A\n",
      " 25%|█████████████████████████████████████████▉                                                                                                                              | 134/537 [00:40<02:00,  3.35it/s]\u001b[A\n",
      " 25%|██████████████████████████████████████████▏                                                                                                                             | 135/537 [00:40<02:00,  3.35it/s]\u001b[A\n",
      " 25%|██████████████████████████████████████████▌                                                                                                                             | 136/537 [00:40<01:59,  3.34it/s]\u001b[A\n",
      " 26%|██████████████████████████████████████████▊                                                                                                                             | 137/537 [00:41<01:59,  3.34it/s]\u001b[A\n",
      " 26%|███████████████████████████████████████████▏                                                                                                                            | 138/537 [00:41<01:59,  3.33it/s]\u001b[A\n",
      " 26%|███████████████████████████████████████████▍                                                                                                                            | 139/537 [00:41<01:59,  3.33it/s]\u001b[A\n",
      " 26%|███████████████████████████████████████████▊                                                                                                                            | 140/537 [00:42<01:59,  3.33it/s]\u001b[A\n",
      " 26%|████████████████████████████████████████████                                                                                                                            | 141/537 [00:42<01:58,  3.33it/s]\u001b[A\n",
      " 26%|████████████████████████████████████████████▍                                                                                                                           | 142/537 [00:42<01:58,  3.34it/s]\u001b[A\n",
      " 27%|████████████████████████████████████████████▋                                                                                                                           | 143/537 [00:42<01:57,  3.34it/s]\u001b[A\n",
      " 27%|█████████████████████████████████████████████                                                                                                                           | 144/537 [00:43<01:57,  3.34it/s]\u001b[A\n",
      " 27%|█████████████████████████████████████████████▎                                                                                                                          | 145/537 [00:43<01:57,  3.34it/s]\u001b[A\n",
      " 27%|█████████████████████████████████████████████▋                                                                                                                          | 146/537 [00:43<01:56,  3.35it/s]\u001b[A\n",
      " 27%|█████████████████████████████████████████████▉                                                                                                                          | 147/537 [00:44<01:56,  3.35it/s]\u001b[A\n",
      " 28%|██████████████████████████████████████████████▎                                                                                                                         | 148/537 [00:44<01:56,  3.35it/s]\u001b[A\n",
      " 28%|██████████████████████████████████████████████▌                                                                                                                         | 149/537 [00:44<01:56,  3.34it/s]\u001b[A\n",
      " 28%|██████████████████████████████████████████████▉                                                                                                                         | 150/537 [00:45<01:55,  3.34it/s]\u001b[A\n",
      " 28%|███████████████████████████████████████████████▏                                                                                                                        | 151/537 [00:45<01:55,  3.35it/s]\u001b[A\n",
      " 28%|███████████████████████████████████████████████▌                                                                                                                        | 152/537 [00:45<01:54,  3.35it/s]\u001b[A\n",
      " 28%|███████████████████████████████████████████████▊                                                                                                                        | 153/537 [00:45<01:54,  3.35it/s]\u001b[A\n",
      " 29%|████████████████████████████████████████████████▏                                                                                                                       | 154/537 [00:46<01:54,  3.35it/s]\u001b[A\n",
      " 29%|████████████████████████████████████████████████▍                                                                                                                       | 155/537 [00:46<01:54,  3.35it/s]\u001b[A\n",
      " 29%|████████████████████████████████████████████████▊                                                                                                                       | 156/537 [00:46<01:53,  3.34it/s]\u001b[A\n",
      " 29%|█████████████████████████████████████████████████                                                                                                                       | 157/537 [00:47<01:53,  3.35it/s]\u001b[A\n",
      " 29%|█████████████████████████████████████████████████▍                                                                                                                      | 158/537 [00:47<01:53,  3.34it/s]\u001b[A\n",
      " 30%|█████████████████████████████████████████████████▋                                                                                                                      | 159/537 [00:47<01:53,  3.33it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████████                                                                                                                      | 160/537 [00:48<01:52,  3.34it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████████▎                                                                                                                     | 161/537 [00:48<01:52,  3.34it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████████▋                                                                                                                     | 162/537 [00:48<01:52,  3.34it/s]\u001b[A\n",
      " 30%|██████████████████████████████████████████████████▉                                                                                                                     | 163/537 [00:48<01:51,  3.35it/s]\u001b[A\n",
      " 31%|███████████████████████████████████████████████████▎                                                                                                                    | 164/537 [00:49<01:51,  3.35it/s]\u001b[A\n",
      " 31%|███████████████████████████████████████████████████▌                                                                                                                    | 165/537 [00:49<01:51,  3.34it/s]\u001b[A\n",
      " 31%|███████████████████████████████████████████████████▉                                                                                                                    | 166/537 [00:49<01:51,  3.34it/s]\u001b[A\n",
      " 31%|████████████████████████████████████████████████████▏                                                                                                                   | 167/537 [00:50<01:50,  3.35it/s]\u001b[A\n",
      " 31%|████████████████████████████████████████████████████▌                                                                                                                   | 168/537 [00:50<01:50,  3.35it/s]\u001b[A\n",
      " 31%|████████████████████████████████████████████████████▊                                                                                                                   | 169/537 [00:50<01:49,  3.35it/s]\u001b[A\n",
      " 32%|█████████████████████████████████████████████████████▏                                                                                                                  | 170/537 [00:51<01:49,  3.35it/s]\u001b[A\n",
      " 32%|█████████████████████████████████████████████████████▍                                                                                                                  | 171/537 [00:51<01:49,  3.34it/s]\u001b[A\n",
      " 32%|█████████████████████████████████████████████████████▊                                                                                                                  | 172/537 [00:51<01:49,  3.35it/s]\u001b[A\n",
      " 32%|██████████████████████████████████████████████████████                                                                                                                  | 173/537 [00:51<01:48,  3.35it/s]\u001b[A\n",
      " 32%|██████████████████████████████████████████████████████▍                                                                                                                 | 174/537 [00:52<01:48,  3.36it/s]\u001b[A\n",
      " 33%|██████████████████████████████████████████████████████▋                                                                                                                 | 175/537 [00:52<01:48,  3.35it/s]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████                                                                                                                 | 176/537 [00:52<01:47,  3.35it/s]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████▎                                                                                                                | 177/537 [00:53<01:47,  3.35it/s]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████████▋                                                                                                                | 178/537 [00:53<01:47,  3.35it/s]\u001b[A\n",
      " 33%|████████████████████████████████████████████████████████                                                                                                                | 179/537 [00:53<01:46,  3.35it/s]\u001b[A\n",
      " 34%|████████████████████████████████████████████████████████▎                                                                                                               | 180/537 [00:54<01:46,  3.35it/s]\u001b[A\n",
      " 34%|████████████████████████████████████████████████████████▋                                                                                                               | 181/537 [00:54<01:46,  3.34it/s]\u001b[A\n",
      " 34%|████████████████████████████████████████████████████████▉                                                                                                               | 182/537 [00:54<01:46,  3.34it/s]\u001b[A\n",
      " 34%|█████████████████████████████████████████████████████████▎                                                                                                              | 183/537 [00:54<01:46,  3.34it/s]\u001b[A\n",
      " 34%|█████████████████████████████████████████████████████████▌                                                                                                              | 184/537 [00:55<01:45,  3.34it/s]\u001b[A\n",
      " 34%|█████████████████████████████████████████████████████████▉                                                                                                              | 185/537 [00:55<01:44,  3.35it/s]\u001b[A\n",
      " 35%|██████████████████████████████████████████████████████████▏                                                                                                             | 186/537 [00:55<01:45,  3.34it/s]\u001b[A\n",
      " 35%|██████████████████████████████████████████████████████████▌                                                                                                             | 187/537 [00:56<01:44,  3.34it/s]\u001b[A\n",
      " 35%|██████████████████████████████████████████████████████████▊                                                                                                             | 188/537 [00:56<01:44,  3.34it/s]\u001b[A\n",
      " 35%|███████████████████████████████████████████████████████████▏                                                                                                            | 189/537 [00:56<01:44,  3.34it/s]\u001b[A\n",
      " 35%|███████████████████████████████████████████████████████████▍                                                                                                            | 190/537 [00:57<01:43,  3.34it/s]\u001b[A\n",
      " 36%|███████████████████████████████████████████████████████████▊                                                                                                            | 191/537 [00:57<01:43,  3.35it/s]\u001b[A\n",
      " 36%|████████████████████████████████████████████████████████████                                                                                                            | 192/537 [00:57<01:43,  3.35it/s]\u001b[A\n",
      " 36%|████████████████████████████████████████████████████████████▍                                                                                                           | 193/537 [00:57<01:43,  3.34it/s]\u001b[A\n",
      " 36%|████████████████████████████████████████████████████████████▋                                                                                                           | 194/537 [00:58<01:42,  3.34it/s]\u001b[A\n",
      " 36%|█████████████████████████████████████████████████████████████                                                                                                           | 195/537 [00:58<01:42,  3.33it/s]\u001b[A\n",
      " 36%|█████████████████████████████████████████████████████████████▎                                                                                                          | 196/537 [00:58<01:42,  3.33it/s]\u001b[A\n",
      " 37%|█████████████████████████████████████████████████████████████▋                                                                                                          | 197/537 [00:59<01:41,  3.33it/s]\u001b[A\n",
      " 37%|█████████████████████████████████████████████████████████████▉                                                                                                          | 198/537 [00:59<01:41,  3.33it/s]\u001b[A\n",
      " 37%|██████████████████████████████████████████████████████████████▎                                                                                                         | 199/537 [00:59<01:41,  3.33it/s]\u001b[A\n",
      " 37%|██████████████████████████████████████████████████████████████▌                                                                                                         | 200/537 [01:00<01:40,  3.34it/s]\u001b[A\n",
      " 37%|██████████████████████████████████████████████████████████████▉                                                                                                         | 201/537 [01:00<01:40,  3.35it/s]\u001b[A\n",
      " 38%|███████████████████████████████████████████████████████████████▏                                                                                                        | 202/537 [01:00<01:40,  3.35it/s]\u001b[A\n",
      " 38%|███████████████████████████████████████████████████████████████▌                                                                                                        | 203/537 [01:00<01:39,  3.34it/s]\u001b[A\n",
      " 38%|███████████████████████████████████████████████████████████████▊                                                                                                        | 204/537 [01:01<01:39,  3.34it/s]\u001b[A\n",
      " 38%|████████████████████████████████████████████████████████████████▏                                                                                                       | 205/537 [01:01<01:39,  3.34it/s]\u001b[A\n",
      " 38%|████████████████████████████████████████████████████████████████▍                                                                                                       | 206/537 [01:01<01:38,  3.34it/s]\u001b[A\n",
      " 39%|████████████████████████████████████████████████████████████████▊                                                                                                       | 207/537 [01:02<01:38,  3.34it/s]\u001b[A\n",
      " 39%|█████████████████████████████████████████████████████████████████                                                                                                       | 208/537 [01:02<01:38,  3.35it/s]\u001b[A\n",
      " 39%|█████████████████████████████████████████████████████████████████▍                                                                                                      | 209/537 [01:02<01:37,  3.35it/s]\u001b[A\n",
      " 39%|█████████████████████████████████████████████████████████████████▋                                                                                                      | 210/537 [01:03<01:37,  3.36it/s]\u001b[A\n",
      " 39%|██████████████████████████████████████████████████████████████████                                                                                                      | 211/537 [01:03<01:37,  3.36it/s]\u001b[A\n",
      " 39%|██████████████████████████████████████████████████████████████████▎                                                                                                     | 212/537 [01:03<01:36,  3.36it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████████▋                                                                                                     | 213/537 [01:03<01:36,  3.35it/s]\u001b[A\n",
      " 40%|██████████████████████████████████████████████████████████████████▉                                                                                                     | 214/537 [01:04<01:36,  3.35it/s]\u001b[A\n",
      " 40%|███████████████████████████████████████████████████████████████████▎                                                                                                    | 215/537 [01:04<01:36,  3.34it/s]\u001b[A\n",
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                    | 216/537 [01:04<01:36,  3.34it/s]\u001b[A\n",
      " 40%|███████████████████████████████████████████████████████████████████▉                                                                                                    | 217/537 [01:05<01:35,  3.34it/s]\u001b[A\n",
      " 41%|████████████████████████████████████████████████████████████████████▏                                                                                                   | 218/537 [01:05<01:35,  3.34it/s]\u001b[A\n",
      " 41%|████████████████████████████████████████████████████████████████████▌                                                                                                   | 219/537 [01:05<01:35,  3.34it/s]\u001b[A\n",
      " 41%|████████████████████████████████████████████████████████████████████▊                                                                                                   | 220/537 [01:06<01:35,  3.34it/s]\u001b[A\n",
      " 41%|█████████████████████████████████████████████████████████████████████▏                                                                                                  | 221/537 [01:06<01:34,  3.33it/s]\u001b[A\n",
      " 41%|█████████████████████████████████████████████████████████████████████▍                                                                                                  | 222/537 [01:06<01:34,  3.33it/s]\u001b[A\n",
      " 42%|█████████████████████████████████████████████████████████████████████▊                                                                                                  | 223/537 [01:06<01:34,  3.34it/s]\u001b[A\n",
      " 42%|██████████████████████████████████████████████████████████████████████                                                                                                  | 224/537 [01:07<01:33,  3.34it/s]\u001b[A\n",
      " 42%|██████████████████████████████████████████████████████████████████████▍                                                                                                 | 225/537 [01:07<01:33,  3.34it/s]\u001b[A\n",
      " 42%|██████████████████████████████████████████████████████████████████████▋                                                                                                 | 226/537 [01:07<01:32,  3.35it/s]\u001b[A\n",
      " 42%|███████████████████████████████████████████████████████████████████████                                                                                                 | 227/537 [01:08<01:32,  3.35it/s]\u001b[A\n",
      " 42%|███████████████████████████████████████████████████████████████████████▎                                                                                                | 228/537 [01:08<01:32,  3.35it/s]\u001b[A\n",
      " 43%|███████████████████████████████████████████████████████████████████████▋                                                                                                | 229/537 [01:08<01:31,  3.35it/s]\u001b[A\n",
      " 43%|███████████████████████████████████████████████████████████████████████▉                                                                                                | 230/537 [01:09<01:31,  3.35it/s]\u001b[A\n",
      " 43%|████████████████████████████████████████████████████████████████████████▎                                                                                               | 231/537 [01:09<01:31,  3.34it/s]\u001b[A\n",
      " 43%|████████████████████████████████████████████████████████████████████████▌                                                                                               | 232/537 [01:09<01:31,  3.34it/s]\u001b[A\n",
      " 43%|████████████████████████████████████████████████████████████████████████▉                                                                                               | 233/537 [01:09<01:30,  3.34it/s]\u001b[A\n",
      " 44%|█████████████████████████████████████████████████████████████████████████▏                                                                                              | 234/537 [01:10<01:30,  3.35it/s]\u001b[A\n",
      " 44%|█████████████████████████████████████████████████████████████████████████▌                                                                                              | 235/537 [01:10<01:30,  3.34it/s]\u001b[A\n",
      " 44%|█████████████████████████████████████████████████████████████████████████▊                                                                                              | 236/537 [01:10<01:30,  3.34it/s]\u001b[A\n",
      " 44%|██████████████████████████████████████████████████████████████████████████▏                                                                                             | 237/537 [01:11<01:29,  3.33it/s]\u001b[A\n",
      " 44%|██████████████████████████████████████████████████████████████████████████▍                                                                                             | 238/537 [01:11<01:29,  3.34it/s]\u001b[A\n",
      " 45%|██████████████████████████████████████████████████████████████████████████▊                                                                                             | 239/537 [01:11<01:28,  3.35it/s]\u001b[A\n",
      " 45%|███████████████████████████████████████████████████████████████████████████                                                                                             | 240/537 [01:12<01:28,  3.35it/s]\u001b[A\n",
      " 45%|███████████████████████████████████████████████████████████████████████████▍                                                                                            | 241/537 [01:12<01:28,  3.35it/s]\u001b[A\n",
      " 45%|███████████████████████████████████████████████████████████████████████████▋                                                                                            | 242/537 [01:12<01:28,  3.34it/s]\u001b[A\n",
      " 45%|████████████████████████████████████████████████████████████████████████████                                                                                            | 243/537 [01:12<01:27,  3.35it/s]\u001b[A\n",
      " 45%|████████████████████████████████████████████████████████████████████████████▎                                                                                           | 244/537 [01:13<01:27,  3.35it/s]\u001b[A\n",
      " 46%|████████████████████████████████████████████████████████████████████████████▋                                                                                           | 245/537 [01:13<01:27,  3.34it/s]\u001b[A\n",
      " 46%|████████████████████████████████████████████████████████████████████████████▉                                                                                           | 246/537 [01:13<01:27,  3.34it/s]\u001b[A\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▎                                                                                          | 247/537 [01:14<01:26,  3.34it/s]\u001b[A\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▌                                                                                          | 248/537 [01:14<01:26,  3.34it/s]\u001b[A\n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▉                                                                                          | 249/537 [01:14<01:26,  3.34it/s]\u001b[A\n",
      " 47%|██████████████████████████████████████████████████████████████████████████████▏                                                                                         | 250/537 [01:14<01:25,  3.35it/s]\u001b[A\n",
      " 47%|██████████████████████████████████████████████████████████████████████████████▌                                                                                         | 251/537 [01:15<01:25,  3.35it/s]\u001b[A\n",
      " 47%|██████████████████████████████████████████████████████████████████████████████▊                                                                                         | 252/537 [01:15<01:25,  3.34it/s]\u001b[A\n",
      " 47%|███████████████████████████████████████████████████████████████████████████████▏                                                                                        | 253/537 [01:15<01:25,  3.33it/s]\u001b[A\n",
      " 47%|███████████████████████████████████████████████████████████████████████████████▍                                                                                        | 254/537 [01:16<01:24,  3.33it/s]\u001b[A\n",
      " 47%|███████████████████████████████████████████████████████████████████████████████▊                                                                                        | 255/537 [01:16<01:24,  3.33it/s]\u001b[A\n",
      " 48%|████████████████████████████████████████████████████████████████████████████████                                                                                        | 256/537 [01:16<01:24,  3.33it/s]\u001b[A\n",
      " 48%|████████████████████████████████████████████████████████████████████████████████▍                                                                                       | 257/537 [01:17<01:23,  3.34it/s]\u001b[A\n",
      " 48%|████████████████████████████████████████████████████████████████████████████████▋                                                                                       | 258/537 [01:17<01:23,  3.34it/s]\u001b[A\n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████                                                                                       | 259/537 [01:17<01:23,  3.34it/s]\u001b[A\n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████▎                                                                                      | 260/537 [01:17<01:22,  3.34it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 261/537 [01:18<01:22,  3.35it/s]\u001b[A\n",
      " 49%|█████████████████████████████████████████████████████████████████████████████████▉                                                                                      | 262/537 [01:18<01:22,  3.34it/s]\u001b[A\n",
      " 49%|██████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 263/537 [01:18<01:21,  3.34it/s]\u001b[A\n",
      " 49%|██████████████████████████████████████████████████████████████████████████████████▌                                                                                     | 264/537 [01:19<01:21,  3.34it/s]\u001b[A\n",
      " 49%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                     | 265/537 [01:19<01:21,  3.35it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████▏                                                                                    | 266/537 [01:19<01:21,  3.34it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 267/537 [01:20<01:20,  3.34it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 268/537 [01:20<01:20,  3.33it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 269/537 [01:20<01:20,  3.33it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 270/537 [01:20<01:20,  3.33it/s]\u001b[A\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 271/537 [01:21<01:20,  3.32it/s]\u001b[A\n",
      " 51%|█████████████████████████████████████████████████████████████████████████████████████                                                                                   | 272/537 [01:21<01:19,  3.34it/s]\u001b[A\n",
      " 51%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 273/537 [01:21<01:18,  3.34it/s]\u001b[A\n",
      " 51%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 274/537 [01:22<01:18,  3.34it/s]\u001b[A\n",
      " 51%|██████████████████████████████████████████████████████████████████████████████████████                                                                                  | 275/537 [01:22<01:18,  3.33it/s]\u001b[A\n",
      " 51%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 276/537 [01:22<01:18,  3.34it/s]\u001b[A\n",
      " 52%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 277/537 [01:23<01:17,  3.34it/s]\u001b[A\n",
      " 52%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 278/537 [01:23<01:17,  3.34it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 279/537 [01:23<01:17,  3.34it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 280/537 [01:23<01:16,  3.35it/s]\u001b[A\n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 281/537 [01:24<01:16,  3.35it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 282/537 [01:24<01:16,  3.34it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████████████████████████████████████████████████████▌                                                                               | 283/537 [01:24<01:15,  3.34it/s]\u001b[A\n",
      " 53%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 284/537 [01:25<01:15,  3.35it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████▏                                                                              | 285/537 [01:25<01:15,  3.34it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 286/537 [01:25<01:15,  3.34it/s]\u001b[A\n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████▊                                                                              | 287/537 [01:26<01:14,  3.35it/s]\u001b[A\n",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████                                                                              | 288/537 [01:26<01:14,  3.34it/s]\u001b[A\n",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████▍                                                                             | 289/537 [01:26<01:14,  3.34it/s]\u001b[A\n",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████▋                                                                             | 290/537 [01:26<01:13,  3.34it/s]\u001b[A\n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████                                                                             | 291/537 [01:27<01:13,  3.33it/s]\u001b[A\n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                            | 292/537 [01:27<01:13,  3.33it/s]\u001b[A\n",
      " 55%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                            | 293/537 [01:27<01:13,  3.33it/s]\u001b[A\n",
      " 55%|███████████████████████████████████████████████████████████████████████████████████████████▉                                                                            | 294/537 [01:28<01:12,  3.34it/s]\u001b[A\n",
      " 55%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                           | 295/537 [01:28<01:12,  3.35it/s]\u001b[A\n",
      " 55%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                           | 296/537 [01:28<01:12,  3.34it/s]\u001b[A\n",
      " 55%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 297/537 [01:29<01:11,  3.35it/s]\u001b[A\n",
      " 55%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                          | 298/537 [01:29<01:11,  3.35it/s]\u001b[A\n",
      " 56%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 299/537 [01:29<01:10,  3.36it/s]\u001b[A\n",
      " 56%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                          | 300/537 [01:29<01:10,  3.35it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 301/537 [01:30<01:10,  3.34it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                         | 302/537 [01:30<01:10,  3.35it/s]\u001b[A\n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 303/537 [01:30<01:09,  3.35it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 304/537 [01:31<01:09,  3.35it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 305/537 [01:31<01:09,  3.35it/s]\u001b[A\n",
      " 57%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 306/537 [01:31<01:09,  3.34it/s]\u001b[A\n",
      " 57%|████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 307/537 [01:32<01:08,  3.34it/s]\u001b[A\n",
      " 57%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 308/537 [01:32<01:08,  3.35it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 309/537 [01:32<01:08,  3.35it/s]\u001b[A\n",
      " 58%|████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 310/537 [01:32<01:07,  3.35it/s]\u001b[A\n",
      " 58%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 311/537 [01:33<01:07,  3.35it/s]\u001b[A\n",
      " 58%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 312/537 [01:33<01:07,  3.35it/s]\u001b[A\n",
      " 58%|█████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 313/537 [01:33<01:06,  3.35it/s]\u001b[A\n",
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 314/537 [01:34<01:06,  3.34it/s]\u001b[A\n",
      " 59%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 315/537 [01:34<01:06,  3.34it/s]\u001b[A\n",
      " 59%|██████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 316/537 [01:34<01:06,  3.34it/s]\u001b[A\n",
      " 59%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 317/537 [01:35<01:05,  3.34it/s]\u001b[A\n",
      " 59%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 318/537 [01:35<01:05,  3.34it/s]\u001b[A\n",
      " 59%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                    | 319/537 [01:35<01:05,  3.34it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 320/537 [01:35<01:05,  3.34it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 321/537 [01:36<01:04,  3.34it/s]\u001b[A\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 322/537 [01:36<01:04,  3.35it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 323/537 [01:36<01:03,  3.35it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 324/537 [01:37<01:03,  3.35it/s]\u001b[A\n",
      " 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                  | 325/537 [01:37<01:03,  3.35it/s]\u001b[A\n",
      " 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                  | 326/537 [01:37<01:03,  3.34it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                 | 327/537 [01:38<01:02,  3.34it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                 | 328/537 [01:38<01:02,  3.35it/s]\u001b[A\n",
      " 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                 | 329/537 [01:38<01:02,  3.35it/s]\u001b[A\n",
      " 61%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                | 330/537 [01:38<01:01,  3.35it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                | 331/537 [01:39<01:01,  3.35it/s]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                | 332/537 [01:39<01:01,  3.35it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 333/537 [01:39<01:00,  3.36it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                               | 334/537 [01:40<01:00,  3.36it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 335/537 [01:40<01:00,  3.35it/s]\u001b[A\n",
      " 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 336/537 [01:40<01:00,  3.34it/s]\u001b[A\n",
      " 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 337/537 [01:41<00:59,  3.35it/s]\u001b[A\n",
      " 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                              | 338/537 [01:41<00:59,  3.35it/s]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 339/537 [01:41<00:59,  3.35it/s]\u001b[A\n",
      " 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                             | 340/537 [01:41<00:58,  3.36it/s]\u001b[A\n",
      " 64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 341/537 [01:42<00:58,  3.36it/s]\u001b[A\n",
      " 64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 342/537 [01:42<00:58,  3.36it/s]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 343/537 [01:42<00:57,  3.36it/s]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 344/537 [01:43<00:57,  3.36it/s]\u001b[A\n",
      " 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 345/537 [01:43<00:57,  3.36it/s]\u001b[A\n",
      " 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 346/537 [01:43<00:56,  3.36it/s]\u001b[A\n",
      " 65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 347/537 [01:43<00:56,  3.36it/s]\u001b[A\n",
      " 65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 348/537 [01:44<00:56,  3.36it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 349/537 [01:44<00:56,  3.35it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 350/537 [01:44<00:55,  3.35it/s]\u001b[A\n",
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 351/537 [01:45<00:55,  3.35it/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 352/537 [01:45<00:55,  3.35it/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 353/537 [01:45<00:54,  3.36it/s]\u001b[A\n",
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 354/537 [01:46<00:54,  3.35it/s]\u001b[A\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 355/537 [01:46<00:54,  3.36it/s]\u001b[A\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 356/537 [01:46<00:53,  3.35it/s]\u001b[A\n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 357/537 [01:46<00:53,  3.35it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                        | 358/537 [01:47<00:53,  3.35it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 359/537 [01:47<00:53,  3.35it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                       | 360/537 [01:47<00:52,  3.35it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                       | 361/537 [01:48<00:52,  3.34it/s]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 362/537 [01:48<00:52,  3.35it/s]\u001b[A\n",
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                      | 363/537 [01:48<00:51,  3.35it/s]\u001b[A\n",
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 364/537 [01:49<00:51,  3.35it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                     | 365/537 [01:49<00:51,  3.35it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 366/537 [01:49<00:51,  3.35it/s]\u001b[A\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                     | 367/537 [01:49<00:50,  3.34it/s]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 368/537 [01:50<00:50,  3.34it/s]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                    | 369/537 [01:50<00:50,  3.35it/s]\u001b[A\n",
      " 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 370/537 [01:50<00:49,  3.35it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 371/537 [01:51<00:49,  3.36it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 372/537 [01:51<00:49,  3.36it/s]\u001b[A\n",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 373/537 [01:51<00:48,  3.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 374/537 [01:52<00:48,  3.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 375/537 [01:52<00:48,  3.36it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 376/537 [01:52<00:48,  3.35it/s]\u001b[A\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 377/537 [01:52<00:47,  3.35it/s]\u001b[A\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 378/537 [01:53<00:47,  3.35it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 379/537 [01:53<00:47,  3.35it/s]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 380/537 [01:53<00:46,  3.34it/s]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 381/537 [01:54<00:46,  3.34it/s]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 382/537 [01:54<00:46,  3.34it/s]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 383/537 [01:54<00:46,  3.34it/s]\u001b[A\n",
      " 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                               | 384/537 [01:55<00:45,  3.35it/s]\u001b[A\n",
      " 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 385/537 [01:55<00:45,  3.35it/s]\u001b[A\n",
      " 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                               | 386/537 [01:55<00:45,  3.35it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 387/537 [01:55<00:44,  3.35it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                              | 388/537 [01:56<00:44,  3.36it/s]\u001b[A\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 389/537 [01:56<00:44,  3.35it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                              | 390/537 [01:56<00:43,  3.35it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                             | 391/537 [01:57<00:43,  3.35it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 392/537 [01:57<00:43,  3.34it/s]\u001b[A\n",
      " 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                             | 393/537 [01:57<00:43,  3.34it/s]\u001b[A\n",
      " 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                            | 394/537 [01:58<00:42,  3.34it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                            | 395/537 [01:58<00:42,  3.34it/s]\u001b[A\n",
      " 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                            | 396/537 [01:58<00:42,  3.34it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                           | 397/537 [01:58<00:41,  3.34it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 398/537 [01:59<00:41,  3.34it/s]\u001b[A\n",
      " 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                           | 399/537 [01:59<00:41,  3.36it/s]\u001b[A\n",
      " 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 400/537 [01:59<00:40,  3.36it/s]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                          | 401/537 [02:00<00:40,  3.35it/s]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 402/537 [02:00<00:40,  3.34it/s]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                          | 403/537 [02:00<00:40,  3.35it/s]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 404/537 [02:01<00:39,  3.35it/s]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                         | 405/537 [02:01<00:39,  3.35it/s]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 406/537 [02:01<00:39,  3.35it/s]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 407/537 [02:01<00:38,  3.35it/s]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 408/537 [02:02<00:38,  3.35it/s]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 409/537 [02:02<00:38,  3.35it/s]\u001b[A\n",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 410/537 [02:02<00:37,  3.35it/s]\u001b[A\n",
      " 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 411/537 [02:03<00:37,  3.34it/s]\u001b[A\n",
      " 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 412/537 [02:03<00:37,  3.34it/s]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 413/537 [02:03<00:37,  3.34it/s]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 414/537 [02:04<00:36,  3.34it/s]\u001b[A\n",
      " 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 415/537 [02:04<00:36,  3.34it/s]\u001b[A\n",
      " 77%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 416/537 [02:04<00:36,  3.35it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 417/537 [02:04<00:35,  3.35it/s]\u001b[A\n",
      " 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 418/537 [02:05<00:35,  3.34it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 419/537 [02:05<00:35,  3.35it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 420/537 [02:05<00:34,  3.35it/s]\u001b[A\n",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 421/537 [02:06<00:34,  3.35it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                    | 422/537 [02:06<00:34,  3.35it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 423/537 [02:06<00:34,  3.35it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                   | 424/537 [02:06<00:33,  3.35it/s]\u001b[A\n",
      " 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 425/537 [02:07<00:33,  3.35it/s]\u001b[A\n",
      " 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                  | 426/537 [02:07<00:33,  3.36it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 427/537 [02:07<00:32,  3.35it/s]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                  | 428/537 [02:08<00:32,  3.35it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 429/537 [02:08<00:32,  3.34it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 430/537 [02:08<00:32,  3.34it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 431/537 [02:09<00:31,  3.35it/s]\u001b[A\n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                | 432/537 [02:09<00:31,  3.35it/s]\u001b[A\n",
      " 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                | 433/537 [02:09<00:31,  3.34it/s]\u001b[A\n",
      " 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 434/537 [02:09<00:30,  3.34it/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                | 435/537 [02:10<00:30,  3.34it/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 436/537 [02:10<00:30,  3.35it/s]\u001b[A\n",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                               | 437/537 [02:10<00:29,  3.36it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 438/537 [02:11<00:29,  3.34it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                              | 439/537 [02:11<00:29,  3.35it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 440/537 [02:11<00:28,  3.35it/s]\u001b[A\n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                              | 441/537 [02:12<00:28,  3.35it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 442/537 [02:12<00:28,  3.35it/s]\u001b[A\n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 443/537 [02:12<00:28,  3.35it/s]\u001b[A\n",
      " 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 444/537 [02:12<00:27,  3.35it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 445/537 [02:13<00:27,  3.35it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 446/537 [02:13<00:27,  3.35it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 447/537 [02:13<00:26,  3.35it/s]\u001b[A\n",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 448/537 [02:14<00:26,  3.35it/s]\u001b[A\n",
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 449/537 [02:14<00:26,  3.35it/s]\u001b[A\n",
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 450/537 [02:14<00:25,  3.35it/s]\u001b[A\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 451/537 [02:15<00:25,  3.35it/s]\u001b[A\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 452/537 [02:15<00:25,  3.35it/s]\u001b[A\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 453/537 [02:15<00:25,  3.35it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 454/537 [02:15<00:24,  3.34it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 455/537 [02:16<00:24,  3.35it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                         | 456/537 [02:16<00:24,  3.35it/s]\u001b[A\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 457/537 [02:16<00:23,  3.35it/s]\u001b[A\n",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                        | 458/537 [02:17<00:23,  3.35it/s]\u001b[A\n",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 459/537 [02:17<00:23,  3.34it/s]\u001b[A\n",
      " 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                        | 460/537 [02:17<00:23,  3.34it/s]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 461/537 [02:18<00:22,  3.34it/s]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                       | 462/537 [02:18<00:22,  3.35it/s]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 463/537 [02:18<00:22,  3.35it/s]\u001b[A\n",
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                      | 464/537 [02:18<00:21,  3.34it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                      | 465/537 [02:19<00:21,  3.34it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                      | 466/537 [02:19<00:21,  3.34it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 467/537 [02:19<00:20,  3.35it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 468/537 [02:20<00:20,  3.35it/s]\u001b[A\n",
      " 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                     | 469/537 [02:20<00:20,  3.35it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                     | 470/537 [02:20<00:20,  3.35it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                    | 471/537 [02:21<00:19,  3.34it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 472/537 [02:21<00:19,  3.34it/s]\u001b[A\n",
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                    | 473/537 [02:21<00:19,  3.35it/s]\u001b[A\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 474/537 [02:21<00:18,  3.35it/s]\u001b[A\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                   | 475/537 [02:22<00:18,  3.35it/s]\u001b[A\n",
      " 89%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 476/537 [02:22<00:18,  3.34it/s]\u001b[A\n",
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                  | 477/537 [02:22<00:17,  3.35it/s]\u001b[A\n",
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 478/537 [02:23<00:17,  3.35it/s]\u001b[A\n",
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 479/537 [02:23<00:17,  3.35it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 480/537 [02:23<00:17,  3.35it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 481/537 [02:24<00:16,  3.36it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 482/537 [02:24<00:16,  3.35it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 483/537 [02:24<00:16,  3.34it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 484/537 [02:24<00:15,  3.34it/s]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 485/537 [02:25<00:15,  3.34it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 486/537 [02:25<00:15,  3.34it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 487/537 [02:25<00:14,  3.35it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 488/537 [02:26<00:14,  3.35it/s]\u001b[A\n",
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 489/537 [02:26<00:14,  3.34it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 490/537 [02:26<00:14,  3.35it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 491/537 [02:27<00:13,  3.35it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 492/537 [02:27<00:13,  3.34it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 493/537 [02:27<00:13,  3.35it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 494/537 [02:27<00:12,  3.36it/s]\u001b[A\n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 495/537 [02:28<00:12,  3.35it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 496/537 [02:28<00:12,  3.35it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 497/537 [02:28<00:11,  3.35it/s]\u001b[A\n",
      " 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 498/537 [02:29<00:11,  3.36it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 499/537 [02:29<00:11,  3.35it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 500/537 [02:29<00:11,  3.34it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋           | 501/537 [02:29<00:10,  3.34it/s]\u001b[A\n",
      " 93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 502/537 [02:30<00:10,  3.34it/s]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 503/537 [02:30<00:10,  3.35it/s]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 504/537 [02:30<00:09,  3.35it/s]\u001b[A\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉          | 505/537 [02:31<00:09,  3.34it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 506/537 [02:31<00:09,  3.35it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌         | 507/537 [02:31<00:08,  3.36it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 508/537 [02:32<00:08,  3.35it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 509/537 [02:32<00:08,  3.34it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 510/537 [02:32<00:08,  3.35it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 511/537 [02:32<00:07,  3.34it/s]\u001b[A\n",
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 512/537 [02:33<00:07,  3.34it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 513/537 [02:33<00:07,  3.33it/s]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 514/537 [02:33<00:06,  3.34it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 515/537 [02:34<00:06,  3.34it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 516/537 [02:34<00:06,  3.34it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 517/537 [02:34<00:05,  3.34it/s]\u001b[A\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 518/537 [02:35<00:05,  3.34it/s]\u001b[A\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 519/537 [02:35<00:05,  3.34it/s]\u001b[A\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 520/537 [02:35<00:05,  3.34it/s]\u001b[A\n",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 521/537 [02:35<00:04,  3.34it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 522/537 [02:36<00:04,  3.34it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 523/537 [02:36<00:04,  3.35it/s]\u001b[A\n",
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 524/537 [02:36<00:03,  3.36it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 525/537 [02:37<00:03,  3.35it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 526/537 [02:37<00:03,  3.35it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 527/537 [02:37<00:02,  3.35it/s]\u001b[A\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 528/537 [02:38<00:02,  3.34it/s]\u001b[A\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 529/537 [02:38<00:02,  3.35it/s]\u001b[A\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 530/537 [02:38<00:02,  3.35it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 531/537 [02:38<00:01,  3.35it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 532/537 [02:39<00:01,  3.35it/s]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 533/537 [02:39<00:01,  3.35it/s]\u001b[A\n",
      " 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 534/537 [02:39<00:00,  3.35it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 535/537 [02:40<00:00,  3.36it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 536/537 [02:40<00:00,  3.36it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 537/537 [02:40<00:00,  3.34it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [05:21<00:00, 160.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Average Loss: 0.09751381910643653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Evaluation Loss: 0.2087076625149501\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Define the optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(training_data_loader) * 3)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(training_data_loader):\n",
    "        inputs = batch[\"input_ids\"].to(device=device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs, labels=inputs, attention_mask=attention_mask, token_type_ids=None)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(training_data_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}\")\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "total_eval_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in eval_data_loader:\n",
    "        inputs = batch[\"input_ids\"].to(device=device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device=device)\n",
    "\n",
    "        outputs = model(inputs, labels=inputs, attention_mask=attention_mask, token_type_ids=None)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "average_eval_loss = total_eval_loss / len(eval_data_loader)\n",
    "print(f\"Average Evaluation Loss: {average_eval_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T06:01:07.640417600Z",
     "start_time": "2023-12-22T05:54:52.712980200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3794/3794 [06:14<00:00, 10.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40264,\n",
       " 82231,\n",
       " [0.005747318267822266,\n",
       "  0.004419088363647461,\n",
       "  0.0043408870697021484,\n",
       "  0.004266262054443359,\n",
       "  0.004271268844604492,\n",
       "  0.004292726516723633,\n",
       "  0.0043866634368896484,\n",
       "  0.004395484924316406,\n",
       "  0.004330158233642578,\n",
       "  0.004338741302490234,\n",
       "  0.004199028015136719,\n",
       "  0.0042133331298828125,\n",
       "  0.004231691360473633,\n",
       "  0.004241228103637695,\n",
       "  0.0042421817779541016,\n",
       "  0.0042841434478759766,\n",
       "  0.004193305969238281,\n",
       "  0.004197597503662109,\n",
       "  0.0040435791015625,\n",
       "  0.004195451736450195,\n",
       "  0.004090785980224609,\n",
       "  0.004246234893798828,\n",
       "  0.004330158233642578,\n",
       "  0.004189252853393555,\n",
       "  0.004166841506958008,\n",
       "  0.004203081130981445,\n",
       "  0.00417017936706543,\n",
       "  0.004268169403076172,\n",
       "  0.004297733306884766,\n",
       "  0.004301309585571289,\n",
       "  0.004270076751708984,\n",
       "  0.004227638244628906,\n",
       "  0.004248142242431641,\n",
       "  0.0042688846588134766,\n",
       "  0.0042858123779296875,\n",
       "  0.004254579544067383,\n",
       "  0.004270076751708984,\n",
       "  0.004236698150634766,\n",
       "  0.004289150238037109,\n",
       "  0.004268646240234375,\n",
       "  0.004274129867553711,\n",
       "  0.004341602325439453,\n",
       "  0.0043163299560546875,\n",
       "  0.0043947696685791016,\n",
       "  0.004263401031494141,\n",
       "  0.0043718814849853516,\n",
       "  0.004475593566894531,\n",
       "  0.00434565544128418,\n",
       "  0.0044078826904296875,\n",
       "  0.0043752193450927734,\n",
       "  0.004580497741699219,\n",
       "  0.004614114761352539,\n",
       "  0.0046558380126953125,\n",
       "  0.004549980163574219,\n",
       "  0.004582881927490234,\n",
       "  0.00461578369140625,\n",
       "  0.0045871734619140625,\n",
       "  0.004550457000732422,\n",
       "  0.004567384719848633,\n",
       "  0.0045299530029296875,\n",
       "  0.004537343978881836,\n",
       "  0.004559516906738281,\n",
       "  0.004610300064086914,\n",
       "  0.0045926570892333984,\n",
       "  0.004586458206176758,\n",
       "  0.004582881927490234,\n",
       "  0.0046465396881103516,\n",
       "  0.00459599494934082,\n",
       "  0.0043218135833740234,\n",
       "  0.004003047943115234,\n",
       "  0.004010200500488281,\n",
       "  0.0040569305419921875,\n",
       "  0.00420379638671875,\n",
       "  0.004133939743041992,\n",
       "  0.004094123840332031,\n",
       "  0.004204511642456055,\n",
       "  0.004174947738647461,\n",
       "  0.004225969314575195,\n",
       "  0.004230976104736328,\n",
       "  0.004212617874145508,\n",
       "  0.0042951107025146484,\n",
       "  0.0042459964752197266,\n",
       "  0.004182338714599609,\n",
       "  0.00434565544128418,\n",
       "  0.004095792770385742,\n",
       "  0.004105806350708008,\n",
       "  0.003997325897216797,\n",
       "  0.004140377044677734,\n",
       "  0.004172325134277344,\n",
       "  0.004193544387817383,\n",
       "  0.004130363464355469,\n",
       "  0.0041408538818359375,\n",
       "  0.00421142578125,\n",
       "  0.004286766052246094,\n",
       "  0.004316806793212891,\n",
       "  0.0042514801025390625,\n",
       "  0.004254579544067383,\n",
       "  0.0042650699615478516,\n",
       "  0.004316568374633789,\n",
       "  0.004418373107910156,\n",
       "  0.004431962966918945,\n",
       "  0.004369258880615234,\n",
       "  0.004307985305786133,\n",
       "  0.004255533218383789,\n",
       "  0.004307746887207031,\n",
       "  0.004290342330932617,\n",
       "  0.0042421817779541016,\n",
       "  0.0042188167572021484,\n",
       "  0.0039708614349365234,\n",
       "  0.003988742828369141,\n",
       "  0.004015207290649414,\n",
       "  0.003960609436035156,\n",
       "  0.004319667816162109,\n",
       "  0.003973960876464844,\n",
       "  0.0041141510009765625,\n",
       "  0.004255056381225586,\n",
       "  0.0041844844818115234,\n",
       "  0.0041120052337646484,\n",
       "  0.004189491271972656,\n",
       "  0.004169940948486328,\n",
       "  0.004200458526611328,\n",
       "  0.004201412200927734,\n",
       "  0.004255771636962891,\n",
       "  0.004340648651123047,\n",
       "  0.004160165786743164,\n",
       "  0.004148006439208984,\n",
       "  0.004186391830444336,\n",
       "  0.004259347915649414,\n",
       "  0.004331827163696289,\n",
       "  0.004243612289428711,\n",
       "  0.004271745681762695,\n",
       "  0.004256248474121094,\n",
       "  0.004281044006347656,\n",
       "  0.004258871078491211,\n",
       "  0.004271984100341797,\n",
       "  0.004339456558227539,\n",
       "  0.004138469696044922,\n",
       "  0.003990650177001953,\n",
       "  0.004052639007568359,\n",
       "  0.004014492034912109,\n",
       "  0.0041484832763671875,\n",
       "  0.004065513610839844,\n",
       "  0.004105091094970703,\n",
       "  0.004117727279663086,\n",
       "  0.00419163703918457,\n",
       "  0.00423884391784668,\n",
       "  0.004228830337524414,\n",
       "  0.0041408538818359375,\n",
       "  0.004147052764892578,\n",
       "  0.0041637420654296875,\n",
       "  0.0042150020599365234,\n",
       "  0.004403591156005859,\n",
       "  0.0042591094970703125,\n",
       "  0.004267454147338867,\n",
       "  0.0043032169342041016,\n",
       "  0.0042629241943359375,\n",
       "  0.004273414611816406,\n",
       "  0.00424647331237793,\n",
       "  0.0043528079986572266,\n",
       "  0.004445552825927734,\n",
       "  0.004340410232543945,\n",
       "  0.004369974136352539,\n",
       "  0.004312276840209961,\n",
       "  0.004521608352661133,\n",
       "  0.003994464874267578,\n",
       "  0.0040130615234375,\n",
       "  0.004061460494995117,\n",
       "  0.004060983657836914,\n",
       "  0.004240989685058594,\n",
       "  0.004332542419433594,\n",
       "  0.0040454864501953125,\n",
       "  0.004279136657714844,\n",
       "  0.0042455196380615234,\n",
       "  0.0041539669036865234,\n",
       "  0.004204273223876953,\n",
       "  0.0041959285736083984,\n",
       "  0.004178524017333984,\n",
       "  0.00406956672668457,\n",
       "  0.003982067108154297,\n",
       "  0.004124879837036133,\n",
       "  0.004153728485107422,\n",
       "  0.00415349006652832,\n",
       "  0.004141569137573242,\n",
       "  0.004118442535400391,\n",
       "  0.004192829132080078,\n",
       "  0.004217863082885742,\n",
       "  0.00421452522277832,\n",
       "  0.0042726993560791016,\n",
       "  0.004226207733154297,\n",
       "  0.004183053970336914,\n",
       "  0.00418400764465332,\n",
       "  0.004227161407470703,\n",
       "  0.0042724609375,\n",
       "  0.004342555999755859,\n",
       "  0.004004716873168945,\n",
       "  0.004122257232666016,\n",
       "  0.004144191741943359,\n",
       "  0.004053831100463867,\n",
       "  0.0041043758392333984,\n",
       "  0.0042154788970947266,\n",
       "  0.0042231082916259766,\n",
       "  0.004237174987792969,\n",
       "  0.004221200942993164,\n",
       "  0.004353523254394531,\n",
       "  0.004188060760498047,\n",
       "  0.00423121452331543,\n",
       "  0.004255533218383789,\n",
       "  0.004000186920166016,\n",
       "  0.003993988037109375,\n",
       "  0.003995418548583984,\n",
       "  0.004115581512451172,\n",
       "  0.004156351089477539,\n",
       "  0.0040056705474853516,\n",
       "  0.004016876220703125,\n",
       "  0.004002094268798828,\n",
       "  0.004101753234863281,\n",
       "  0.0041925907135009766,\n",
       "  0.00417780876159668,\n",
       "  0.004120588302612305,\n",
       "  0.004125118255615234,\n",
       "  0.004226207733154297,\n",
       "  0.004181861877441406,\n",
       "  0.004150390625,\n",
       "  0.004520416259765625,\n",
       "  0.004266262054443359,\n",
       "  0.0043926239013671875,\n",
       "  0.004212379455566406,\n",
       "  0.004359245300292969,\n",
       "  0.004113674163818359,\n",
       "  0.004083871841430664,\n",
       "  0.004136800765991211,\n",
       "  0.004082441329956055,\n",
       "  0.004144906997680664,\n",
       "  0.004196643829345703,\n",
       "  0.004150390625,\n",
       "  0.004270076751708984,\n",
       "  0.00420832633972168,\n",
       "  0.0041730403900146484,\n",
       "  0.003995180130004883,\n",
       "  0.0040090084075927734,\n",
       "  0.00408625602722168,\n",
       "  0.004122734069824219,\n",
       "  0.004216194152832031,\n",
       "  0.004174709320068359,\n",
       "  0.004106760025024414,\n",
       "  0.004212379455566406,\n",
       "  0.004155874252319336,\n",
       "  0.004291534423828125,\n",
       "  0.004210948944091797,\n",
       "  0.004184722900390625,\n",
       "  0.004213571548461914,\n",
       "  0.004037380218505859,\n",
       "  0.0040814876556396484,\n",
       "  0.004014015197753906,\n",
       "  0.0041637420654296875,\n",
       "  0.0041446685791015625,\n",
       "  0.004189252853393555,\n",
       "  0.0040967464447021484,\n",
       "  0.004104137420654297,\n",
       "  0.004202127456665039,\n",
       "  0.004201173782348633,\n",
       "  0.004225254058837891,\n",
       "  0.004275083541870117,\n",
       "  0.003993988037109375,\n",
       "  0.004008054733276367,\n",
       "  0.004091024398803711,\n",
       "  0.004132986068725586,\n",
       "  0.0041158199310302734,\n",
       "  0.004065036773681641,\n",
       "  0.004187822341918945,\n",
       "  0.004109621047973633,\n",
       "  0.004195213317871094,\n",
       "  0.004212141036987305,\n",
       "  0.004204511642456055,\n",
       "  0.004248857498168945,\n",
       "  0.004206180572509766,\n",
       "  0.004200458526611328,\n",
       "  0.004246234893798828,\n",
       "  0.004281282424926758,\n",
       "  0.0042264461517333984,\n",
       "  0.00428318977355957,\n",
       "  0.004235744476318359,\n",
       "  0.004300594329833984,\n",
       "  0.0042917728424072266,\n",
       "  0.0042896270751953125,\n",
       "  0.0044307708740234375,\n",
       "  0.004274845123291016,\n",
       "  0.004321098327636719,\n",
       "  0.004342079162597656,\n",
       "  0.004342555999755859,\n",
       "  0.004351615905761719,\n",
       "  0.004329681396484375,\n",
       "  0.004395008087158203,\n",
       "  0.004332542419433594,\n",
       "  0.004530191421508789,\n",
       "  0.004496097564697266,\n",
       "  0.004549741744995117,\n",
       "  0.004553079605102539,\n",
       "  0.004590034484863281,\n",
       "  0.0039370059967041016,\n",
       "  0.004079341888427734,\n",
       "  0.003951072692871094,\n",
       "  0.004171133041381836,\n",
       "  0.004072427749633789,\n",
       "  0.0041561126708984375,\n",
       "  0.004154682159423828,\n",
       "  0.004220485687255859,\n",
       "  0.004193305969238281,\n",
       "  0.004214286804199219,\n",
       "  0.004118919372558594,\n",
       "  0.00402522087097168,\n",
       "  0.004073381423950195,\n",
       "  0.004084587097167969,\n",
       "  0.0041408538818359375,\n",
       "  0.004158735275268555,\n",
       "  0.004136085510253906,\n",
       "  0.00420689582824707,\n",
       "  0.004178762435913086,\n",
       "  0.004228830337524414,\n",
       "  0.0042133331298828125,\n",
       "  0.00413823127746582,\n",
       "  0.00421595573425293,\n",
       "  0.004193782806396484,\n",
       "  0.0042340755462646484,\n",
       "  0.004235267639160156,\n",
       "  0.00423431396484375,\n",
       "  0.0042073726654052734,\n",
       "  0.0042874813079833984,\n",
       "  0.004266262054443359,\n",
       "  0.00426030158996582,\n",
       "  0.004264116287231445,\n",
       "  0.004305601119995117,\n",
       "  0.00425410270690918,\n",
       "  0.004344463348388672,\n",
       "  0.004327058792114258,\n",
       "  0.00448918342590332,\n",
       "  0.004510641098022461,\n",
       "  0.004533290863037109,\n",
       "  0.0042972564697265625,\n",
       "  0.004004478454589844,\n",
       "  0.004105567932128906,\n",
       "  0.004079580307006836,\n",
       "  0.0041654109954833984,\n",
       "  0.004081010818481445,\n",
       "  0.004176139831542969,\n",
       "  0.004195451736450195,\n",
       "  0.004230499267578125,\n",
       "  0.004199504852294922,\n",
       "  0.004229068756103516,\n",
       "  0.0042340755462646484,\n",
       "  0.004221677780151367,\n",
       "  0.004239320755004883,\n",
       "  0.0042307376861572266,\n",
       "  0.004282951354980469,\n",
       "  0.004255056381225586,\n",
       "  0.004236936569213867,\n",
       "  0.0042841434478759766,\n",
       "  0.004308938980102539,\n",
       "  0.004250526428222656,\n",
       "  0.0043566226959228516,\n",
       "  0.003943681716918945,\n",
       "  0.004011392593383789,\n",
       "  0.004018545150756836,\n",
       "  0.004082202911376953,\n",
       "  0.00426030158996582,\n",
       "  0.004187107086181641,\n",
       "  0.004135847091674805,\n",
       "  0.004190206527709961,\n",
       "  0.004227399826049805,\n",
       "  0.0041904449462890625,\n",
       "  0.004161834716796875,\n",
       "  0.0041577816009521484,\n",
       "  0.004191875457763672,\n",
       "  0.0041046142578125,\n",
       "  0.00407099723815918,\n",
       "  0.00410008430480957,\n",
       "  0.004102945327758789,\n",
       "  0.004179716110229492,\n",
       "  0.0042057037353515625,\n",
       "  0.004166841506958008,\n",
       "  0.00420379638671875,\n",
       "  0.004256725311279297,\n",
       "  0.004231929779052734,\n",
       "  0.004266977310180664,\n",
       "  0.004192829132080078,\n",
       "  0.004255771636962891,\n",
       "  0.004307746887207031,\n",
       "  0.00423884391784668,\n",
       "  0.004222869873046875,\n",
       "  0.004220485687255859,\n",
       "  0.0041544437408447266,\n",
       "  0.0042459964752197266,\n",
       "  0.0042171478271484375,\n",
       "  0.004258394241333008,\n",
       "  0.004256248474121094,\n",
       "  0.004270315170288086,\n",
       "  0.004273653030395508,\n",
       "  0.004256248474121094,\n",
       "  0.004179239273071289,\n",
       "  0.004204511642456055,\n",
       "  0.004255056381225586,\n",
       "  0.0043010711669921875,\n",
       "  0.004312276840209961,\n",
       "  0.004277706146240234,\n",
       "  0.004446983337402344,\n",
       "  0.004268169403076172,\n",
       "  0.004414796829223633,\n",
       "  0.004336357116699219,\n",
       "  0.004349231719970703,\n",
       "  0.004313230514526367,\n",
       "  0.004292964935302734,\n",
       "  0.0042819976806640625,\n",
       "  0.004322528839111328,\n",
       "  0.004295825958251953,\n",
       "  0.004553556442260742,\n",
       "  0.004540920257568359,\n",
       "  0.004580020904541016,\n",
       "  0.004561662673950195,\n",
       "  0.004554033279418945,\n",
       "  0.004559993743896484,\n",
       "  0.004568815231323242,\n",
       "  0.004591464996337891,\n",
       "  0.0045642852783203125,\n",
       "  0.00464630126953125,\n",
       "  0.004615068435668945,\n",
       "  0.004579782485961914,\n",
       "  0.00457453727722168,\n",
       "  0.004471778869628906,\n",
       "  0.004574298858642578,\n",
       "  0.004532814025878906,\n",
       "  0.004551887512207031,\n",
       "  0.004603385925292969,\n",
       "  0.004534482955932617,\n",
       "  0.0043315887451171875,\n",
       "  0.004002094268798828,\n",
       "  0.004046440124511719,\n",
       "  0.004079103469848633,\n",
       "  0.004161357879638672,\n",
       "  0.004167079925537109,\n",
       "  0.004070281982421875,\n",
       "  0.0041468143463134766,\n",
       "  0.004217863082885742,\n",
       "  0.0041866302490234375,\n",
       "  0.004229545593261719,\n",
       "  0.004231452941894531,\n",
       "  0.004206418991088867,\n",
       "  0.0041730403900146484,\n",
       "  0.0042247772216796875,\n",
       "  0.004263401031494141,\n",
       "  0.004266500473022461,\n",
       "  0.0042493343353271484,\n",
       "  0.004257917404174805,\n",
       "  0.0042858123779296875,\n",
       "  0.0042798519134521484,\n",
       "  0.0042917728424072266,\n",
       "  0.004244565963745117,\n",
       "  0.004307270050048828,\n",
       "  0.0043070316314697266,\n",
       "  0.004328727722167969,\n",
       "  0.0042896270751953125,\n",
       "  0.004346132278442383,\n",
       "  0.0045354366302490234,\n",
       "  0.004526615142822266,\n",
       "  0.004538297653198242,\n",
       "  0.004549980163574219,\n",
       "  0.004570960998535156,\n",
       "  0.004487514495849609,\n",
       "  0.004595756530761719,\n",
       "  0.004599809646606445,\n",
       "  0.004537105560302734,\n",
       "  0.004584789276123047,\n",
       "  0.004518032073974609,\n",
       "  0.003993988037109375,\n",
       "  0.004023075103759766,\n",
       "  0.0040090084075927734,\n",
       "  0.004067182540893555,\n",
       "  0.004081249237060547,\n",
       "  0.004160642623901367,\n",
       "  0.004205226898193359,\n",
       "  0.004268646240234375,\n",
       "  0.004251241683959961,\n",
       "  0.00429844856262207,\n",
       "  0.004335165023803711,\n",
       "  0.004239797592163086,\n",
       "  0.004216194152832031,\n",
       "  0.0041997432708740234,\n",
       "  0.0042340755462646484,\n",
       "  0.00401616096496582,\n",
       "  0.00403594970703125,\n",
       "  0.004004955291748047,\n",
       "  0.004069805145263672,\n",
       "  0.004047870635986328,\n",
       "  0.004143238067626953,\n",
       "  0.004170894622802734,\n",
       "  0.004158496856689453,\n",
       "  0.004147052764892578,\n",
       "  0.004214048385620117,\n",
       "  0.004225730895996094,\n",
       "  0.004227399826049805,\n",
       "  0.0042340755462646484,\n",
       "  0.004287242889404297,\n",
       "  0.00400090217590332,\n",
       "  0.004042625427246094,\n",
       "  0.004057407379150391,\n",
       "  0.004147052764892578,\n",
       "  0.0041599273681640625,\n",
       "  0.004114627838134766,\n",
       "  0.004233121871948242,\n",
       "  0.004197835922241211,\n",
       "  0.004239082336425781,\n",
       "  0.0042514801025390625,\n",
       "  0.004188060760498047,\n",
       "  0.004212856292724609,\n",
       "  0.00424504280090332,\n",
       "  0.004230976104736328,\n",
       "  0.004247188568115234,\n",
       "  0.004243135452270508,\n",
       "  0.004269838333129883,\n",
       "  0.004275321960449219,\n",
       "  0.004273414611816406,\n",
       "  0.0040171146392822266,\n",
       "  0.0040361881256103516,\n",
       "  0.004004001617431641,\n",
       "  0.004461765289306641,\n",
       "  0.004200935363769531,\n",
       "  0.0041656494140625,\n",
       "  0.0040590763092041016,\n",
       "  0.0041844844818115234,\n",
       "  0.004151582717895508,\n",
       "  0.004210710525512695,\n",
       "  0.0042095184326171875,\n",
       "  0.004256248474121094,\n",
       "  0.004258871078491211,\n",
       "  0.00424504280090332,\n",
       "  0.004229307174682617,\n",
       "  0.004257917404174805,\n",
       "  0.004278659820556641,\n",
       "  0.0042307376861572266,\n",
       "  0.004199028015136719,\n",
       "  0.004278421401977539,\n",
       "  0.004271268844604492,\n",
       "  0.00428462028503418,\n",
       "  0.00432896614074707,\n",
       "  0.004420757293701172,\n",
       "  0.0043849945068359375,\n",
       "  0.004304409027099609,\n",
       "  0.0042688846588134766,\n",
       "  0.004464149475097656,\n",
       "  0.0044231414794921875,\n",
       "  0.00429534912109375,\n",
       "  0.00428462028503418,\n",
       "  0.004393339157104492,\n",
       "  0.004429340362548828,\n",
       "  0.004558086395263672,\n",
       "  0.0045626163482666016,\n",
       "  0.004547119140625,\n",
       "  0.0045430660247802734,\n",
       "  0.004575490951538086,\n",
       "  0.0045185089111328125,\n",
       "  0.004496574401855469,\n",
       "  0.0045511722564697266,\n",
       "  0.004565000534057617,\n",
       "  0.004517078399658203,\n",
       "  0.004556179046630859,\n",
       "  0.004577159881591797,\n",
       "  0.004584789276123047,\n",
       "  0.00461888313293457,\n",
       "  0.0046613216400146484,\n",
       "  0.004748821258544922,\n",
       "  0.0047342777252197266,\n",
       "  0.004656553268432617,\n",
       "  0.004603862762451172,\n",
       "  0.004622936248779297,\n",
       "  0.004006385803222656,\n",
       "  0.0040857791900634766,\n",
       "  0.00409388542175293,\n",
       "  0.004203319549560547,\n",
       "  0.004177093505859375,\n",
       "  0.0041539669036865234,\n",
       "  0.0043103694915771484,\n",
       "  0.004229307174682617,\n",
       "  0.00413060188293457,\n",
       "  0.004228115081787109,\n",
       "  0.0041997432708740234,\n",
       "  0.004252195358276367,\n",
       "  0.004214763641357422,\n",
       "  0.004278421401977539,\n",
       "  0.004248619079589844,\n",
       "  0.004312992095947266,\n",
       "  0.00402522087097168,\n",
       "  0.003995180130004883,\n",
       "  0.004111766815185547,\n",
       "  0.004079341888427734,\n",
       "  0.004121065139770508,\n",
       "  0.004202842712402344,\n",
       "  0.00411677360534668,\n",
       "  0.004236698150634766,\n",
       "  0.004230499267578125,\n",
       "  0.0042209625244140625,\n",
       "  0.004177570343017578,\n",
       "  0.004225015640258789,\n",
       "  0.004180908203125,\n",
       "  0.004233837127685547,\n",
       "  0.004273653030395508,\n",
       "  0.004279375076293945,\n",
       "  0.0043523311614990234,\n",
       "  0.004278898239135742,\n",
       "  0.004279613494873047,\n",
       "  0.0042951107025146484,\n",
       "  0.004271030426025391,\n",
       "  0.004261493682861328,\n",
       "  0.0042989253997802734,\n",
       "  0.004289865493774414,\n",
       "  0.004323720932006836,\n",
       "  0.004285335540771484,\n",
       "  0.004292964935302734,\n",
       "  0.00429844856262207,\n",
       "  0.004287004470825195,\n",
       "  0.0043070316314697266,\n",
       "  0.004319429397583008,\n",
       "  0.00428009033203125,\n",
       "  0.004319190979003906,\n",
       "  0.0043261051177978516,\n",
       "  0.004319429397583008,\n",
       "  0.0039958953857421875,\n",
       "  0.004022836685180664,\n",
       "  0.0040056705474853516,\n",
       "  0.004113197326660156,\n",
       "  0.004163026809692383,\n",
       "  0.004168987274169922,\n",
       "  0.004068136215209961,\n",
       "  0.0042057037353515625,\n",
       "  0.0041887760162353516,\n",
       "  0.0042171478271484375,\n",
       "  0.004200935363769531,\n",
       "  0.004258871078491211,\n",
       "  0.0042836666107177734,\n",
       "  0.004263877868652344,\n",
       "  0.004232883453369141,\n",
       "  0.004256010055541992,\n",
       "  0.004256486892700195,\n",
       "  0.004319190979003906,\n",
       "  0.004246234893798828,\n",
       "  0.0042362213134765625,\n",
       "  0.004273176193237305,\n",
       "  0.004291534423828125,\n",
       "  0.004300355911254883,\n",
       "  0.004271507263183594,\n",
       "  0.004309892654418945,\n",
       "  0.004342555999755859,\n",
       "  0.004337787628173828,\n",
       "  0.004355430603027344,\n",
       "  0.004338264465332031,\n",
       "  0.004313230514526367,\n",
       "  0.004363059997558594,\n",
       "  0.004338979721069336,\n",
       "  0.004523277282714844,\n",
       "  0.004560708999633789,\n",
       "  0.004569292068481445,\n",
       "  0.004639863967895508,\n",
       "  0.004585742950439453,\n",
       "  0.0046536922454833984,\n",
       "  0.004602193832397461,\n",
       "  0.0045545101165771484,\n",
       "  0.004561662673950195,\n",
       "  0.0045549869537353516,\n",
       "  0.004667043685913086,\n",
       "  0.004529476165771484,\n",
       "  0.004588127136230469,\n",
       "  0.004522562026977539,\n",
       "  0.004583597183227539,\n",
       "  0.004553556442260742,\n",
       "  0.0046346187591552734,\n",
       "  0.0046045780181884766,\n",
       "  0.004607200622558594,\n",
       "  0.004616975784301758,\n",
       "  0.004595756530761719,\n",
       "  0.004604816436767578,\n",
       "  0.004616260528564453,\n",
       "  0.004618644714355469,\n",
       "  0.004609107971191406,\n",
       "  0.004585981369018555,\n",
       "  0.0046825408935546875,\n",
       "  0.004714488983154297,\n",
       "  0.0046422481536865234,\n",
       "  0.004617214202880859,\n",
       "  0.004664897918701172,\n",
       "  0.004677295684814453,\n",
       "  0.00500035285949707,\n",
       "  0.004891872406005859,\n",
       "  0.0048906803131103516,\n",
       "  0.004903316497802734,\n",
       "  0.004910469055175781,\n",
       "  0.0051991939544677734,\n",
       "  0.00487828254699707,\n",
       "  0.004923820495605469,\n",
       "  0.0048487186431884766,\n",
       "  0.004883766174316406,\n",
       "  0.004922389984130859,\n",
       "  0.004904508590698242,\n",
       "  0.00493621826171875,\n",
       "  0.004921674728393555,\n",
       "  0.0049936771392822266,\n",
       "  0.0049593448638916016,\n",
       "  0.004978179931640625,\n",
       "  0.004948139190673828,\n",
       "  0.004910707473754883,\n",
       "  0.0051288604736328125,\n",
       "  0.004973173141479492,\n",
       "  0.004949808120727539,\n",
       "  0.004956245422363281,\n",
       "  0.0049610137939453125,\n",
       "  0.005011320114135742,\n",
       "  0.004990100860595703,\n",
       "  0.005002498626708984,\n",
       "  0.004910945892333984,\n",
       "  0.00495147705078125,\n",
       "  0.005072116851806641,\n",
       "  0.004976987838745117,\n",
       "  0.005011320114135742,\n",
       "  0.005012989044189453,\n",
       "  0.004985332489013672,\n",
       "  0.004998683929443359,\n",
       "  0.005057096481323242,\n",
       "  0.004991054534912109,\n",
       "  0.005074024200439453,\n",
       "  0.005073070526123047,\n",
       "  0.005060434341430664,\n",
       "  0.005085468292236328,\n",
       "  0.005069732666015625,\n",
       "  0.005080461502075195,\n",
       "  0.00510859489440918,\n",
       "  0.005062580108642578,\n",
       "  0.0050601959228515625,\n",
       "  0.004029989242553711,\n",
       "  0.003977537155151367,\n",
       "  0.004097938537597656,\n",
       "  0.004133701324462891,\n",
       "  0.00409698486328125,\n",
       "  0.004116058349609375,\n",
       "  0.004166126251220703,\n",
       "  0.004174709320068359,\n",
       "  0.004174470901489258,\n",
       "  0.004156827926635742,\n",
       "  0.004189729690551758,\n",
       "  0.004230976104736328,\n",
       "  0.004214286804199219,\n",
       "  0.0042111873626708984,\n",
       "  0.004221677780151367,\n",
       "  0.004232645034790039,\n",
       "  0.0042285919189453125,\n",
       "  0.004221916198730469,\n",
       "  0.004265785217285156,\n",
       "  0.004251003265380859,\n",
       "  0.004261016845703125,\n",
       "  0.004290342330932617,\n",
       "  0.0042569637298583984,\n",
       "  0.00429844856262207,\n",
       "  0.00432896614074707,\n",
       "  0.00432896614074707,\n",
       "  0.004300117492675781,\n",
       "  0.0043354034423828125,\n",
       "  0.004332304000854492,\n",
       "  0.004343509674072266,\n",
       "  0.004313230514526367,\n",
       "  0.004528522491455078,\n",
       "  0.004544973373413086,\n",
       "  0.004463672637939453,\n",
       "  0.004452228546142578,\n",
       "  0.004288196563720703,\n",
       "  0.004029035568237305,\n",
       "  0.0039882659912109375,\n",
       "  0.003983259201049805,\n",
       "  0.0039827823638916016,\n",
       "  0.004076957702636719,\n",
       "  0.00409698486328125,\n",
       "  0.0041370391845703125,\n",
       "  0.004169464111328125,\n",
       "  0.004088401794433594,\n",
       "  0.004172801971435547,\n",
       "  0.004191875457763672,\n",
       "  0.004186391830444336,\n",
       "  0.004233837127685547,\n",
       "  0.0041925907135009766,\n",
       "  0.00416254997253418,\n",
       "  0.004136323928833008,\n",
       "  0.004153251647949219,\n",
       "  0.004232883453369141,\n",
       "  0.004237651824951172,\n",
       "  0.004254817962646484,\n",
       "  0.004280805587768555,\n",
       "  0.004347801208496094,\n",
       "  0.004315376281738281,\n",
       "  0.004401683807373047,\n",
       "  0.0044040679931640625,\n",
       "  0.0044176578521728516,\n",
       "  0.00437164306640625,\n",
       "  0.004319429397583008,\n",
       "  0.004328250885009766,\n",
       "  0.004270315170288086,\n",
       "  0.004326581954956055,\n",
       "  0.0043489933013916016,\n",
       "  0.004525184631347656,\n",
       "  0.004010200500488281,\n",
       "  0.004017353057861328,\n",
       "  0.0040130615234375,\n",
       "  0.004050731658935547,\n",
       "  0.004143953323364258,\n",
       "  0.004163026809692383,\n",
       "  0.004105806350708008,\n",
       "  0.004172801971435547,\n",
       "  0.004141330718994141,\n",
       "  0.0041387081146240234,\n",
       "  0.004533052444458008,\n",
       "  0.00423884391784668,\n",
       "  0.004190683364868164,\n",
       "  0.00429987907409668,\n",
       "  0.004244089126586914,\n",
       "  0.004323005676269531,\n",
       "  0.004204750061035156,\n",
       "  0.004295825958251953,\n",
       "  0.0043239593505859375,\n",
       "  0.004222869873046875,\n",
       "  0.004294633865356445,\n",
       "  0.004271268844604492,\n",
       "  0.004312753677368164,\n",
       "  0.004324197769165039,\n",
       "  0.0043277740478515625,\n",
       "  0.004334211349487305,\n",
       "  0.0043141841888427734,\n",
       "  0.004335641860961914,\n",
       "  0.004333019256591797,\n",
       "  0.004282951354980469,\n",
       "  0.003954172134399414,\n",
       "  0.00401759147644043,\n",
       "  0.004096508026123047,\n",
       "  0.004117250442504883,\n",
       "  0.0042378902435302734,\n",
       "  0.004197359085083008,\n",
       "  0.004208803176879883,\n",
       "  0.004224538803100586,\n",
       "  0.003989458084106445,\n",
       "  0.00402069091796875,\n",
       "  0.004010438919067383,\n",
       "  0.004076242446899414,\n",
       "  0.004148244857788086,\n",
       "  0.004135847091674805,\n",
       "  0.004091024398803711,\n",
       "  0.004167795181274414,\n",
       "  0.004204511642456055,\n",
       "  0.004139900207519531,\n",
       "  0.004227399826049805,\n",
       "  0.004148006439208984,\n",
       "  0.00414586067199707,\n",
       "  0.004185199737548828,\n",
       "  0.00424504280090332,\n",
       "  0.0042269229888916016,\n",
       "  0.004216432571411133,\n",
       "  0.004227399826049805,\n",
       "  0.0042264461517333984,\n",
       "  0.004228115081787109,\n",
       "  0.004297018051147461,\n",
       "  0.004302263259887695,\n",
       "  0.004243373870849609,\n",
       "  0.004240751266479492,\n",
       "  0.004317522048950195,\n",
       "  0.0043179988861083984,\n",
       "  0.004292011260986328,\n",
       "  0.00438380241394043,\n",
       "  0.004350423812866211,\n",
       "  0.0045490264892578125,\n",
       "  0.0045452117919921875,\n",
       "  0.004653215408325195,\n",
       "  0.004463911056518555,\n",
       "  0.004564762115478516,\n",
       "  0.0045168399810791016,\n",
       "  0.00449061393737793,\n",
       "  0.004553318023681641,\n",
       "  0.004583835601806641,\n",
       "  0.0045735836029052734,\n",
       "  0.004585742950439453,\n",
       "  0.0046062469482421875,\n",
       "  0.004556179046630859,\n",
       "  0.004590272903442383,\n",
       "  0.003979206085205078,\n",
       "  0.004015684127807617,\n",
       "  0.003993034362792969,\n",
       "  0.004148244857788086,\n",
       "  0.00419163703918457,\n",
       "  0.0042645931243896484,\n",
       "  0.003965854644775391,\n",
       "  0.0040132999420166016,\n",
       "  0.004082679748535156,\n",
       "  0.004086732864379883,\n",
       "  0.0041201114654541016,\n",
       "  0.004021883010864258,\n",
       "  0.004231929779052734,\n",
       "  0.004172086715698242,\n",
       "  0.0041925907135009766,\n",
       "  0.004141807556152344,\n",
       "  0.004229545593261719,\n",
       "  0.004204750061035156,\n",
       "  0.0042345523834228516,\n",
       "  0.004228830337524414,\n",
       "  0.004202127456665039,\n",
       "  0.004208564758300781,\n",
       "  0.004236459732055664,\n",
       "  0.004260063171386719,\n",
       "  0.004259824752807617,\n",
       "  0.004285335540771484,\n",
       "  0.0042133331298828125,\n",
       "  0.0039653778076171875,\n",
       "  0.003949165344238281,\n",
       "  0.0040090084075927734,\n",
       "  0.004258155822753906,\n",
       "  0.004080533981323242,\n",
       "  0.004149436950683594,\n",
       "  0.0040740966796875,\n",
       "  0.004159688949584961,\n",
       "  0.004191875457763672,\n",
       "  0.004197359085083008,\n",
       "  0.004204750061035156,\n",
       "  0.00420832633972168,\n",
       "  0.0042192935943603516,\n",
       "  0.00416111946105957,\n",
       "  0.0042111873626708984,\n",
       "  0.0042345523834228516,\n",
       "  0.004225730895996094,\n",
       "  0.004212617874145508,\n",
       "  0.004250288009643555,\n",
       "  0.0042572021484375,\n",
       "  0.00423884391784668,\n",
       "  0.004194736480712891,\n",
       "  0.004288673400878906,\n",
       "  0.004314422607421875,\n",
       "  0.004303693771362305,\n",
       "  0.004282474517822266,\n",
       "  0.004015684127807617,\n",
       "  0.004113435745239258,\n",
       "  0.0040187835693359375,\n",
       "  0.004360675811767578,\n",
       "  0.004081010818481445,\n",
       "  0.0040280818939208984,\n",
       "  0.004167079925537109,\n",
       "  0.0041141510009765625,\n",
       "  0.003994464874267578,\n",
       "  0.003968477249145508,\n",
       "  0.00402069091796875,\n",
       "  0.003958463668823242,\n",
       "  0.003981351852416992,\n",
       "  0.004015207290649414,\n",
       "  0.004013776779174805,\n",
       "  0.004076480865478516,\n",
       "  0.004143238067626953,\n",
       "  0.0040435791015625,\n",
       "  0.004098653793334961,\n",
       "  0.004164695739746094,\n",
       "  0.003972291946411133,\n",
       "  0.0040721893310546875,\n",
       "  0.004010200500488281,\n",
       "  0.004075288772583008,\n",
       "  0.0041506290435791016,\n",
       "  0.0041506290435791016,\n",
       "  0.004050016403198242,\n",
       "  0.004168987274169922,\n",
       "  0.0042569637298583984,\n",
       "  0.004032135009765625,\n",
       "  0.0041561126708984375,\n",
       "  0.0041141510009765625,\n",
       "  0.00409388542175293,\n",
       "  0.004177093505859375,\n",
       "  0.0041882991790771484,\n",
       "  0.004210710525512695,\n",
       "  0.004168987274169922,\n",
       "  0.004183769226074219,\n",
       "  0.004159450531005859,\n",
       "  0.004138946533203125,\n",
       "  0.00420832633972168,\n",
       "  0.004216670989990234,\n",
       "  0.004225015640258789,\n",
       "  0.00428462028503418,\n",
       "  0.004289150238037109,\n",
       "  0.0042917728424072266,\n",
       "  0.004274129867553711,\n",
       "  0.003975391387939453,\n",
       "  0.003979206085205078,\n",
       "  0.004002094268798828,\n",
       "  0.004154205322265625,\n",
       "  0.0043032169342041016,\n",
       "  0.004266023635864258,\n",
       "  0.004175662994384766,\n",
       "  0.003905057907104492,\n",
       "  0.004010677337646484,\n",
       "  0.00399327278137207,\n",
       "  0.0040569305419921875,\n",
       "  0.004096031188964844,\n",
       "  0.004124164581298828,\n",
       "  0.004109621047973633,\n",
       "  0.004146575927734375,\n",
       "  0.00417017936706543,\n",
       "  ...])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_accuracy(model, user_posts_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T19:56:14.472901400Z",
     "start_time": "2023-12-22T19:56:14.433901Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPT2LMHeadModel' object has no attribute 'ewc_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mewc_loss\u001b[49m\n",
      "File \u001b[0;32m/projectnb/cs505ws/projects/NextType/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GPT2LMHeadModel' object has no attribute 'ewc_loss'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T21:06:02.674288Z",
     "start_time": "2023-12-22T21:06:02.614883600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fisher_dict = {}\n",
    "optpar_dict = {}\n",
    "ewc_lambda = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T21:06:02.846672400Z",
     "start_time": "2023-12-22T21:06:02.830656300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def on_task_update(model, device, task_id, optimizer, training_data_loader):\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # accumulating gradients\n",
    "    for batch in tqdm(training_data_loader):\n",
    "        inputs = batch[\"input_ids\"].to(device=device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs, labels=inputs, attention_mask=attention_mask, token_type_ids=None)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "    fisher_dict[task_id] = {}\n",
    "    optpar_dict[task_id] = {}\n",
    "\n",
    "    # gradients accumulated can be used to calculate fisher\n",
    "    for name, param in model.named_parameters():\n",
    "        optpar_dict[task_id][name] = param.data.clone()\n",
    "        fisher_dict[task_id][name] = param.grad.data.clone().pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T21:06:03.383197800Z",
     "start_time": "2023-12-22T21:06:03.339162900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_ewc(model, device, task_id, optimizer, training_data_loader):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(training_data_loader):\n",
    "        inputs = batch[\"input_ids\"].to(device=device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs, labels=inputs, attention_mask=attention_mask, token_type_ids=None)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        ### magic here! :-)\n",
    "        for task in range(task_id):\n",
    "            for name, param in model.named_parameters():\n",
    "                fisher = fisher_dict[task][name]\n",
    "                optpar = optpar_dict[task][name]\n",
    "                loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(training_data_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-22T21:06:06.325604800Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                    | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                                                                  | 0/537 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|▎                                                                                                                                                                         | 1/537 [00:01<09:32,  1.07s/it]\u001b[A\n",
      "  0%|▋                                                                                                                                                                         | 2/537 [00:01<05:25,  1.64it/s]\u001b[A\n",
      "  1%|▉                                                                                                                                                                         | 3/537 [00:01<04:06,  2.16it/s]\u001b[A\n",
      "  1%|█▎                                                                                                                                                                        | 4/537 [00:01<03:29,  2.54it/s]\u001b[A\n",
      "  1%|█▌                                                                                                                                                                        | 5/537 [00:02<03:08,  2.82it/s]\u001b[A\n",
      "  1%|█▉                                                                                                                                                                        | 6/537 [00:02<02:56,  3.01it/s]\u001b[A\n",
      "  1%|██▏                                                                                                                                                                       | 7/537 [00:02<02:48,  3.15it/s]\u001b[A\n",
      "  1%|██▌                                                                                                                                                                       | 8/537 [00:03<02:42,  3.25it/s]\u001b[A\n",
      "  2%|██▊                                                                                                                                                                       | 9/537 [00:03<02:38,  3.32it/s]\u001b[A\n",
      "  2%|███▏                                                                                                                                                                     | 10/537 [00:03<02:35,  3.38it/s]\u001b[A\n",
      "  2%|███▍                                                                                                                                                                     | 11/537 [00:03<02:34,  3.41it/s]\u001b[A\n",
      "  2%|███▊                                                                                                                                                                     | 12/537 [00:04<02:32,  3.44it/s]\u001b[A\n",
      "  2%|████                                                                                                                                                                     | 13/537 [00:04<02:32,  3.45it/s]\u001b[A\n",
      "  3%|████▍                                                                                                                                                                    | 14/537 [00:04<02:31,  3.46it/s]\u001b[A\n",
      "  3%|████▋                                                                                                                                                                    | 15/537 [00:05<02:30,  3.46it/s]\u001b[A\n",
      "  3%|█████                                                                                                                                                                    | 16/537 [00:05<02:30,  3.46it/s]\u001b[A\n",
      "  3%|█████▎                                                                                                                                                                   | 17/537 [00:05<02:29,  3.47it/s]\u001b[A\n",
      "  3%|█████▋                                                                                                                                                                   | 18/537 [00:05<02:29,  3.48it/s]\u001b[A\n",
      "  4%|█████▉                                                                                                                                                                   | 19/537 [00:06<02:29,  3.47it/s]\u001b[A\n",
      "  4%|██████▎                                                                                                                                                                  | 20/537 [00:06<02:28,  3.47it/s]\u001b[A\n",
      "  4%|██████▌                                                                                                                                                                  | 21/537 [00:06<02:28,  3.47it/s]\u001b[A\n",
      "  4%|██████▉                                                                                                                                                                  | 22/537 [00:07<02:28,  3.47it/s]\u001b[A\n",
      "  4%|███████▏                                                                                                                                                                 | 23/537 [00:07<02:28,  3.47it/s]\u001b[A\n",
      "  4%|███████▌                                                                                                                                                                 | 24/537 [00:07<02:27,  3.47it/s]\u001b[A\n",
      "  5%|███████▊                                                                                                                                                                 | 25/537 [00:07<02:27,  3.47it/s]\u001b[A\n",
      "  5%|████████▏                                                                                                                                                                | 26/537 [00:08<02:26,  3.48it/s]\u001b[A\n",
      "  5%|████████▍                                                                                                                                                                | 27/537 [00:08<02:26,  3.48it/s]\u001b[A\n",
      "  5%|████████▊                                                                                                                                                                | 28/537 [00:08<02:26,  3.47it/s]\u001b[A\n",
      "  5%|█████████▏                                                                                                                                                               | 29/537 [00:09<02:26,  3.47it/s]\u001b[A\n",
      "  6%|█████████▍                                                                                                                                                               | 30/537 [00:09<02:25,  3.48it/s]\u001b[A\n",
      "  6%|█████████▊                                                                                                                                                               | 31/537 [00:09<02:25,  3.48it/s]\u001b[A\n",
      "  6%|██████████                                                                                                                                                               | 32/537 [00:09<02:24,  3.48it/s]\u001b[A\n",
      "  6%|██████████▍                                                                                                                                                              | 33/537 [00:10<02:24,  3.48it/s]\u001b[A\n",
      "  6%|██████████▋                                                                                                                                                              | 34/537 [00:10<02:24,  3.48it/s]\u001b[A\n",
      "  7%|███████████                                                                                                                                                              | 35/537 [00:10<02:24,  3.48it/s]\u001b[A\n",
      "  7%|███████████▎                                                                                                                                                             | 36/537 [00:11<02:24,  3.48it/s]\u001b[A\n",
      "  7%|███████████▋                                                                                                                                                             | 37/537 [00:11<02:23,  3.48it/s]\u001b[A\n",
      "  7%|███████████▉                                                                                                                                                             | 38/537 [00:11<02:23,  3.47it/s]\u001b[A\n",
      "  7%|████████████▎                                                                                                                                                            | 39/537 [00:11<02:23,  3.47it/s]\u001b[A\n",
      "  7%|████████████▌                                                                                                                                                            | 40/537 [00:12<02:23,  3.47it/s]\u001b[A\n",
      "  8%|████████████▉                                                                                                                                                            | 41/537 [00:12<02:22,  3.47it/s]\u001b[A\n",
      "  8%|█████████████▏                                                                                                                                                           | 42/537 [00:12<02:22,  3.47it/s]\u001b[A\n",
      "  8%|█████████████▌                                                                                                                                                           | 43/537 [00:13<02:22,  3.47it/s]\u001b[A\n",
      "  8%|█████████████▊                                                                                                                                                           | 44/537 [00:13<02:21,  3.47it/s]\u001b[A\n",
      "  8%|██████████████▏                                                                                                                                                          | 45/537 [00:13<02:21,  3.47it/s]\u001b[A\n",
      "  9%|██████████████▍                                                                                                                                                          | 46/537 [00:14<02:21,  3.46it/s]\u001b[A\n",
      "  9%|██████████████▊                                                                                                                                                          | 47/537 [00:14<02:21,  3.46it/s]\u001b[A\n",
      "  9%|███████████████                                                                                                                                                          | 48/537 [00:14<02:21,  3.46it/s]\u001b[A\n",
      "  9%|███████████████▍                                                                                                                                                         | 49/537 [00:14<02:21,  3.46it/s]\u001b[A\n",
      "  9%|███████████████▋                                                                                                                                                         | 50/537 [00:15<02:20,  3.47it/s]\u001b[A\n",
      "  9%|████████████████                                                                                                                                                         | 51/537 [00:15<02:20,  3.47it/s]\u001b[A\n",
      " 10%|████████████████▎                                                                                                                                                        | 52/537 [00:15<02:19,  3.47it/s]\u001b[A\n",
      " 10%|████████████████▋                                                                                                                                                        | 53/537 [00:16<02:19,  3.47it/s]\u001b[A\n",
      " 10%|████████████████▉                                                                                                                                                        | 54/537 [00:16<02:19,  3.46it/s]\u001b[A\n",
      " 10%|█████████████████▎                                                                                                                                                       | 55/537 [00:16<02:19,  3.46it/s]\u001b[A\n",
      " 10%|█████████████████▌                                                                                                                                                       | 56/537 [00:16<02:19,  3.46it/s]\u001b[A\n",
      " 11%|█████████████████▉                                                                                                                                                       | 57/537 [00:17<02:18,  3.46it/s]\u001b[A\n",
      " 11%|██████████████████▎                                                                                                                                                      | 58/537 [00:17<02:18,  3.46it/s]\u001b[A\n",
      " 11%|██████████████████▌                                                                                                                                                      | 59/537 [00:17<02:18,  3.46it/s]\u001b[A\n",
      " 11%|██████████████████▉                                                                                                                                                      | 60/537 [00:18<02:17,  3.46it/s]\u001b[A\n",
      " 11%|███████████████████▏                                                                                                                                                     | 61/537 [00:18<02:17,  3.45it/s]\u001b[A\n",
      " 12%|███████████████████▌                                                                                                                                                     | 62/537 [00:18<02:17,  3.45it/s]\u001b[A\n",
      " 12%|███████████████████▊                                                                                                                                                     | 63/537 [00:18<02:17,  3.45it/s]\u001b[A\n",
      " 12%|████████████████████▏                                                                                                                                                    | 64/537 [00:19<02:16,  3.45it/s]\u001b[A\n",
      " 12%|████████████████████▍                                                                                                                                                    | 65/537 [00:19<02:16,  3.45it/s]\u001b[A\n",
      " 12%|████████████████████▊                                                                                                                                                    | 66/537 [00:19<02:16,  3.45it/s]\u001b[A\n",
      " 12%|█████████████████████                                                                                                                                                    | 67/537 [00:20<02:15,  3.46it/s]\u001b[A\n",
      " 13%|█████████████████████▍                                                                                                                                                   | 68/537 [00:20<02:15,  3.46it/s]\u001b[A\n",
      " 13%|█████████████████████▋                                                                                                                                                   | 69/537 [00:20<02:15,  3.45it/s]\u001b[A\n",
      " 13%|██████████████████████                                                                                                                                                   | 70/537 [00:20<02:15,  3.45it/s]\u001b[A\n",
      " 13%|██████████████████████▎                                                                                                                                                  | 71/537 [00:21<02:15,  3.45it/s]\u001b[A\n",
      " 13%|██████████████████████▋                                                                                                                                                  | 72/537 [00:21<02:14,  3.45it/s]\u001b[A\n",
      " 14%|██████████████████████▉                                                                                                                                                  | 73/537 [00:21<02:14,  3.45it/s]\u001b[A\n",
      " 14%|███████████████████████▎                                                                                                                                                 | 74/537 [00:22<02:14,  3.45it/s]\u001b[A\n",
      " 14%|███████████████████████▌                                                                                                                                                 | 75/537 [00:22<02:13,  3.46it/s]\u001b[A\n",
      " 14%|███████████████████████▉                                                                                                                                                 | 76/537 [00:22<02:12,  3.47it/s]\u001b[A\n",
      " 14%|████████████████████████▏                                                                                                                                                | 77/537 [00:22<02:12,  3.46it/s]\u001b[A\n",
      " 15%|████████████████████████▌                                                                                                                                                | 78/537 [00:23<02:12,  3.46it/s]\u001b[A\n",
      " 15%|████████████████████████▊                                                                                                                                                | 79/537 [00:23<02:12,  3.45it/s]\u001b[A\n",
      " 15%|█████████████████████████▏                                                                                                                                               | 80/537 [00:23<02:12,  3.45it/s]\u001b[A\n",
      " 15%|█████████████████████████▍                                                                                                                                               | 81/537 [00:24<02:12,  3.45it/s]\u001b[A\n",
      " 15%|█████████████████████████▊                                                                                                                                               | 82/537 [00:24<02:11,  3.46it/s]\u001b[A\n",
      " 15%|██████████████████████████                                                                                                                                               | 83/537 [00:24<02:11,  3.46it/s]\u001b[A\n",
      " 16%|██████████████████████████▍                                                                                                                                              | 84/537 [00:25<02:10,  3.47it/s]\u001b[A\n",
      " 16%|██████████████████████████▊                                                                                                                                              | 85/537 [00:25<02:10,  3.47it/s]\u001b[A\n",
      " 16%|███████████████████████████                                                                                                                                              | 86/537 [00:25<02:10,  3.46it/s]\u001b[A\n",
      " 16%|███████████████████████████▍                                                                                                                                             | 87/537 [00:25<02:10,  3.45it/s]\u001b[A\n",
      " 16%|███████████████████████████▋                                                                                                                                             | 88/537 [00:26<02:10,  3.45it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "ewc_accs = []\n",
    "for id, task in enumerate(task_sets):\n",
    "\n",
    "    training_data_loader = DataLoader(\n",
    "        dataset=trained_dataset_processed,\n",
    "        batch_size=6,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "    )\n",
    "\n",
    "    print(\"Training on task: \", id)\n",
    "\n",
    "    for epoch in tqdm(range(1, 3)):\n",
    "        train_ewc(model, device, id, optimizer, training_data_loader)\n",
    "        on_task_update(model, device, id, optimizer, training_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Resources and Publications\n",
    "\n",
    "For this project, I am considering/planning to use the following resources for research:\n",
    "\n",
    "1. Tunstall, L., Werra, L., Wolf, T., &amp; Géron, A. (2022). Natural language processing with transformers: Building language applications with hugging face. O’Reilly.\n",
    "\n",
    "> This book has been repeatedly recommended by both Professor Snyder and other students in CS505. Upon a coarse inspection, I expect to particular find the sections on \"Fine Tuning\" various models helpful (since this is very much a Fine-Tuning project). The book also contains extensive details about various transformer architectures which will inevitably prove useful.\n",
    "\n",
    "2. \"Fine-Tune a Pretrained Model.\" Hugging Face, https://huggingface.co/docs/transformers/training. Accessed 1 Dec. 2023.\n",
    "\n",
    "> This blog post contains examples Fine-Tuning bert using three different methods along with model evaluation. Although unlike source (#1), it goes into less details on the theory, the sample code is more rich, and easier to work with.\n",
    "\n",
    "3. Raffel, Colin, et al. “Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.” Arxiv, 23 Oct. 2019, Accessed 1 Dec. 2023.\n",
    "\n",
    "> This is the original paper that introduced T5 to the world. As covered in lecture, similar to Bert, T5 was (partially) trained on Mask-Fill task where random spans of texts were removed which naturally make it a great candidate for what we want to achieve here. However, this Mask-Fill process was only part of the process. T5 is a very versitile (and large) model, and has huge applications. There is no better place to learn what it is, how it works, and how to use it than the original paper!\n",
    "\n",
    "4. https://212digital.medium.com/fine-tuning-the-gpt-2-large-language-model-unlocking-its-full-potential-66e3a082ab9c\n",
    "\n",
    "> This great blog post contains all the coded needed to get started on fine-tuning GPT2 and the warnings about the various pitfalls."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
